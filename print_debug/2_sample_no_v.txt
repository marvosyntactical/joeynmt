<built-in method with_traceback of PicklingError object at 0x7f8dd6155a08>
<built-in method with_traceback of PicklingError object at 0x7f8dd6155a08>
encoder.output_size:  60
batch.kbsrc:  (tensor([[  0,   3,   1,   1,   1,   1],
        [143,  90,   1,   8,   3,   1],
        [143,  90,   1,  10,   3,   1],
        [143,  90,   1,   9,   3,   1],
        [143,  90,   1,   6,   3,   1],
        [ 42, 192,  90,   1,   8,   3],
        [ 42, 192,  90,   1,  10,   3],
        [ 42, 192,  90,   1,   9,   3],
        [ 42, 192,  90,   1,   6,   3],
        [289, 128,   1,   8,   3,   1],
        [289, 128,   1,  10,   3,   1],
        [289, 128,   1,   9,   3,   1],
        [289, 128,   1,   6,   3,   1],
        [  5, 181,   1,   8,   3,   1],
        [  5, 181,   1,  10,   3,   1],
        [  5, 181,   1,   9,   3,   1],
        [  5, 181,   1,   6,   3,   1],
        [165,  62,   1,   8,   3,   1],
        [165,  62,   1,  10,   3,   1],
        [165,  62,   1,   9,   3,   1],
        [165,  62,   1,   6,   3,   1],
        [ 59,  37,   1,   8,   3,   1],
        [ 59,  37,   1,  10,   3,   1],
        [ 59,  37,   1,   9,   3,   1],
        [ 59,  37,   1,   6,   3,   1],
        [210,   1,   8,   3,   1,   1],
        [210,   1,  10,   3,   1,   1],
        [210,   1,   9,   3,   1,   1],
        [210,   1,   6,   3,   1,   1],
        [152, 158,   1,   8,   3,   1],
        [152, 158,   1,  10,   3,   1],
        [152, 158,   1,   9,   3,   1],
        [152, 158,   1,   6,   3,   1]]), tensor([2, 5, 5, 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
        5, 4, 4, 4, 4, 5, 5, 5, 5])) <class 'tuple'>
batch.kbtrg:  (tensor([[  2,   0,   3],
        [  2, 335,   3],
        [  2, 337,   3],
        [  2, 336,   3],
        [  2, 334,   3],
        [  2, 505,   3],
        [  2, 507,   3],
        [  2, 506,   3],
        [  2, 504,   3],
        [  2, 709,   3],
        [  2, 711,   3],
        [  2, 710,   3],
        [  2, 708,   3],
        [  2, 479,   3],
        [  2, 481,   3],
        [  2, 480,   3],
        [  2, 478,   3],
        [  2, 348,   3],
        [  2, 350,   3],
        [  2, 349,   3],
        [  2, 347,   3],
        [  2, 323,   3],
        [  2, 325,   3],
        [  2, 324,   3],
        [  2, 322,   3],
        [  2, 528,   3],
        [  2, 530,   3],
        [  2, 529,   3],
        [  2, 527,   3],
        [  2, 392,   3],
        [  2, 394,   3],
        [  2, 393,   3],
        [  2, 391,   3]]), tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3])) <class 'tuple'>

----------TRN FWD PASS: START current batch----------

proc_batch: batch.src: ["where's", 'the', 'nearest', 'parking', 'garage', '@dot', 'the', 'nearest', 'parking', 'garage', 'is', 'dish', 'parking', 'at', '550', 'alester', 'ave.', 'would', 'you', 'like', 'directions', 'there?', '@dot', 'yes,', 'please', 'set', 'directions', 'via', 'a', 'route', 'that', 'avoids', 'all', 'heavy', 'traffic', 'if', 'possible.', '@dot', 'it', 'looks', 'like', 'there', 'is', 'a', 'road', 'block', 'being', 'reported', 'on', 'the', 'route', 'but', 'i', 'will', 'still', 'find', 'the', 'quickest', 'route', 'to', '550', 'alester', 'ave.', '@dot', 'thanks', 'so', 'much', 'for', 'your', 'help.']
proc_batch: batch.trg: ["you're", 'very', 'welcome!']
proc_batch: kbkeys: [['<unk>'], ['downtown_chicago_tuesday', 'yoga_activity_agenda', '<pad>', 'at'], ['downtown_chicago_tuesday', 'yoga_activity_agenda', '<pad>', 'in'], ['downtown_chicago_tuesday', 'yoga_activity_agenda', '<pad>', 'to'], ['downtown_chicago_tuesday', 'yoga_activity_agenda', '<pad>', 'you'], ['do', 'oakland_saturday', 'yoga_activity_agenda', '<pad>', 'at'], ['do', 'oakland_saturday', 'yoga_activity_agenda', '<pad>', 'in'], ['do', 'oakland_saturday', 'yoga_activity_agenda', '<pad>', 'to'], ['do', 'oakland_saturday', 'yoga_activity_agenda', '<pad>', 'you'], ['alhambra_saturday', 'redwood_city_thursday', '<pad>', 'at'], ['alhambra_saturday', 'redwood_city_thursday', '<pad>', 'in'], ['alhambra_saturday', 'redwood_city_thursday', '<pad>', 'to'], ['alhambra_saturday', 'redwood_city_thursday', '<pad>', 'you'], ['is', 'dinner_room', '<pad>', 'at'], ['is', 'dinner_room', '<pad>', 'in'], ['is', 'dinner_room', '<pad>', 'to'], ['is', 'dinner_room', '<pad>', 'you'], ['durham_tuesday', 'dentist_appointment_time', '<pad>', 'at'], ['durham_tuesday', 'dentist_appointment_time', '<pad>', 'in'], ['durham_tuesday', 'dentist_appointment_time', '<pad>', 'to'], ['durham_tuesday', 'dentist_appointment_time', '<pad>', 'you'], ['dentist_appointment_date', 'home_traffic_info', '<pad>', 'at'], ['dentist_appointment_date', 'home_traffic_info', '<pad>', 'in'], ['dentist_appointment_date', 'home_traffic_info', '<pad>', 'to'], ['dentist_appointment_date', 'home_traffic_info', '<pad>', 'you'], ['cleveland_monday', '<pad>', 'at'], ['cleveland_monday', '<pad>', 'in'], ['cleveland_monday', '<pad>', 'to'], ['cleveland_monday', '<pad>', 'you'], ['menlo_park_wednesday', 'compton_tuesday', '<pad>', 'at'], ['menlo_park_wednesday', 'compton_tuesday', '<pad>', 'in'], ['menlo_park_wednesday', 'compton_tuesday', '<pad>', 'to'], ['menlo_park_wednesday', 'compton_tuesday', '<pad>', 'you']]
proc_batch: kbvals: [['<s>', '<unk>'], ['<s>', 'dish_parking_distance'], ['<s>', 'dish_parking_traffic_info'], ['<s>', 'dish_parking_poi_type'], ['<s>', 'dish_parking_address'], ['<s>', 'stanford_oval_parking_distance'], ['<s>', 'stanford_oval_parking_traffic_info'], ['<s>', 'stanford_oval_parking_poi_type'], ['<s>', 'stanford_oval_parking_address'], ['<s>', 'willows_market_distance'], ['<s>', 'willows_market_traffic_info'], ['<s>', 'willows_market_poi_type'], ['<s>', 'willows_market_address'], ['<s>', 'the_westin_distance'], ['<s>', 'the_westin_traffic_info'], ['<s>', 'the_westin_poi_type'], ['<s>', 'the_westin_address'], ['<s>', 'toms_house_distance'], ['<s>', 'toms_house_traffic_info'], ['<s>', 'toms_house_poi_type'], ['<s>', 'toms_house_address'], ['<s>', 'pizza_chicago_distance'], ['<s>', 'pizza_chicago_traffic_info'], ['<s>', 'pizza_chicago_poi_type'], ['<s>', 'pizza_chicago_address'], ['<s>', 'valero_distance'], ['<s>', 'valero_traffic_info'], ['<s>', 'valero_poi_type'], ['<s>', 'valero_address'], ['<s>', 'mandarin_roots_distance'], ['<s>', 'mandarin_roots_traffic_info'], ['<s>', 'mandarin_roots_poi_type'], ['<s>', 'mandarin_roots_address']]
decoder.forward() unroll_steps in model.forward
is 26, which is 1st dim of trg_input=torch.Size([3, 26])
batch.trg_input: ['<s>', "you're", 'very', 'welcome!']
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1767,  0.1152,  0.3159,  0.1454,  0.0250,  0.1476,  0.3429,
           0.1831,  0.0566, -0.0511,  0.1484, -0.0197, -0.1447, -0.1634,
           0.0277, -0.1401, -0.2563, -0.1626,  0.0381, -0.1366, -0.2471,
           0.0811,  0.2799,  0.1131, -0.0136, -0.0559,  0.1423, -0.0269,
          -0.1464,  0.0284,  0.2219,  0.0561, -0.0682]],

        [[-0.2691,  0.0062,  0.2123,  0.0437, -0.0755,  0.0570,  0.2578,
           0.0951, -0.0333, -0.1424,  0.0590, -0.0997, -0.2322, -0.2539,
          -0.0648, -0.2238, -0.3443, -0.2568, -0.0541, -0.2301, -0.3422,
          -0.0092,  0.1888,  0.0240, -0.1000, -0.1492,  0.0547, -0.1127,
          -0.2406, -0.0713,  0.1292, -0.0345, -0.1610]],

        [[ 0.0338,  0.3044,  0.5131,  0.3437,  0.2338,  0.3616,  0.5576,
           0.4002,  0.2801,  0.1536,  0.3592,  0.1960,  0.0733,  0.0387,
           0.2373,  0.0686, -0.0472,  0.0461,  0.2504,  0.0696, -0.0447,
           0.2946,  0.4953,  0.3279,  0.2098,  0.1617,  0.3612,  0.1949,
           0.0727,  0.2232,  0.4228,  0.2594,  0.1450]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1819,  0.1098,  0.3102,  0.1399,  0.0192,  0.1413,  0.3369,
           0.1770,  0.0504, -0.0568,  0.1426, -0.0250, -0.1505, -0.1682,
           0.0221, -0.1451, -0.2617, -0.1678,  0.0324, -0.1419, -0.2529,
           0.0753,  0.2738,  0.1072, -0.0196, -0.0614,  0.1368, -0.0322,
          -0.1521,  0.0230,  0.2157,  0.0506, -0.0741]],

        [[-0.4415, -0.1661,  0.0351, -0.1332, -0.2508, -0.1189,  0.0792,
          -0.0858, -0.2098, -0.3210, -0.1235, -0.2819, -0.4109, -0.4203,
          -0.2422, -0.3960, -0.5113, -0.4268, -0.2301, -0.4032, -0.5083,
          -0.1825,  0.0095, -0.1544, -0.2750, -0.3279, -0.1275, -0.2932,
          -0.4162, -0.2466, -0.0485, -0.2146, -0.3389]],

        [[-0.0561,  0.2177,  0.4234,  0.2530,  0.1434,  0.2708,  0.4668,
           0.3052,  0.1872,  0.0608,  0.2651,  0.1001, -0.0201, -0.0443,
           0.1454, -0.0199, -0.1329, -0.0416,  0.1580, -0.0218, -0.1343,
           0.2048,  0.4017,  0.2333,  0.1169,  0.0693,  0.2675,  0.1001,
          -0.0199,  0.1335,  0.3318,  0.1647,  0.0517]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1829,  0.1089,  0.3089,  0.1387,  0.0181,  0.1401,  0.3356,
           0.1757,  0.0492, -0.0578,  0.1412, -0.0259, -0.1516, -0.1685,
           0.0209, -0.1459, -0.2626, -0.1688,  0.0307, -0.1435, -0.2548,
           0.0745,  0.2726,  0.1059, -0.0207, -0.0626,  0.1355, -0.0334,
          -0.1536,  0.0220,  0.2140,  0.0494, -0.0755]],

        [[-0.5574, -0.2859, -0.0875, -0.2544, -0.3724, -0.2393, -0.0429,
          -0.2082, -0.3302, -0.4417, -0.2478, -0.4048, -0.5323, -0.5359,
          -0.3641, -0.5136, -0.6263, -0.5452, -0.3519, -0.5216, -0.6230,
          -0.3025, -0.1136, -0.2757, -0.3958, -0.4498, -0.2521, -0.4154,
          -0.5357, -0.3667, -0.1697, -0.3361, -0.4603]],

        [[-0.1243,  0.1498,  0.3492,  0.1797,  0.0711,  0.1986,  0.3917,
           0.2279,  0.1120, -0.0126,  0.1877,  0.0232, -0.0946, -0.1048,
           0.0738, -0.0859, -0.1968, -0.1061,  0.0851, -0.0902, -0.2033,
           0.1350,  0.3253,  0.1579,  0.0438, -0.0015,  0.1916,  0.0263,
          -0.0930,  0.0649,  0.2580,  0.0906, -0.0213]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-2.0496e-01,  8.6923e-02,  2.8649e-01,  1.1652e-01, -4.1889e-03,
           1.1814e-01,  3.1369e-01,  1.5353e-01,  2.7480e-02, -7.9929e-02,
           1.1865e-01, -4.8070e-02, -1.7384e-01, -1.8956e-01, -1.3660e-03,
          -1.6751e-01, -2.8407e-01, -1.9067e-01,  8.4618e-03, -1.6585e-01,
          -2.7644e-01,  5.2794e-02,  2.5035e-01,  8.3751e-02, -4.2444e-02,
          -8.5265e-02,  1.1321e-01, -5.5975e-02, -1.7593e-01,  2.0787e-05,
           1.9174e-01,  2.7083e-02, -9.7889e-02]],

        [[-6.1570e-01, -3.4914e-01, -1.5040e-01, -3.1688e-01, -4.3437e-01,
          -2.9802e-01, -1.0392e-01, -2.6765e-01, -3.8765e-01, -5.0255e-01,
          -3.1044e-01, -4.6637e-01, -5.9198e-01, -5.9492e-01, -4.2460e-01,
          -5.7063e-01, -6.8204e-01, -6.0508e-01, -4.1194e-01, -5.7774e-01,
          -6.7658e-01, -3.6242e-01, -1.7460e-01, -3.3407e-01, -4.5438e-01,
          -5.0816e-01, -3.1298e-01, -4.7245e-01, -5.9003e-01, -4.2898e-01,
          -2.3084e-01, -3.9668e-01, -5.2061e-01]],

        [[-2.3929e-01,  3.8718e-02,  2.3168e-01,  6.4399e-02, -4.9143e-02,
           8.0190e-02,  2.7113e-01,  1.0557e-01, -1.2910e-02, -1.2843e-01,
           6.6793e-02, -9.6265e-02, -2.1677e-01, -2.1067e-01, -4.3594e-02,
          -1.9651e-01, -3.0979e-01, -2.2125e-01, -3.7270e-02, -2.0788e-01,
          -3.2409e-01,  1.9448e-02,  2.0368e-01,  3.8629e-02, -7.9349e-02,
          -1.2116e-01,  6.7710e-02, -9.5600e-02, -2.1781e-01, -4.7511e-02,
           1.4174e-01, -2.5632e-02, -1.4233e-01]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2276,  0.0645,  0.2637,  0.0937, -0.0271,  0.0955,  0.2914,
           0.1304,  0.0051, -0.1030,  0.0952, -0.0715, -0.1970, -0.2114,
          -0.0244, -0.1899, -0.3061, -0.2134, -0.0147, -0.1887, -0.2990,
           0.0301,  0.2274,  0.0606, -0.0651, -0.1087,  0.0898, -0.0793,
          -0.1991, -0.0229,  0.1686,  0.0038, -0.1212]],

        [[-0.5720, -0.3102, -0.1077, -0.2768, -0.3900, -0.2516, -0.0587,
          -0.2220, -0.3361, -0.4586, -0.2659, -0.4237, -0.5429, -0.5553,
          -0.3811, -0.5290, -0.6368, -0.5610, -0.3656, -0.5311, -0.6249,
          -0.3184, -0.1288, -0.2886, -0.4058, -0.4616, -0.2671, -0.4263,
          -0.5361, -0.3858, -0.1861, -0.3535, -0.4717]],

        [[-0.3177, -0.0359,  0.1565, -0.0122, -0.1296,  0.0052,  0.1960,
           0.0285, -0.0930, -0.2046, -0.0088, -0.1747, -0.2968, -0.2864,
          -0.1204, -0.2747, -0.3875, -0.2972, -0.1137, -0.2839, -0.3997,
          -0.0565,  0.1278, -0.0388, -0.1595, -0.2001, -0.0105, -0.1750,
          -0.2986, -0.1185,  0.0711, -0.0990, -0.2199]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2600,  0.0324,  0.2307,  0.0610, -0.0596,  0.0628,  0.2592,
           0.0974, -0.0274, -0.1357,  0.0619, -0.1045, -0.2297, -0.2424,
          -0.0572, -0.2217, -0.3371, -0.2457, -0.0478, -0.2214, -0.3308,
          -0.0026,  0.1944,  0.0274, -0.0977, -0.1421,  0.0568, -0.1127,
          -0.2319, -0.0554,  0.1360, -0.0289, -0.1541]],

        [[-0.4538, -0.1956,  0.0107, -0.1609, -0.2692, -0.1349,  0.0555,
          -0.1069, -0.2142, -0.3435, -0.1507, -0.3107, -0.4234, -0.4443,
          -0.2636, -0.4152, -0.5203, -0.4441, -0.2455, -0.4118, -0.5030,
          -0.2023, -0.0106, -0.1715, -0.2848, -0.3416, -0.1500, -0.3076,
          -0.4109, -0.2722, -0.0708, -0.2391, -0.3506]],

        [[-0.4144, -0.1263,  0.0596, -0.1073, -0.2285, -0.0946,  0.0942,
          -0.0732, -0.1983, -0.2988, -0.1081, -0.2741, -0.3972, -0.3775,
          -0.2201, -0.3712, -0.4852, -0.3978, -0.2198, -0.3880, -0.5034,
          -0.1555,  0.0245, -0.1404, -0.2653, -0.2987, -0.1136, -0.2780,
          -0.4010, -0.2121, -0.0267, -0.1978, -0.3217]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2799,  0.0130,  0.2108,  0.0411, -0.0792,  0.0432,  0.2397,
           0.0775, -0.0467, -0.1557,  0.0416, -0.1250, -0.2493, -0.2613,
          -0.0771, -0.2412, -0.3556, -0.2653, -0.0677, -0.2410, -0.3495,
          -0.0224,  0.1743,  0.0073, -0.1174, -0.1625,  0.0366, -0.1332,
          -0.2515, -0.0753,  0.1163, -0.0491, -0.1741]],

        [[-0.3154, -0.0609,  0.1479, -0.0243, -0.1264,  0.0005,  0.1869,
           0.0274, -0.0724, -0.2070, -0.0146, -0.1748, -0.2804, -0.3096,
          -0.1224, -0.2769, -0.3778, -0.3028, -0.1026, -0.2677, -0.3553,
          -0.0641,  0.1280, -0.0320, -0.1397, -0.2022, -0.0132, -0.1681,
          -0.2646, -0.1382,  0.0629, -0.1042, -0.2084]],

        [[-0.3242, -0.0357,  0.1520, -0.0159, -0.1358, -0.0053,  0.1863,
           0.0169, -0.1069, -0.2086, -0.0154, -0.1843, -0.3052, -0.2911,
          -0.1312, -0.2850, -0.3983, -0.3089, -0.1298, -0.2996, -0.4187,
          -0.0675,  0.1160, -0.0512, -0.1762, -0.2080, -0.0218, -0.1881,
          -0.3113, -0.1208,  0.0664, -0.1058, -0.2286]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-3.1563e-01, -2.2279e-02,  1.7499e-01,  5.2903e-03, -1.1465e-01,
           8.0092e-03,  2.0494e-01,  4.1712e-02, -8.1247e-02, -1.9172e-01,
           5.1304e-03, -1.6171e-01, -2.8495e-01, -2.9605e-01, -1.1306e-01,
          -2.7648e-01, -3.8977e-01, -3.0102e-01, -1.0344e-01, -2.7659e-01,
          -3.8372e-01, -5.8113e-02,  1.3845e-01, -2.8863e-02, -1.5261e-01,
          -1.9895e-01,  3.9032e-04, -1.6966e-01, -2.8669e-01, -1.1143e-01,
           8.0537e-02, -8.5423e-02, -2.1003e-01]],

        [[-1.5441e-01,  1.0064e-01,  3.0942e-01,  1.3638e-01,  4.0039e-02,
           1.6005e-01,  3.4097e-01,  1.8409e-01,  9.0317e-02, -4.7645e-02,
           1.4324e-01, -1.8513e-02, -1.1742e-01, -1.4992e-01,  4.1864e-02,
          -1.1705e-01, -2.1337e-01, -1.3749e-01,  6.2089e-02, -1.0337e-01,
          -1.8751e-01,  9.8164e-02,  2.8917e-01,  1.2887e-01,  2.6659e-02,
          -4.0571e-02,  1.4371e-01, -9.2916e-03, -1.0038e-01,  2.0493e-02,
           2.2020e-01,  5.3099e-02, -4.4167e-02]],

        [[-3.5103e-01, -6.0750e-02,  1.1914e-01, -4.4932e-02, -1.6290e-01,
          -3.6073e-02,  1.5171e-01, -1.7510e-02, -1.3900e-01, -2.3857e-01,
          -4.9458e-02, -2.1686e-01, -3.3600e-01, -3.1380e-01, -1.5961e-01,
          -3.1236e-01, -4.2155e-01, -3.3270e-01, -1.6039e-01, -3.2687e-01,
          -4.4467e-01, -9.5394e-02,  8.3428e-02, -8.2829e-02, -2.0504e-01,
          -2.3789e-01, -5.7688e-02, -2.1951e-01, -3.4272e-01, -1.4692e-01,
           3.5655e-02, -1.3468e-01, -2.5679e-01]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.3486, -0.0546,  0.1422, -0.0274, -0.1465, -0.0238,  0.1733,
           0.0092, -0.1121, -0.2246, -0.0282, -0.1955, -0.3172, -0.3284,
          -0.1460, -0.3092, -0.4211, -0.3343, -0.1363, -0.3097, -0.4149,
          -0.0908,  0.1059, -0.0619, -0.1845, -0.2321, -0.0326, -0.2030,
          -0.3182, -0.1450,  0.0479, -0.1189, -0.2427]],

        [[-0.0125,  0.2458,  0.4500,  0.2784,  0.1864,  0.2982,  0.4707,
           0.3178,  0.2283,  0.0932,  0.2777,  0.1170,  0.0231, -0.0059,
           0.1859,  0.0243, -0.0681,  0.0083,  0.2030,  0.0384, -0.0426,
           0.2408,  0.4267,  0.2679,  0.1698,  0.0990,  0.2765,  0.1250,
           0.0383,  0.1622,  0.3564,  0.1914,  0.0988]],

        [[-0.3225, -0.0297,  0.1515, -0.0157, -0.1391, -0.0034,  0.1848,
           0.0149, -0.1116, -0.2027, -0.0108, -0.1837, -0.3050, -0.2880,
          -0.1288, -0.2876, -0.4010, -0.3034, -0.1275, -0.2971, -0.4181,
          -0.0650,  0.1162, -0.0527, -0.1805, -0.2074, -0.0260, -0.1906,
          -0.3150, -0.1045,  0.0785, -0.0955, -0.2210]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4018, -0.1071,  0.0882, -0.0812, -0.1992, -0.0766,  0.1216,
          -0.0441, -0.1637, -0.2787, -0.0826, -0.2503, -0.3704, -0.3799,
          -0.1996, -0.3618, -0.4717, -0.3868, -0.1893, -0.3622, -0.4656,
          -0.1447,  0.0523, -0.1161, -0.2373, -0.2859, -0.0862, -0.2568,
          -0.3703, -0.1992, -0.0058, -0.1732, -0.2962]],

        [[ 0.1658,  0.4220,  0.6244,  0.4561,  0.3679,  0.4721,  0.6401,
           0.4918,  0.4062,  0.2691,  0.4525,  0.2929,  0.2041,  0.1726,
           0.3687,  0.2050,  0.1157,  0.1912,  0.3855,  0.2222,  0.1432,
           0.4199,  0.6044,  0.4480,  0.3536,  0.2758,  0.4495,  0.3020,
           0.2192,  0.3379,  0.5296,  0.3671,  0.2800]],

        [[-0.1730,  0.1184,  0.2968,  0.1344,  0.0133,  0.1457,  0.3278,
           0.1639,  0.0390, -0.0503,  0.1401, -0.0293, -0.1499, -0.1369,
           0.0242, -0.1366, -0.2481, -0.1545,  0.0181, -0.1497, -0.2730,
           0.0891,  0.2669,  0.1011, -0.0248, -0.0598,  0.1170, -0.0417,
          -0.1692,  0.0445,  0.2254,  0.0554, -0.0686]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4178, -0.1223,  0.0721, -0.0971, -0.2146, -0.0927,  0.1056,
          -0.0603, -0.1797, -0.2950, -0.0988, -0.2672, -0.3861, -0.3948,
          -0.2156, -0.3774, -0.4867, -0.4019, -0.2049, -0.3776, -0.4808,
          -0.1608,  0.0359, -0.1325, -0.2536, -0.3017, -0.1022, -0.2731,
          -0.3858, -0.2158, -0.0219, -0.1900, -0.3121]],

        [[ 0.3125,  0.5734,  0.7701,  0.6058,  0.5163,  0.6112,  0.7723,
           0.6286,  0.5430,  0.4154,  0.5937,  0.4359,  0.3478,  0.3214,
           0.5168,  0.3526,  0.2615,  0.3377,  0.5275,  0.3675,  0.2845,
           0.5648,  0.7447,  0.5906,  0.4959,  0.4150,  0.5825,  0.4383,
           0.3552,  0.4833,  0.6673,  0.5091,  0.4228]],

        [[-0.3340, -0.0374,  0.1324, -0.0264, -0.1498, -0.0179,  0.1584,
          -0.0030, -0.1292, -0.2056, -0.0219, -0.1877, -0.3098, -0.2874,
          -0.1314, -0.2887, -0.4002, -0.3077, -0.1393, -0.3014, -0.4215,
          -0.0698,  0.1015, -0.0599, -0.1874, -0.2248, -0.0524, -0.2065,
          -0.3335, -0.1064,  0.0673, -0.0983, -0.2248]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4443, -0.1483,  0.0459, -0.1240, -0.2403, -0.1183,  0.0812,
          -0.0865, -0.2046, -0.3224, -0.1250, -0.2953, -0.4126, -0.4218,
          -0.2423, -0.4046, -0.5122, -0.4277, -0.2300, -0.4024, -0.5051,
          -0.1881,  0.0099, -0.1596, -0.2796, -0.3279, -0.1285, -0.2992,
          -0.4109, -0.2433, -0.0477, -0.2172, -0.3384]],

        [[ 0.3525,  0.6194,  0.8097,  0.6488,  0.5594,  0.6484,  0.8028,
           0.6626,  0.5781,  0.4563,  0.6289,  0.4731,  0.3861,  0.3666,
           0.5579,  0.3930,  0.3039,  0.3795,  0.5644,  0.4043,  0.3222,
           0.6054,  0.7795,  0.6271,  0.5337,  0.4527,  0.6165,  0.4727,
           0.3894,  0.5247,  0.7040,  0.5478,  0.4613]],

        [[-0.2229,  0.0750,  0.2436,  0.0885, -0.0348,  0.0979,  0.2665,
           0.1133, -0.0146, -0.0843,  0.0972, -0.0647, -0.1876, -0.1688,
          -0.0111, -0.1692, -0.2809, -0.1954, -0.0290, -0.1899, -0.3106,
           0.0502,  0.2172,  0.0607, -0.0680, -0.1107,  0.0588, -0.0917,
          -0.2211,  0.0082,  0.1807,  0.0181, -0.1084]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4409, -0.1440,  0.0500, -0.1204, -0.2359, -0.1143,  0.0859,
          -0.0828, -0.2009, -0.3192, -0.1203, -0.2925, -0.4087, -0.4191,
          -0.2391, -0.4022, -0.5091, -0.4238, -0.2261, -0.3981, -0.5022,
          -0.1852,  0.0139, -0.1567, -0.2765, -0.3238, -0.1254, -0.2954,
          -0.4076, -0.2401, -0.0434, -0.2138, -0.3341]],

        [[ 0.4794,  0.7463,  0.9339,  0.7742,  0.6875,  0.7771,  0.9258,
           0.7891,  0.7060,  0.5838,  0.7533,  0.5987,  0.5137,  0.4980,
           0.6895,  0.5238,  0.4369,  0.5120,  0.6941,  0.5350,  0.4540,
           0.7379,  0.9085,  0.7579,  0.6671,  0.5792,  0.7381,  0.5965,
           0.5141,  0.6510,  0.8269,  0.6724,  0.5884]],

        [[-0.1103,  0.1794,  0.3490,  0.1914,  0.0698,  0.2232,  0.3865,
           0.2366,  0.1102,  0.0335,  0.2159,  0.0521, -0.0681, -0.0562,
           0.1086, -0.0565, -0.1670, -0.0750,  0.0942, -0.0692, -0.1872,
           0.1750,  0.3416,  0.1842,  0.0568,  0.0056,  0.1755,  0.0245,
          -0.1014,  0.1293,  0.2994,  0.1367,  0.0131]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4471, -0.1474,  0.0433, -0.1259, -0.2400, -0.1212,  0.0755,
          -0.0917, -0.2100, -0.3237, -0.1246, -0.2979, -0.4131, -0.4229,
          -0.2437, -0.4076, -0.5129, -0.4268, -0.2316, -0.4026, -0.5071,
          -0.1902,  0.0063, -0.1634, -0.2828, -0.3306, -0.1357, -0.3030,
          -0.4167, -0.2454, -0.0494, -0.2202, -0.3394]],

        [[ 0.5850,  0.8535,  1.0466,  0.8849,  0.7950,  0.8918,  1.0452,
           0.9069,  0.8190,  0.6966,  0.8732,  0.7149,  0.6265,  0.6020,
           0.8011,  0.6291,  0.5388,  0.6189,  0.8061,  0.6422,  0.5546,
           0.8491,  1.0257,  0.8712,  0.7767,  0.6916,  0.8570,  0.7110,
           0.6226,  0.7633,  0.9454,  0.7880,  0.7008]],

        [[ 0.0126,  0.2984,  0.4694,  0.3158,  0.1979,  0.3527,  0.5116,
           0.3693,  0.2454,  0.1651,  0.3474,  0.1890,  0.0688,  0.0701,
           0.2387,  0.0736, -0.0348,  0.0469,  0.2167,  0.0533, -0.0620,
           0.3053,  0.4704,  0.3171,  0.1934,  0.1334,  0.3038,  0.1560,
           0.0286,  0.2478,  0.4199,  0.2608,  0.1387]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4170, -0.1172,  0.0690, -0.0969, -0.2085, -0.0959,  0.0961,
          -0.0680, -0.1856, -0.2928, -0.0968, -0.2682, -0.3816, -0.3893,
          -0.2129, -0.3749, -0.4791, -0.3952, -0.2042, -0.3727, -0.4774,
          -0.1612,  0.0312, -0.1354, -0.2542, -0.3029, -0.1139, -0.2771,
          -0.3906, -0.2182, -0.0241, -0.1933, -0.3103]],

        [[ 0.6146,  0.8824,  1.0733,  0.9158,  0.8221,  0.9159,  1.0680,
           0.9333,  0.8447,  0.7246,  0.8999,  0.7445,  0.6542,  0.6274,
           0.8276,  0.6562,  0.5620,  0.6427,  0.8299,  0.6678,  0.5773,
           0.8748,  1.0503,  0.8981,  0.8017,  0.7175,  0.8828,  0.7394,
           0.6494,  0.7888,  0.9670,  0.8133,  0.7243]],

        [[ 0.0383,  0.3210,  0.4942,  0.3405,  0.2242,  0.3842,  0.5436,
           0.4021,  0.2812,  0.1962,  0.3791,  0.2213,  0.1038,  0.0965,
           0.2676,  0.1025, -0.0047,  0.0707,  0.2438,  0.0792, -0.0315,
           0.3340,  0.5001,  0.3479,  0.2259,  0.1624,  0.3351,  0.1867,
           0.0638,  0.2707,  0.4454,  0.2851,  0.1657]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.3443, -0.0462,  0.1347, -0.0258, -0.1369, -0.0288,  0.1558,
          -0.0015, -0.1199, -0.2182, -0.0271, -0.1941, -0.3068, -0.3132,
          -0.1392, -0.2986, -0.4025, -0.3225, -0.1368, -0.3003, -0.4057,
          -0.0892,  0.0972, -0.0633, -0.1831, -0.2337, -0.0516, -0.2085,
          -0.3225, -0.1465,  0.0430, -0.1218, -0.2382]],

        [[ 0.6331,  0.9030,  1.0913,  0.9355,  0.8404,  0.9394,  1.0862,
           0.9535,  0.8652,  0.7457,  0.9180,  0.7643,  0.6729,  0.6475,
           0.8465,  0.6747,  0.5794,  0.6615,  0.8467,  0.6838,  0.5935,
           0.8974,  1.0689,  0.9174,  0.8211,  0.7400,  0.9028,  0.7605,
           0.6690,  0.8095,  0.9860,  0.8327,  0.7431]],

        [[ 0.0500,  0.3298,  0.5074,  0.3511,  0.2361,  0.3914,  0.5546,
           0.4117,  0.2926,  0.2059,  0.3919,  0.2322,  0.1167,  0.1030,
           0.2790,  0.1113,  0.0052,  0.0844,  0.2623,  0.0957, -0.0128,
           0.3409,  0.5115,  0.3575,  0.2364,  0.1717,  0.3477,  0.1977,
           0.0785,  0.2805,  0.4571,  0.2958,  0.1781]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2665,  0.0281,  0.2045,  0.0510, -0.0625,  0.0409,  0.2200,
           0.0694, -0.0528, -0.1382,  0.0469, -0.1138, -0.2285, -0.2323,
          -0.0616, -0.2150, -0.3223, -0.2483, -0.0674, -0.2250, -0.3344,
          -0.0145,  0.1668,  0.0141, -0.1103, -0.1607,  0.0141, -0.1361,
          -0.2526, -0.0692,  0.1172, -0.0422, -0.1605]],

        [[ 0.6465,  0.9175,  1.1121,  0.9517,  0.8552,  0.9694,  1.1202,
           0.9846,  0.8960,  0.7649,  0.9427,  0.7857,  0.6922,  0.6567,
           0.8621,  0.6861,  0.5876,  0.6732,  0.8647,  0.6968,  0.6057,
           0.9198,  1.0961,  0.9405,  0.8438,  0.7641,  0.9329,  0.7865,
           0.6934,  0.8251,  1.0057,  0.8488,  0.7586]],

        [[ 0.0922,  0.3673,  0.5454,  0.3870,  0.2729,  0.4507,  0.6113,
           0.4700,  0.3507,  0.2516,  0.4393,  0.2772,  0.1621,  0.1460,
           0.3242,  0.1523,  0.0481,  0.1284,  0.3067,  0.1368,  0.0320,
           0.3946,  0.5648,  0.4092,  0.2897,  0.2221,  0.3994,  0.2469,
           0.1279,  0.3244,  0.5023,  0.3380,  0.2213]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2436,  0.0487,  0.2215,  0.0725, -0.0427,  0.0572,  0.2318,
           0.0877, -0.0377, -0.1137,  0.0670, -0.0889, -0.2050, -0.2073,
          -0.0387, -0.1878, -0.2973, -0.2271, -0.0483, -0.2012, -0.3104,
           0.0057,  0.1831,  0.0370, -0.0912, -0.1402,  0.0302, -0.1152,
          -0.2307, -0.0472,  0.1356, -0.0197, -0.1391]],

        [[ 0.6992,  0.9717,  1.1693,  1.0068,  0.9079,  1.0296,  1.1827,
           1.0455,  0.9534,  0.8225,  1.0040,  0.8444,  0.7478,  0.7090,
           0.9188,  0.7399,  0.6375,  0.7277,  0.9221,  0.7518,  0.6557,
           0.9776,  1.1569,  0.9991,  0.8995,  0.8216,  0.9920,  0.8444,
           0.7466,  0.8836,  1.0674,  0.9083,  0.8160]],

        [[ 0.0769,  0.3512,  0.5246,  0.3702,  0.2576,  0.4232,  0.5794,
           0.4426,  0.3252,  0.2336,  0.4159,  0.2588,  0.1448,  0.1310,
           0.3049,  0.1374,  0.0348,  0.1101,  0.2845,  0.1196,  0.0166,
           0.3719,  0.5372,  0.3866,  0.2690,  0.2010,  0.3744,  0.2262,
           0.1089,  0.3041,  0.4778,  0.3181,  0.2018]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1810,  0.1067,  0.2761,  0.1312,  0.0181,  0.1151,  0.2828,
           0.1452,  0.0218, -0.0498,  0.1262, -0.0248, -0.1390, -0.1410,
           0.0255, -0.1209, -0.2287, -0.1638,  0.0114, -0.1383, -0.2444,
           0.0690,  0.2407,  0.1002, -0.0264, -0.0803,  0.0856, -0.0552,
          -0.1683,  0.0131,  0.1916,  0.0402, -0.0773]],

        [[ 0.7625,  1.0321,  1.2336,  1.0697,  0.9703,  1.1046,  1.2594,
           1.1223,  1.0296,  0.8879,  1.0729,  0.9125,  0.8143,  0.7716,
           0.9862,  0.8057,  0.7009,  0.7930,  0.9905,  0.8187,  0.7207,
           1.0482,  1.2305,  1.0715,  0.9720,  0.8919,  1.0647,  0.9163,
           0.8165,  0.9446,  1.1300,  0.9704,  0.8781]],

        [[ 0.1320,  0.4036,  0.5806,  0.4254,  0.3135,  0.4810,  0.6382,
           0.5032,  0.3865,  0.2904,  0.4746,  0.3168,  0.2044,  0.1809,
           0.3598,  0.1905,  0.0885,  0.1615,  0.3401,  0.1739,  0.0734,
           0.4267,  0.5948,  0.4445,  0.3272,  0.2580,  0.4341,  0.2845,
           0.1700,  0.3563,  0.5330,  0.3725,  0.2578]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0975,  0.1859,  0.3557,  0.2140,  0.0973,  0.1939,  0.3597,
           0.2276,  0.1001,  0.0351,  0.2106,  0.0635, -0.0545, -0.0597,
           0.1078, -0.0362, -0.1478, -0.0848,  0.0902, -0.0564, -0.1658,
           0.1505,  0.3210,  0.1850,  0.0547,  0.0029,  0.1681,  0.0308,
          -0.0856,  0.0973,  0.2745,  0.1267,  0.0054]],

        [[ 0.7893,  1.0576,  1.2582,  1.0954,  0.9938,  1.1311,  1.2853,
           1.1504,  1.0553,  0.9146,  1.0994,  0.9394,  0.8403,  0.7979,
           1.0128,  0.8317,  0.7260,  0.8187,  1.0162,  0.8452,  0.7453,
           1.0747,  1.2567,  1.0992,  0.9974,  0.9183,  1.0920,  0.9435,
           0.8421,  0.9709,  1.1557,  0.9974,  0.9033]],

        [[ 0.1362,  0.4078,  0.5895,  0.4316,  0.3212,  0.4839,  0.6412,
           0.5064,  0.3914,  0.2939,  0.4805,  0.3197,  0.2105,  0.1765,
           0.3622,  0.1882,  0.0877,  0.1649,  0.3483,  0.1783,  0.0815,
           0.4252,  0.5965,  0.4445,  0.3282,  0.2631,  0.4417,  0.2889,
           0.1784,  0.3576,  0.5373,  0.3740,  0.2626]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0743,  0.2070,  0.3752,  0.2373,  0.1177,  0.2115,  0.3761,
           0.2476,  0.1183,  0.0600,  0.2334,  0.0904, -0.0296, -0.0361,
           0.1302, -0.0103, -0.1245, -0.0645,  0.1102, -0.0335, -0.1446,
           0.1706,  0.3391,  0.2075,  0.0746,  0.0234,  0.1882,  0.0537,
          -0.0637,  0.1213,  0.2960,  0.1517,  0.0284]],

        [[ 0.7618,  1.0333,  1.2381,  1.0717,  0.9686,  1.1109,  1.2682,
           1.1289,  1.0323,  0.8910,  1.0794,  0.9165,  0.8141,  0.7686,
           0.9850,  0.8024,  0.6940,  0.7914,  0.9911,  0.8164,  0.7140,
           1.0500,  1.2349,  1.0732,  0.9703,  0.8956,  1.0712,  0.9200,
           0.8153,  0.9485,  1.1373,  0.9752,  0.8792]],

        [[ 0.1783,  0.4522,  0.6339,  0.4764,  0.3641,  0.5266,  0.6821,
           0.5487,  0.4326,  0.3399,  0.5260,  0.3642,  0.2551,  0.2160,
           0.4034,  0.2277,  0.1256,  0.2032,  0.3875,  0.2165,  0.1192,
           0.4654,  0.6363,  0.4848,  0.3664,  0.3068,  0.4857,  0.3309,
           0.2211,  0.3987,  0.5795,  0.4148,  0.3037]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0486,  0.2318,  0.3971,  0.2623,  0.1416,  0.2309,  0.3937,
           0.2685,  0.1384,  0.0873,  0.2586,  0.1182, -0.0022, -0.0086,
           0.1552,  0.0171, -0.0986, -0.0407,  0.1319, -0.0098, -0.1216,
           0.1931,  0.3592,  0.2307,  0.0963,  0.0458,  0.2094,  0.0766,
          -0.0406,  0.1462,  0.3183,  0.1761,  0.0523]],

        [[ 0.7215,  0.9871,  1.1945,  1.0296,  0.9242,  1.0661,  1.2285,
           1.0909,  0.9915,  0.8480,  1.0421,  0.8794,  0.7750,  0.7232,
           0.9457,  0.7626,  0.6503,  0.7523,  0.9570,  0.7838,  0.6786,
           1.0048,  1.1944,  1.0341,  0.9281,  0.8545,  1.0362,  0.8857,
           0.7796,  0.9056,  1.0963,  0.9361,  0.8389]],

        [[ 0.1700,  0.4479,  0.6222,  0.4708,  0.3539,  0.5100,  0.6581,
           0.5295,  0.4100,  0.3336,  0.5128,  0.3562,  0.2432,  0.2077,
           0.3891,  0.2174,  0.1119,  0.1870,  0.3644,  0.1983,  0.0984,
           0.4508,  0.6144,  0.4675,  0.3458,  0.2942,  0.4670,  0.3164,
           0.2031,  0.3889,  0.5633,  0.4033,  0.2884]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.0301,  0.3058,  0.4732,  0.3400,  0.2177,  0.3073,  0.4680,
           0.3468,  0.2162,  0.1684,  0.3392,  0.2014,  0.0797,  0.0645,
           0.2321,  0.0949, -0.0237,  0.0314,  0.2065,  0.0661, -0.0468,
           0.2693,  0.4351,  0.3096,  0.1740,  0.1251,  0.2888,  0.1579,
           0.0401,  0.2252,  0.3979,  0.2576,  0.1332]],

        [[ 0.7009,  0.9681,  1.1751,  1.0098,  0.9036,  1.0459,  1.2080,
           1.0719,  0.9687,  0.8272,  1.0200,  0.8579,  0.7518,  0.7069,
           0.9260,  0.7457,  0.6321,  0.7301,  0.9323,  0.7607,  0.6518,
           0.9858,  1.1744,  1.0161,  0.9075,  0.8348,  1.0156,  0.8642,
           0.7550,  0.8820,  1.0704,  0.9122,  0.8128]],

        [[ 0.1882,  0.4727,  0.6483,  0.4959,  0.3743,  0.5293,  0.6783,
           0.5498,  0.4254,  0.3542,  0.5343,  0.3768,  0.2592,  0.2193,
           0.4041,  0.2302,  0.1218,  0.1988,  0.3777,  0.2118,  0.1094,
           0.4682,  0.6332,  0.4857,  0.3605,  0.3125,  0.4868,  0.3352,
           0.2175,  0.4132,  0.5866,  0.4272,  0.3070]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[0.1162, 0.3926, 0.5613, 0.4258, 0.3034, 0.4079, 0.5657, 0.4453,
          0.3148, 0.2629, 0.4348, 0.2958, 0.1733, 0.1545, 0.3236, 0.1825,
          0.0634, 0.1192, 0.2943, 0.1506, 0.0375, 0.3682, 0.5323, 0.4053,
          0.2705, 0.2173, 0.3816, 0.2490, 0.1299, 0.3196, 0.4911, 0.3489,
          0.2252]],

        [[0.7234, 0.9882, 1.1964, 1.0329, 0.9224, 1.0774, 1.2410, 1.1047,
          1.0004, 0.8515, 1.0469, 0.8867, 0.7756, 0.7260, 0.9474, 0.7666,
          0.6493, 0.7514, 0.9553, 0.7835, 0.6731, 1.0116, 1.2017, 1.0421,
          0.9327, 0.8619, 1.0449, 0.8957, 0.7826, 0.9039, 1.0925, 0.9355,
          0.8325]],

        [[0.2519, 0.5350, 0.7076, 0.5602, 0.4366, 0.5935, 0.7364, 0.6132,
          0.4861, 0.4190, 0.5928, 0.4412, 0.3212, 0.2830, 0.4667, 0.2961,
          0.1856, 0.2576, 0.4332, 0.2711, 0.1673, 0.5308, 0.6918, 0.5492,
          0.4212, 0.3793, 0.5479, 0.4008, 0.2815, 0.4740, 0.6435, 0.4894,
          0.3674]]], grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[0.1490, 0.4221, 0.5876, 0.4574, 0.3296, 0.4308, 0.5868, 0.4711,
          0.3381, 0.2949, 0.4641, 0.3304, 0.2040, 0.1844, 0.3526, 0.2151,
          0.0913, 0.1456, 0.3189, 0.1810, 0.0628, 0.3932, 0.5548, 0.4325,
          0.2949, 0.2454, 0.4097, 0.2809, 0.1583, 0.3546, 0.5203, 0.3848,
          0.2569]],

        [[0.6707, 0.9374, 1.1459, 0.9820, 0.8708, 1.0235, 1.1896, 1.0537,
          0.9439, 0.7998, 0.9964, 0.8363, 0.7220, 0.6732, 0.8940, 0.7137,
          0.5946, 0.6995, 0.9025, 0.7303, 0.6170, 0.9565, 1.1479, 0.9886,
          0.8762, 0.8143, 0.9988, 0.8474, 0.7303, 0.8527, 1.0404, 0.8849,
          0.7795]],

        [[0.2594, 0.5515, 0.7183, 0.5723, 0.4506, 0.6027, 0.7393, 0.6147,
          0.4885, 0.4327, 0.6013, 0.4494, 0.3299, 0.2916, 0.4691, 0.3010,
          0.1905, 0.2603, 0.4299, 0.2682, 0.1638, 0.5370, 0.6918, 0.5493,
          0.4224, 0.3885, 0.5504, 0.4032, 0.2820, 0.4773, 0.6458, 0.4902,
          0.3697]]], grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[0.1816, 0.4500, 0.6173, 0.4875, 0.3589, 0.4622, 0.6189, 0.5053,
          0.3705, 0.3272, 0.4980, 0.3643, 0.2389, 0.2115, 0.3821, 0.2447,
          0.1210, 0.1752, 0.3507, 0.2131, 0.0961, 0.4207, 0.5836, 0.4627,
          0.3234, 0.2797, 0.4456, 0.3167, 0.1961, 0.3832, 0.5499, 0.4139,
          0.2863]],

        [[0.7412, 0.9992, 1.2097, 1.0483, 0.9343, 1.0936, 1.2615, 1.1285,
          1.0155, 0.8682, 1.0675, 0.9103, 0.7913, 0.7377, 0.9625, 0.7819,
          0.6597, 0.7697, 0.9747, 0.8033, 0.6859, 1.0235, 1.2177, 1.0597,
          0.9448, 0.8882, 1.0761, 0.9261, 0.8039, 0.9205, 1.1092, 0.9569,
          0.8478]],

        [[0.3087, 0.6038, 0.7692, 0.6256, 0.4990, 0.6474, 0.7831, 0.6615,
          0.5305, 0.4821, 0.6483, 0.4990, 0.3753, 0.3390, 0.5177, 0.3497,
          0.2356, 0.3058, 0.4748, 0.3154, 0.2070, 0.5845, 0.7388, 0.5986,
          0.4677, 0.4359, 0.5968, 0.4509, 0.3258, 0.5329, 0.6976, 0.5460,
          0.4209]]], grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
kb_values.shape:torch.Size([3, 33])
debug: kb_values: torch.Size([3, 26, 33])
debug: kb_probs: torch.Size([3, 26, 33])
filled v=torch.Size([3, 26, 2695]) in 0.14174175262451172 seconds
v:tensor([[[-0.1767,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1819,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1829,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.1162,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1490,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1816,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.2691,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.4415,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.5574,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.7234,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.6707,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.7412,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.0338,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0561,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1243,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.2519,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.2594,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.3087,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],
       grad_fn=<CopySlices>)
(3, 26)
proc_batch: Hypothesis: ['trouble', 'ahlambra', 'appointments,', '-', '580', '-', '580', 'area', 'turn', "chu's,", 'garage,', 'one,', 'ravenswood_shopping_center_distance', 'one,', 'ravenswood_shopping_center_distance', 'ravenswood_shopping_center_distance', 'garage,', '-', 'garage,', 'one,', '-', 'amaranta', 'garage,', '-', 'driver', 'garage,']

----------TRN FWD PASS: END current batch----------

batch.kbsrc:  (tensor([[  0,   3,   1,   1,   1,   1,   1],
        [150,  24, 156,   1,   8,   3,   1],
        [150,  24, 156,   1,  10,   3,   1],
        [150,  24, 156,   1,   9,   3,   1],
        [150,  24, 156,   1,   6,   3,   1],
        [262,   1,   8,   3,   1,   1,   1],
        [262,   1,  10,   3,   1,   1,   1],
        [262,   1,   9,   3,   1,   1,   1],
        [262,   1,   6,   3,   1,   1,   1],
        [ 42,  57,  43,   1,   8,   3,   1],
        [ 42,  57,  43,   1,  10,   3,   1],
        [ 42,  57,  43,   1,   9,   3,   1],
        [ 42,  57,  43,   1,   6,   3,   1],
        [163,   1,   8,   3,   1,   1,   1],
        [163,   1,  10,   3,   1,   1,   1],
        [163,   1,   9,   3,   1,   1,   1],
        [163,   1,   6,   3,   1,   1,   1],
        [196,   1,   8,   3,   1,   1,   1],
        [196,   1,  10,   3,   1,   1,   1],
        [196,   1,   9,   3,   1,   1,   1],
        [196,   1,   6,   3,   1,   1,   1],
        [ 60,  61,  66, 155,   1,   8,   3],
        [ 60,  61,  66, 155,   1,  10,   3],
        [ 60,  61,  66, 155,   1,   9,   3],
        [ 60,  61,  66, 155,   1,   6,   3],
        [ 42, 101, 160,   1,   8,   3,   1],
        [ 42, 101, 160,   1,  10,   3,   1],
        [ 42, 101, 160,   1,   9,   3,   1],
        [ 42, 101, 160,   1,   6,   3,   1],
        [ 60,  61, 146, 149,   1,   8,   3],
        [ 60,  61, 146, 149,   1,  10,   3],
        [ 60,  61, 146, 149,   1,   9,   3],
        [ 60,  61, 146, 149,   1,   6,   3]]), tensor([2, 6, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 7,
        7, 6, 6, 6, 6, 7, 7, 7, 7])) <class 'tuple'>
batch.kbtrg:  (tensor([[  2,   0,   3],
        [  2, 404,   3],
        [  2, 406,   3],
        [  2, 405,   3],
        [  2, 403,   3],
        [  2, 627,   3],
        [  2, 629,   3],
        [  2, 628,   3],
        [  2, 626,   3],
        [  2, 470,   3],
        [  2, 472,   3],
        [  2, 471,   3],
        [  2, 469,   3],
        [  2, 458,   3],
        [  2, 460,   3],
        [  2, 459,   3],
        [  2, 457,   3],
        [  2, 493,   3],
        [  2, 495,   3],
        [  2, 494,   3],
        [  2, 492,   3],
        [  2, 360,   3],
        [  2, 362,   3],
        [  2, 361,   3],
        [  2, 359,   3],
        [  2, 376,   3],
        [  2, 378,   3],
        [  2, 377,   3],
        [  2, 375,   3],
        [  2, 364,   3],
        [  2, 366,   3],
        [  2, 365,   3],
        [  2, 363,   3]]), tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3])) <class 'tuple'>

----------TRN FWD PASS: START current batch----------

proc_batch: batch.src: ['where', 'is', 'the', 'nearest', 'gas', 'station?', '@dot', 'there', 'is', 'a', '76', '4', 'miles', 'away.', '@dot', 'what', 'is', 'the', 'address?', '@dot', 'the', '76', 'gas', 'station', 'is', 'located', 'at', '91', 'el', 'camino', 'real.', 'it', 'is', '4', 'miles', 'away', 'through', 'moderate', 'traffic', '@dot', 'thanks!']
proc_batch: batch.trg: ['anytime!']
proc_batch: kbkeys: [['<unk>'], ['menlo_park_thursday', 'what', 'compton_sunday', '<pad>', 'at'], ['menlo_park_thursday', 'what', 'compton_sunday', '<pad>', 'in'], ['menlo_park_thursday', 'what', 'compton_sunday', '<pad>', 'to'], ['menlo_park_thursday', 'what', 'compton_sunday', '<pad>', 'you'], ['low', '<pad>', 'at'], ['low', '<pad>', 'in'], ['low', '<pad>', 'to'], ['low', '<pad>', 'you'], ['do', 'football_activity_time', 'welcome', '<pad>', 'at'], ['do', 'football_activity_time', 'welcome', '<pad>', 'in'], ['do', 'football_activity_time', 'welcome', '<pad>', 'to'], ['do', 'football_activity_time', 'welcome', '<pad>', 'you'], ['durham_sunday', '<pad>', 'at'], ['durham_sunday', '<pad>', 'in'], ['durham_sunday', '<pad>', 'to'], ['durham_sunday', '<pad>', 'you'], ['oakland_wednesday', '<pad>', 'at'], ['oakland_wednesday', '<pad>', 'in'], ['oakland_wednesday', '<pad>', 'to'], ['oakland_wednesday', '<pad>', 'you'], ['dentist_appointment_party', 'dentist_appointment_room', 'new_york_sunday', 'compton_saturday', '<pad>', 'at'], ['dentist_appointment_party', 'dentist_appointment_room', 'new_york_sunday', 'compton_saturday', '<pad>', 'in'], ['dentist_appointment_party', 'dentist_appointment_room', 'new_york_sunday', 'compton_saturday', '<pad>', 'to'], ['dentist_appointment_party', 'dentist_appointment_room', 'new_york_sunday', 'compton_saturday', '<pad>', 'you'], ['do', 'grand_rapids_monday', 'durham_friday', '<pad>', 'at'], ['do', 'grand_rapids_monday', 'durham_friday', '<pad>', 'in'], ['do', 'grand_rapids_monday', 'durham_friday', '<pad>', 'to'], ['do', 'grand_rapids_monday', 'durham_friday', '<pad>', 'you'], ['dentist_appointment_party', 'dentist_appointment_room', 'menlo_park_friday', 'menlo_park_sunday', '<pad>', 'at'], ['dentist_appointment_party', 'dentist_appointment_room', 'menlo_park_friday', 'menlo_park_sunday', '<pad>', 'in'], ['dentist_appointment_party', 'dentist_appointment_room', 'menlo_park_friday', 'menlo_park_sunday', '<pad>', 'to'], ['dentist_appointment_party', 'dentist_appointment_room', 'menlo_park_friday', 'menlo_park_sunday', '<pad>', 'you']]
proc_batch: kbvals: [['<s>', '<unk>'], ['<s>', 'town_and_country_distance'], ['<s>', 'town_and_country_traffic_info'], ['<s>', 'town_and_country_poi_type'], ['<s>', 'town_and_country_address'], ['<s>', '76_distance'], ['<s>', '76_traffic_info'], ['<s>', '76_poi_type'], ['<s>', '76_address'], ['<s>', 'stanford_shopping_center_distance'], ['<s>', 'stanford_shopping_center_traffic_info'], ['<s>', 'stanford_shopping_center_poi_type'], ['<s>', 'stanford_shopping_center_address'], ['<s>', 'teavana_distance'], ['<s>', 'teavana_traffic_info'], ['<s>', 'teavana_poi_type'], ['<s>', 'teavana_address'], ['<s>', 'dominos_distance'], ['<s>', 'dominos_traffic_info'], ['<s>', 'dominos_poi_type'], ['<s>', 'dominos_address'], ['<s>', 'palo_alto_garage_r_distance'], ['<s>', 'palo_alto_garage_r_traffic_info'], ['<s>', 'palo_alto_garage_r_poi_type'], ['<s>', 'palo_alto_garage_r_address'], ['<s>', 'stanford_express_care_distance'], ['<s>', 'stanford_express_care_traffic_info'], ['<s>', 'stanford_express_care_poi_type'], ['<s>', 'stanford_express_care_address'], ['<s>', 'palo_alto_medical_foundation_distance'], ['<s>', 'palo_alto_medical_foundation_traffic_info'], ['<s>', 'palo_alto_medical_foundation_poi_type'], ['<s>', 'palo_alto_medical_foundation_address']]
decoder.forward() unroll_steps in model.forward
is 20, which is 1st dim of trg_input=torch.Size([3, 20])
batch.trg_input: ['<s>', 'anytime!']
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1011, -0.0061,  0.1898,  0.0219, -0.0985,  0.1917,  0.3890,
           0.2218,  0.0983,  0.0485,  0.2425,  0.0847, -0.0378, -0.1227,
           0.0741, -0.0886, -0.2138,  0.1431,  0.3374,  0.1756,  0.0479,
           0.1905,  0.3792,  0.2126,  0.0964,  0.0801,  0.2734,  0.1132,
          -0.0169,  0.3027,  0.5022,  0.3382,  0.2180]],

        [[-0.1981, -0.0994,  0.0988, -0.0703, -0.1929,  0.0961,  0.2956,
           0.1268,  0.0079, -0.0385,  0.1622, -0.0041, -0.1267, -0.2088,
          -0.0070, -0.1760, -0.3022,  0.0547,  0.2508,  0.0847, -0.0381,
           0.0935,  0.2838,  0.1157,  0.0068,  0.0011,  0.1922,  0.0323,
          -0.1002,  0.2154,  0.4131,  0.2480,  0.1257]],

        [[-0.0495,  0.0268,  0.2349,  0.0684, -0.0427,  0.2358,  0.4421,
           0.2726,  0.1586,  0.0984,  0.3101,  0.1369,  0.0282, -0.0641,
           0.1476, -0.0233, -0.1470,  0.1939,  0.4048,  0.2340,  0.1105,
           0.2263,  0.4277,  0.2596,  0.1510,  0.1481,  0.3498,  0.1838,
           0.0586,  0.3488,  0.5546,  0.3904,  0.2791]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0988, -0.0043,  0.1916,  0.0236, -0.0963,  0.1929,  0.3910,
           0.2235,  0.0999,  0.0505,  0.2446,  0.0870, -0.0351, -0.1206,
           0.0759, -0.0861, -0.2112,  0.1445,  0.3399,  0.1774,  0.0496,
           0.1919,  0.3818,  0.2142,  0.0979,  0.0818,  0.2747,  0.1148,
          -0.0152,  0.3040,  0.5042,  0.3400,  0.2200]],

        [[-0.2242, -0.1252,  0.0735, -0.0948, -0.2195,  0.0725,  0.2702,
           0.1018, -0.0194, -0.0637,  0.1318, -0.0321, -0.1546, -0.2366,
          -0.0371, -0.2056, -0.3310,  0.0284,  0.2244,  0.0573, -0.0655,
           0.0721,  0.2644,  0.0960, -0.0179, -0.0260,  0.1663,  0.0063,
          -0.1272,  0.1888,  0.3864,  0.2209,  0.0973]],

        [[-0.1384, -0.0506,  0.1558, -0.0145, -0.1255,  0.1457,  0.3581,
           0.1830,  0.0709,  0.0127,  0.2298,  0.0508, -0.0576, -0.1476,
           0.0652, -0.1097, -0.2306,  0.1080,  0.3249,  0.1471,  0.0263,
           0.1394,  0.3442,  0.1699,  0.0644,  0.0624,  0.2634,  0.0935,
          -0.0283,  0.2674,  0.4782,  0.3062,  0.1963]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1019, -0.0060,  0.1891,  0.0211, -0.0987,  0.1895,  0.3880,
           0.2202,  0.0964,  0.0487,  0.2430,  0.0850, -0.0370, -0.1229,
           0.0729, -0.0884, -0.2137,  0.1412,  0.3372,  0.1742,  0.0461,
           0.1884,  0.3788,  0.2105,  0.0938,  0.0793,  0.2709,  0.1113,
          -0.0186,  0.3012,  0.5016,  0.3371,  0.2170]],

        [[-0.2189, -0.1174,  0.0817, -0.0863, -0.2123,  0.0790,  0.2772,
           0.1076, -0.0145, -0.0571,  0.1364, -0.0268, -0.1491, -0.2322,
          -0.0335, -0.2025, -0.3264,  0.0338,  0.2316,  0.0622, -0.0596,
           0.0814,  0.2765,  0.1063, -0.0109, -0.0228,  0.1706,  0.0098,
          -0.1228,  0.1925,  0.3920,  0.2242,  0.1016]],

        [[-0.1739, -0.0778,  0.1212, -0.0447, -0.1589,  0.1096,  0.3174,
           0.1454,  0.0314, -0.0232,  0.1892,  0.0141, -0.1004, -0.1804,
           0.0239, -0.1451, -0.2681,  0.0697,  0.2818,  0.1069, -0.0153,
           0.1011,  0.3011,  0.1287,  0.0230,  0.0269,  0.2194,  0.0549,
          -0.0670,  0.2327,  0.4402,  0.2677,  0.1572]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1140, -0.0170,  0.1772,  0.0094, -0.1106,  0.1768,  0.3756,
           0.2076,  0.0834,  0.0381,  0.2320,  0.0737, -0.0480, -0.1341,
           0.0605, -0.1000, -0.2250,  0.1284,  0.3248,  0.1612,  0.0332,
           0.1756,  0.3664,  0.1973,  0.0804,  0.0678,  0.2582,  0.0988,
          -0.0308,  0.2894,  0.4898,  0.3249,  0.2047]],

        [[-0.1455, -0.0445,  0.1564, -0.0132, -0.1380,  0.1497,  0.3509,
           0.1788,  0.0579,  0.0131,  0.2095,  0.0456, -0.0781, -0.1626,
           0.0361, -0.1330, -0.2537,  0.1038,  0.3032,  0.1322,  0.0143,
           0.1536,  0.3505,  0.1783,  0.0625,  0.0442,  0.2387,  0.0765,
          -0.0521,  0.2599,  0.4634,  0.2923,  0.1723]],

        [[-0.1862, -0.0837,  0.1079, -0.0525, -0.1695,  0.0965,  0.2996,
           0.1310,  0.0137, -0.0333,  0.1716,  0.0021, -0.1147, -0.1928,
           0.0036, -0.1586, -0.2819,  0.0521,  0.2604,  0.0882, -0.0348,
           0.0862,  0.2840,  0.1124,  0.0033,  0.0130,  0.1984,  0.0391,
          -0.0837,  0.2209,  0.4243,  0.2547,  0.1428]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1126, -0.0140,  0.1795,  0.0115, -0.1086,  0.1784,  0.3766,
           0.2086,  0.0844,  0.0414,  0.2344,  0.0760, -0.0450, -0.1316,
           0.0619, -0.0979, -0.2224,  0.1293,  0.3249,  0.1614,  0.0337,
           0.1768,  0.3671,  0.1977,  0.0806,  0.0704,  0.2591,  0.0998,
          -0.0292,  0.2917,  0.4914,  0.3268,  0.2065]],

        [[-0.1043, -0.0058,  0.1974,  0.0283, -0.0949,  0.1874,  0.3929,
           0.2183,  0.0979,  0.0522,  0.2501,  0.0851, -0.0346, -0.1252,
           0.0748, -0.0964, -0.2131,  0.1418,  0.3449,  0.1715,  0.0553,
           0.1975,  0.3999,  0.2257,  0.1066,  0.0763,  0.2765,  0.1106,
          -0.0140,  0.2911,  0.4995,  0.3250,  0.2093]],

        [[-0.1865, -0.0839,  0.1091, -0.0505, -0.1675,  0.0908,  0.2946,
           0.1264,  0.0089, -0.0308,  0.1725,  0.0032, -0.1106, -0.1923,
           0.0038, -0.1561, -0.2757,  0.0430,  0.2550,  0.0809, -0.0388,
           0.0765,  0.2795,  0.1056, -0.0036,  0.0148,  0.1994,  0.0408,
          -0.0801,  0.2243,  0.4271,  0.2601,  0.1468]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1385, -0.0380,  0.1545, -0.0133, -0.1336,  0.1528,  0.3501,
           0.1825,  0.0583,  0.0183,  0.2095,  0.0512, -0.0684, -0.1564,
           0.0357, -0.1234, -0.2472,  0.1028,  0.2982,  0.1341,  0.0067,
           0.1509,  0.3413,  0.1717,  0.0539,  0.0458,  0.2330,  0.0739,
          -0.0545,  0.2666,  0.4651,  0.3010,  0.1804]],

        [[-0.0059,  0.0901,  0.2944,  0.1248,  0.0043,  0.2827,  0.4908,
           0.3150,  0.1961,  0.1489,  0.3492,  0.1830,  0.0665, -0.0311,
           0.1713, -0.0015, -0.1148,  0.2377,  0.4426,  0.2692,  0.1552,
           0.2952,  0.4994,  0.3251,  0.2055,  0.1688,  0.3719,  0.2034,
           0.0824,  0.3834,  0.5926,  0.4186,  0.3058]],

        [[-0.2324, -0.1263,  0.0644, -0.0929, -0.2103,  0.0418,  0.2442,
           0.0780, -0.0411, -0.0723,  0.1271, -0.0398, -0.1518, -0.2366,
          -0.0433, -0.1997, -0.3171, -0.0089,  0.2037,  0.0295, -0.0881,
           0.0262,  0.2316,  0.0561, -0.0538, -0.0284,  0.1529, -0.0028,
          -0.1236,  0.1788,  0.3795,  0.2153,  0.0998]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1759, -0.0724,  0.1180, -0.0488, -0.1692,  0.1161,  0.3114,
           0.1449,  0.0203, -0.0143,  0.1731,  0.0161, -0.1017, -0.1924,
          -0.0027, -0.1604, -0.2824,  0.0640,  0.2587,  0.0944, -0.0321,
           0.1132,  0.3037,  0.1340,  0.0149,  0.0109,  0.1958,  0.0379,
          -0.0906,  0.2305,  0.4269,  0.2643,  0.1429]],

        [[ 0.1180,  0.2095,  0.4162,  0.2465,  0.1295,  0.4043,  0.6147,
           0.4378,  0.3217,  0.2698,  0.4723,  0.3056,  0.1932,  0.0876,
           0.2912,  0.1188,  0.0092,  0.3556,  0.5603,  0.3889,  0.2780,
           0.4179,  0.6231,  0.4497,  0.3312,  0.2877,  0.4924,  0.3224,
           0.2065,  0.5020,  0.7117,  0.5390,  0.4300]],

        [[-0.1880, -0.0861,  0.1077, -0.0524, -0.1681,  0.0857,  0.2894,
           0.1209,  0.0020, -0.0238,  0.1744,  0.0080, -0.1020, -0.1920,
           0.0021, -0.1545, -0.2709,  0.0358,  0.2499,  0.0741, -0.0430,
           0.0720,  0.2808,  0.1017, -0.0083,  0.0158,  0.1977,  0.0418,
          -0.0785,  0.2210,  0.4232,  0.2579,  0.1429]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-2.0686e-01, -1.0018e-01,  8.7987e-02, -7.7379e-02, -1.9767e-01,
           8.5605e-02,  2.7866e-01,  1.1405e-01, -1.0614e-02, -4.2294e-02,
           1.4163e-01, -1.3099e-02, -1.2971e-01, -2.2242e-01, -3.5440e-02,
          -1.9101e-01, -3.1206e-01,  3.1806e-02,  2.2454e-01,  6.1863e-02,
          -6.4486e-02,  8.2479e-02,  2.7170e-01,  1.0307e-01, -1.6482e-02,
          -1.7894e-02,  1.6428e-01,  8.4067e-03, -1.1963e-01,  1.9932e-01,
           3.9301e-01,  2.3228e-01,  1.1092e-01]],

        [[ 2.1722e-01,  3.0866e-01,  5.0980e-01,  3.4367e-01,  2.2825e-01,
           5.0288e-01,  7.0935e-01,  5.3567e-01,  4.2043e-01,  3.6808e-01,
           5.6802e-01,  4.0493e-01,  2.9319e-01,  1.8493e-01,  3.8637e-01,
           2.1683e-01,  1.0737e-01,  4.5274e-01,  6.5155e-01,  4.8652e-01,
           3.7490e-01,  5.1579e-01,  7.1390e-01,  5.4559e-01,  4.2735e-01,
           3.8724e-01,  5.8949e-01,  4.2004e-01,  3.0706e-01,  5.9748e-01,
           8.0098e-01,  6.3409e-01,  5.2640e-01]],

        [[-2.4827e-01, -1.4277e-01,  4.0850e-02, -1.1063e-01, -2.2615e-01,
           1.7790e-02,  2.1645e-01,  5.2749e-02, -6.5678e-02, -8.4973e-02,
           1.0607e-01, -5.4116e-02, -1.6240e-01, -2.5198e-01, -6.6669e-02,
          -2.1595e-01, -3.2946e-01, -3.5993e-02,  1.7301e-01,  1.2390e-03,
          -1.1300e-01,  6.5593e-04,  2.0595e-01,  2.9382e-02, -8.0339e-02,
          -4.7180e-02,  1.2685e-01, -2.4059e-02, -1.4131e-01,  1.5456e-01,
           3.5113e-01,  1.9027e-01,  7.6835e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1629, -0.0528,  0.1357, -0.0312, -0.1512,  0.1300,  0.3241,
           0.1575,  0.0340,  0.0039,  0.1886,  0.0325, -0.0835, -0.1758,
           0.0101, -0.1457, -0.2655,  0.0762,  0.2678,  0.1048, -0.0200,
           0.1269,  0.3156,  0.1456,  0.0274,  0.0284,  0.2081,  0.0511,
          -0.0744,  0.2456,  0.4390,  0.2773,  0.1570]],

        [[ 0.2279,  0.3200,  0.5165,  0.3544,  0.2416,  0.5126,  0.7172,
           0.5446,  0.4309,  0.3814,  0.5764,  0.4165,  0.3098,  0.1933,
           0.3906,  0.2245,  0.1190,  0.4580,  0.6566,  0.4919,  0.3828,
           0.5237,  0.7229,  0.5535,  0.4355,  0.3983,  0.5964,  0.4290,
           0.3186,  0.6057,  0.8056,  0.6417,  0.5371]],

        [[-0.1285, -0.0292,  0.1512,  0.0023, -0.1071,  0.1339,  0.3277,
           0.1655,  0.0509,  0.0322,  0.2194,  0.0633, -0.0428, -0.1372,
           0.0431, -0.1011, -0.2111,  0.0763,  0.2801,  0.1115,  0.0008,
           0.1133,  0.3144,  0.1386,  0.0334,  0.0653,  0.2347,  0.0869,
          -0.0247,  0.2652,  0.4578,  0.3001,  0.1931]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1222, -0.0096,  0.1800,  0.0103, -0.1076,  0.1703,  0.3668,
           0.1970,  0.0751,  0.0450,  0.2310,  0.0733, -0.0409, -0.1349,
           0.0515, -0.1054, -0.2238,  0.1175,  0.3098,  0.1455,  0.0218,
           0.1704,  0.3606,  0.1877,  0.0704,  0.0694,  0.2495,  0.0902,
          -0.0328,  0.2855,  0.4798,  0.3163,  0.1982]],

        [[ 0.2189,  0.3162,  0.5087,  0.3481,  0.2350,  0.5074,  0.7091,
           0.5377,  0.4240,  0.3781,  0.5708,  0.4111,  0.3046,  0.1851,
           0.3809,  0.2158,  0.1104,  0.4485,  0.6446,  0.4810,  0.3726,
           0.5156,  0.7121,  0.5432,  0.4261,  0.3944,  0.5888,  0.4224,
           0.3115,  0.6047,  0.8002,  0.6390,  0.5333]],

        [[-0.0419,  0.0547,  0.2343,  0.0867, -0.0208,  0.2204,  0.4143,
           0.2526,  0.1393,  0.1161,  0.3028,  0.1479,  0.0444, -0.0538,
           0.1259, -0.0174, -0.1239,  0.1582,  0.3609,  0.1937,  0.0853,
           0.2009,  0.4006,  0.2261,  0.1209,  0.1510,  0.3203,  0.1710,
           0.0652,  0.3469,  0.5405,  0.3829,  0.2798]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1615, -0.0440,  0.1433, -0.0276, -0.1433,  0.1318,  0.3282,
           0.1573,  0.0362,  0.0096,  0.1930,  0.0365, -0.0759, -0.1709,
           0.0135, -0.1424, -0.2598,  0.0785,  0.2706,  0.1050, -0.0173,
           0.1317,  0.3228,  0.1473,  0.0307,  0.0339,  0.2112,  0.0529,
          -0.0703,  0.2475,  0.4403,  0.2774,  0.1591]],

        [[ 0.2413,  0.3445,  0.5294,  0.3735,  0.2612,  0.5310,  0.7266,
           0.5574,  0.4453,  0.4076,  0.5928,  0.4367,  0.3331,  0.2081,
           0.3975,  0.2368,  0.1337,  0.4674,  0.6579,  0.4976,  0.3902,
           0.5341,  0.7253,  0.5588,  0.4425,  0.4173,  0.6056,  0.4403,
           0.3323,  0.6277,  0.8162,  0.6589,  0.5558]],

        [[ 0.0220,  0.1205,  0.3032,  0.1495,  0.0443,  0.2857,  0.4810,
           0.3139,  0.2025,  0.1895,  0.3763,  0.2162,  0.1178,  0.0141,
           0.1960,  0.0479, -0.0534,  0.2231,  0.4273,  0.2540,  0.1508,
           0.2670,  0.4695,  0.2895,  0.1850,  0.2146,  0.3852,  0.2307,
           0.1273,  0.4175,  0.6119,  0.4516,  0.3496]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1411, -0.0226,  0.1661, -0.0075, -0.1206,  0.1512,  0.3505,
           0.1752,  0.0564,  0.0322,  0.2166,  0.0572, -0.0510, -0.1476,
           0.0377, -0.1207, -0.2354,  0.1007,  0.2955,  0.1257,  0.0056,
           0.1543,  0.3495,  0.1687,  0.0527,  0.0545,  0.2326,  0.0709,
          -0.0495,  0.2668,  0.4614,  0.2955,  0.1805]],

        [[ 0.2224,  0.3300,  0.5109,  0.3532,  0.2441,  0.5093,  0.7041,
           0.5334,  0.4234,  0.3873,  0.5745,  0.4177,  0.3112,  0.1949,
           0.3841,  0.2236,  0.1174,  0.4522,  0.6418,  0.4805,  0.3732,
           0.5132,  0.7015,  0.5317,  0.4218,  0.4030,  0.5875,  0.4238,
           0.3148,  0.6123,  0.7996,  0.6411,  0.5388]],

        [[-0.1814, -0.0730,  0.1105, -0.0444, -0.1538,  0.0870,  0.2887,
           0.1199,  0.0069, -0.0073,  0.1835,  0.0225, -0.0799, -0.1826,
           0.0030, -0.1473, -0.2520,  0.0270,  0.2380,  0.0614, -0.0432,
           0.0720,  0.2815,  0.0969, -0.0069,  0.0327,  0.2059,  0.0526,
          -0.0557,  0.2210,  0.4203,  0.2557,  0.1484]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1454, -0.0253,  0.1623, -0.0134, -0.1249,  0.1459,  0.3464,
           0.1684,  0.0509,  0.0267,  0.2105,  0.0502, -0.0563, -0.1496,
           0.0350, -0.1247, -0.2388,  0.0977,  0.2925,  0.1212,  0.0012,
           0.1516,  0.3473,  0.1640,  0.0485,  0.0489,  0.2266,  0.0624,
          -0.0565,  0.2620,  0.4563,  0.2891,  0.1753]],

        [[ 0.1681,  0.2808,  0.4608,  0.3014,  0.1912,  0.4560,  0.6529,
           0.4797,  0.3693,  0.3398,  0.5288,  0.3684,  0.2619,  0.1492,
           0.3381,  0.1764,  0.0697,  0.4018,  0.5936,  0.4287,  0.3218,
           0.4581,  0.6486,  0.4750,  0.3657,  0.3608,  0.5425,  0.3781,
           0.2682,  0.5679,  0.7547,  0.5948,  0.4906]],

        [[ 0.0146,  0.1120,  0.3012,  0.1427,  0.0416,  0.2792,  0.4786,
           0.3077,  0.2001,  0.1875,  0.3785,  0.2141,  0.1205,  0.0083,
           0.1969,  0.0442, -0.0528,  0.2181,  0.4299,  0.2504,  0.1518,
           0.2614,  0.4717,  0.2854,  0.1860,  0.2126,  0.3873,  0.2308,
           0.1297,  0.4128,  0.6099,  0.4476,  0.3479]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1331, -0.0132,  0.1764, -0.0028, -0.1145,  0.1589,  0.3612,
           0.1804,  0.0645,  0.0357,  0.2220,  0.0596, -0.0476, -0.1375,
           0.0501, -0.1119, -0.2285,  0.1131,  0.3086,  0.1361,  0.0148,
           0.1670,  0.3627,  0.1778,  0.0636,  0.0577,  0.2377,  0.0707,
          -0.0485,  0.2746,  0.4697,  0.3014,  0.1867]],

        [[ 0.1225,  0.2357,  0.4132,  0.2556,  0.1479,  0.4068,  0.6033,
           0.4296,  0.3215,  0.2923,  0.4810,  0.3192,  0.2161,  0.1034,
           0.2902,  0.1284,  0.0249,  0.3542,  0.5467,  0.3796,  0.2754,
           0.4096,  0.6004,  0.4249,  0.3184,  0.3150,  0.4943,  0.3292,
           0.2232,  0.5187,  0.7057,  0.5436,  0.4437]],

        [[ 0.0078,  0.1036,  0.2989,  0.1381,  0.0338,  0.2724,  0.4781,
           0.3047,  0.1969,  0.1798,  0.3777,  0.2089,  0.1150,  0.0048,
           0.2001,  0.0430, -0.0535,  0.2119,  0.4301,  0.2469,  0.1493,
           0.2544,  0.4704,  0.2828,  0.1818,  0.2167,  0.3976,  0.2371,
           0.1366,  0.4107,  0.6135,  0.4485,  0.3466]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0548,  0.0621,  0.2537,  0.0733, -0.0376,  0.2357,  0.4396,
           0.2576,  0.1421,  0.1097,  0.2983,  0.1347,  0.0280, -0.0588,
           0.1314, -0.0318, -0.1498,  0.1941,  0.3900,  0.2188,  0.0951,
           0.2459,  0.4416,  0.2575,  0.1421,  0.1333,  0.3157,  0.1460,
           0.0281,  0.3498,  0.5448,  0.3772,  0.2639]],

        [[ 0.1378,  0.2480,  0.4291,  0.2688,  0.1619,  0.4205,  0.6224,
           0.4441,  0.3383,  0.3072,  0.5017,  0.3352,  0.2338,  0.1185,
           0.3090,  0.1453,  0.0433,  0.3669,  0.5647,  0.3927,  0.2913,
           0.4223,  0.6181,  0.4378,  0.3339,  0.3318,  0.5133,  0.3450,
           0.2419,  0.5349,  0.7275,  0.5610,  0.4633]],

        [[ 0.0660,  0.1607,  0.3624,  0.1957,  0.0932,  0.3322,  0.5402,
           0.3625,  0.2573,  0.2395,  0.4411,  0.2658,  0.1751,  0.0629,
           0.2639,  0.1009,  0.0071,  0.2773,  0.4986,  0.3113,  0.2161,
           0.3181,  0.5368,  0.3462,  0.2473,  0.2705,  0.4557,  0.2899,
           0.1912,  0.4726,  0.6765,  0.5090,  0.4084]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0193,  0.0960,  0.2898,  0.1068, -0.0047,  0.2711,  0.4768,
           0.2924,  0.1780,  0.1482,  0.3403,  0.1726,  0.0660, -0.0182,
           0.1761,  0.0093, -0.1101,  0.2328,  0.4307,  0.2573,  0.1331,
           0.2794,  0.4762,  0.2909,  0.1755,  0.1699,  0.3542,  0.1810,
           0.0632,  0.3920,  0.5873,  0.4187,  0.3048]],

        [[ 0.0424,  0.1502,  0.3347,  0.1757,  0.0678,  0.3228,  0.5273,
           0.3498,  0.2427,  0.2120,  0.4091,  0.2405,  0.1409,  0.0228,
           0.2161,  0.0523, -0.0482,  0.2676,  0.4721,  0.2966,  0.1961,
           0.3204,  0.5230,  0.3406,  0.2365,  0.2349,  0.4187,  0.2517,
           0.1467,  0.4438,  0.6403,  0.4728,  0.3733]],

        [[ 0.1434,  0.2340,  0.4420,  0.2732,  0.1701,  0.4141,  0.6261,
           0.4461,  0.3434,  0.3106,  0.5191,  0.3401,  0.2473,  0.1324,
           0.3397,  0.1744,  0.0801,  0.3550,  0.5791,  0.3914,  0.2977,
           0.4002,  0.6210,  0.4302,  0.3353,  0.3482,  0.5382,  0.3702,
           0.2735,  0.5528,  0.7611,  0.5909,  0.4919]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.0460,  0.1587,  0.3538,  0.1703,  0.0569,  0.3361,  0.5420,
           0.3573,  0.2417,  0.2156,  0.4101,  0.2402,  0.1317,  0.0523,
           0.2493,  0.0811, -0.0406,  0.3006,  0.4982,  0.3259,  0.1998,
           0.3415,  0.5371,  0.3533,  0.2367,  0.2356,  0.4211,  0.2463,
           0.1272,  0.4629,  0.6571,  0.4896,  0.3741]],

        [[ 0.0414,  0.1498,  0.3373,  0.1754,  0.0640,  0.3208,  0.5307,
           0.3485,  0.2408,  0.2096,  0.4116,  0.2385,  0.1368,  0.0266,
           0.2225,  0.0565, -0.0443,  0.2654,  0.4746,  0.2938,  0.1943,
           0.3202,  0.5273,  0.3402,  0.2358,  0.2392,  0.4244,  0.2536,
           0.1498,  0.4478,  0.6499,  0.4774,  0.3757]],

        [[ 0.2159,  0.2978,  0.5164,  0.3412,  0.2373,  0.4917,  0.7107,
           0.5265,  0.4260,  0.3772,  0.5966,  0.4099,  0.3160,  0.1936,
           0.4123,  0.2380,  0.1462,  0.4355,  0.6632,  0.4734,  0.3834,
           0.4841,  0.7082,  0.5169,  0.4255,  0.4218,  0.6231,  0.4475,
           0.3524,  0.6264,  0.8410,  0.6664,  0.5671]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.1257,  0.2326,  0.4327,  0.2474,  0.1323,  0.4141,  0.6228,
           0.4364,  0.3213,  0.2966,  0.4976,  0.3230,  0.2135,  0.1384,
           0.3422,  0.1699,  0.0466,  0.3820,  0.5828,  0.4085,  0.2825,
           0.4158,  0.6131,  0.4288,  0.3132,  0.3179,  0.5070,  0.3296,
           0.2099,  0.5515,  0.7486,  0.5796,  0.4631]],

        [[ 0.0180,  0.1324,  0.3151,  0.1572,  0.0435,  0.2990,  0.5053,
           0.3264,  0.2164,  0.1889,  0.3871,  0.2162,  0.1138,  0.0024,
           0.1950,  0.0308, -0.0717,  0.2434,  0.4482,  0.2716,  0.1688,
           0.2991,  0.5016,  0.3189,  0.2113,  0.2163,  0.3985,  0.2284,
           0.1237,  0.4231,  0.6200,  0.4509,  0.3485]],

        [[ 0.1949,  0.2643,  0.4912,  0.3088,  0.2102,  0.4691,  0.6968,
           0.5057,  0.4108,  0.3529,  0.5794,  0.3885,  0.2988,  0.1663,
           0.3913,  0.2114,  0.1248,  0.4145,  0.6484,  0.4535,  0.3696,
           0.4674,  0.6988,  0.5005,  0.4165,  0.3972,  0.6045,  0.4248,
           0.3345,  0.6000,  0.8226,  0.6406,  0.5463]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.1329,  0.2391,  0.4389,  0.2513,  0.1376,  0.4198,  0.6275,
           0.4393,  0.3253,  0.3123,  0.5128,  0.3346,  0.2274,  0.1544,
           0.3594,  0.1837,  0.0629,  0.3894,  0.5915,  0.4133,  0.2903,
           0.4161,  0.6147,  0.4276,  0.3135,  0.3236,  0.5127,  0.3331,
           0.2139,  0.5679,  0.7636,  0.5935,  0.4768]],

        [[-0.0816,  0.0335,  0.2198,  0.0555, -0.0591,  0.1989,  0.4088,
           0.2249,  0.1154,  0.0887,  0.2902,  0.1154,  0.0098, -0.0924,
           0.1035, -0.0652, -0.1679,  0.1488,  0.3587,  0.1750,  0.0744,
           0.2017,  0.4090,  0.2189,  0.1152,  0.1175,  0.3011,  0.1292,
           0.0225,  0.3292,  0.5308,  0.3551,  0.2500]],

        [[ 0.2131,  0.2837,  0.5106,  0.3252,  0.2283,  0.4874,  0.7137,
           0.5196,  0.4248,  0.3760,  0.5991,  0.4070,  0.3199,  0.1908,
           0.4129,  0.2316,  0.1467,  0.4364,  0.6692,  0.4703,  0.3878,
           0.4866,  0.7185,  0.5161,  0.4313,  0.4138,  0.6183,  0.4377,
           0.3469,  0.6186,  0.8393,  0.6568,  0.5627]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.1188,  0.2205,  0.4228,  0.2348,  0.1226,  0.4015,  0.6105,
           0.4217,  0.3076,  0.3045,  0.5081,  0.3262,  0.2204,  0.1485,
           0.3574,  0.1792,  0.0596,  0.3774,  0.5837,  0.4024,  0.2807,
           0.3925,  0.5949,  0.4058,  0.2936,  0.3137,  0.5051,  0.3245,
           0.2042,  0.5579,  0.7547,  0.5837,  0.4672]],

        [[-0.0807,  0.0316,  0.2198,  0.0549, -0.0572,  0.1983,  0.4101,
           0.2260,  0.1184,  0.0899,  0.2942,  0.1188,  0.0143, -0.0907,
           0.1077, -0.0613, -0.1632,  0.1473,  0.3605,  0.1756,  0.0767,
           0.1978,  0.4079,  0.2166,  0.1154,  0.1235,  0.3094,  0.1378,
           0.0324,  0.3301,  0.5342,  0.3578,  0.2542]],

        [[ 0.2695,  0.3419,  0.5714,  0.3833,  0.2880,  0.5446,  0.7714,
           0.5761,  0.4824,  0.4371,  0.6612,  0.4682,  0.3822,  0.2466,
           0.4725,  0.2876,  0.2047,  0.4972,  0.7298,  0.5316,  0.4502,
           0.5448,  0.7760,  0.5741,  0.4907,  0.4734,  0.6817,  0.4969,
           0.4077,  0.6763,  0.8966,  0.7141,  0.6214]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
kb_values.shape:torch.Size([3, 33])
debug: kb_values: torch.Size([3, 20, 33])
debug: kb_probs: torch.Size([3, 20, 33])
filled v=torch.Size([3, 20, 2695]) in 0.1003880500793457 seconds
v:tensor([[[-0.1011,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0988,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1019,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.1257,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1329,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1188,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.1981,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.2242,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.2189,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.0180,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0816,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0807,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.0495,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1384,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1739,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.1949,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.2131,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.2695,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],
       grad_fn=<CopySlices>)
(3, 20)
proc_batch: Hypothesis: ['particular', 'station.', 'optometrist_appointment_time', 'particular', 'driver!', 'particular', "domino's", 'station.', 'ct', 'particular', 'venetia.', 'ct', 'high.', 'ct', 'fog', 'ct', 'ct.', 'amaranta', '5th', 'venetia.']

----------TRN FWD PASS: END current batch----------

batch.kbsrc:  (tensor([[  0,   3,   1,   1,   1,   1,   1],
        [151, 153,   1,   8,   3,   1,   1],
        [151, 153,   1,  10,   3,   1,   1],
        [151, 153,   1,   9,   3,   1,   1],
        [151, 153,   1,   6,   3,   1,   1],
        [178,  57,  43,   1,   8,   3,   1],
        [178,  57,  43,   1,  10,   3,   1],
        [178,  57,  43,   1,   9,   3,   1],
        [178,  57,  43,   1,   6,   3,   1],
        [161, 167,   1,   8,   3,   1,   1],
        [161, 167,   1,  10,   3,   1,   1],
        [161, 167,   1,   9,   3,   1,   1],
        [161, 167,   1,   6,   3,   1,   1],
        [  5, 181,   1,   8,   3,   1,   1],
        [  5, 181,   1,  10,   3,   1,   1],
        [  5, 181,   1,   9,   3,   1,   1],
        [  5, 181,   1,   6,   3,   1,   1],
        [143,  90,   1,   8,   3,   1,   1],
        [143,  90,   1,  10,   3,   1,   1],
        [143,  90,   1,   9,   3,   1,   1],
        [143,  90,   1,   6,   3,   1,   1],
        [ 76,   1,   8,   3,   1,   1,   1],
        [ 76,   1,  10,   3,   1,   1,   1],
        [ 76,   1,   9,   3,   1,   1,   1],
        [ 76,   1,   6,   3,   1,   1,   1],
        [141,   1,   8,   3,   1,   1,   1],
        [141,   1,  10,   3,   1,   1,   1],
        [141,   1,   9,   3,   1,   1,   1],
        [141,   1,   6,   3,   1,   1,   1],
        [ 60,  61, 146, 149,   1,   8,   3],
        [ 60,  61, 146, 149,   1,  10,   3],
        [ 60,  61, 146, 149,   1,   9,   3],
        [ 60,  61, 146, 149,   1,   6,   3]]), tensor([2, 5, 5, 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4,
        4, 4, 4, 4, 4, 7, 7, 7, 7])) <class 'tuple'>
batch.kbtrg:  (tensor([[  2,   0,   3],
        [  2, 368,   3],
        [  2, 370,   3],
        [  2, 369,   3],
        [  2, 367,   3],
        [  2, 423,   3],
        [  2, 425,   3],
        [  2, 424,   3],
        [  2, 422,   3],
        [  2, 408,   3],
        [  2, 410,   3],
        [  2, 409,   3],
        [  2, 407,   3],
        [  2, 479,   3],
        [  2, 481,   3],
        [  2, 480,   3],
        [  2, 478,   3],
        [  2, 335,   3],
        [  2, 337,   3],
        [  2, 336,   3],
        [  2, 334,   3],
        [  2,  35,   3],
        [  2,  37,   3],
        [  2,  36,   3],
        [  2,  34,   3],
        [  2, 352,   3],
        [  2, 354,   3],
        [  2, 353,   3],
        [  2, 351,   3],
        [  2, 364,   3],
        [  2, 366,   3],
        [  2, 365,   3],
        [  2, 363,   3]]), tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3])) <class 'tuple'>

----------TRN FWD PASS: START current batch----------

proc_batch: batch.src: ['show', 'me', 'the', 'closest', 'location', 'where', 'i', 'can', 'get', 'chinese', 'food', '@dot', 'the', 'closest', 'chinese', 'restaurant', 'is', 'pf', 'changs,', 'located', '5', 'miles', 'away.', '@dot', 'ok,', 'please', 'give', 'me', 'an', 'address', 'and', 'directions', 'via', 'a', 'route', 'that', 'avoids', 'all', 'heavy', 'traffic.', '@dot', 'p.f.', 'changs', 'route', 'set', 'to', '669', 'el', 'camino', 'real', 'with', 'only', 'moderate', 'traffic', 'noted.', '@dot', 'thank', 'you']
proc_batch: batch.trg: ["you're", 'welcome.', 'drive', 'safely,', 'and', 'enjoy.']
proc_batch: kbkeys: [['<unk>'], ['menlo_park_tuesday', 'compton_friday', '<pad>', 'at'], ['menlo_park_tuesday', 'compton_friday', '<pad>', 'in'], ['menlo_park_tuesday', 'compton_friday', '<pad>', 'to'], ['menlo_park_tuesday', 'compton_friday', '<pad>', 'you'], ['dinner_agenda', 'football_activity_time', 'welcome', '<pad>', 'at'], ['dinner_agenda', 'football_activity_time', 'welcome', '<pad>', 'in'], ['dinner_agenda', 'football_activity_time', 'welcome', '<pad>', 'to'], ['dinner_agenda', 'football_activity_time', 'welcome', '<pad>', 'you'], ['durham_monday', 'forecast', '<pad>', 'at'], ['durham_monday', 'forecast', '<pad>', 'in'], ['durham_monday', 'forecast', '<pad>', 'to'], ['durham_monday', 'forecast', '<pad>', 'you'], ['is', 'dinner_room', '<pad>', 'at'], ['is', 'dinner_room', '<pad>', 'in'], ['is', 'dinner_room', '<pad>', 'to'], ['is', 'dinner_room', '<pad>', 'you'], ['downtown_chicago_tuesday', 'yoga_activity_agenda', '<pad>', 'at'], ['downtown_chicago_tuesday', 'yoga_activity_agenda', '<pad>', 'in'], ['downtown_chicago_tuesday', 'yoga_activity_agenda', '<pad>', 'to'], ['downtown_chicago_tuesday', 'yoga_activity_agenda', '<pad>', 'you'], ['mountain_view_friday', '<pad>', 'at'], ['mountain_view_friday', '<pad>', 'in'], ['mountain_view_friday', '<pad>', 'to'], ['mountain_view_friday', '<pad>', 'you'], ['downtown_chicago_sunday', '<pad>', 'at'], ['downtown_chicago_sunday', '<pad>', 'in'], ['downtown_chicago_sunday', '<pad>', 'to'], ['downtown_chicago_sunday', '<pad>', 'you'], ['dentist_appointment_party', 'dentist_appointment_room', 'menlo_park_friday', 'menlo_park_sunday', '<pad>', 'at'], ['dentist_appointment_party', 'dentist_appointment_room', 'menlo_park_friday', 'menlo_park_sunday', '<pad>', 'in'], ['dentist_appointment_party', 'dentist_appointment_room', 'menlo_park_friday', 'menlo_park_sunday', '<pad>', 'to'], ['dentist_appointment_party', 'dentist_appointment_room', 'menlo_park_friday', 'menlo_park_sunday', '<pad>', 'you']]
proc_batch: kbvals: [['<s>', '<unk>'], ['<s>', 'p.f._changs_distance'], ['<s>', 'p.f._changs_traffic_info'], ['<s>', 'p.f._changs_poi_type'], ['<s>', 'p.f._changs_address'], ['<s>', 'ravenswood_shopping_center_distance'], ['<s>', 'ravenswood_shopping_center_traffic_info'], ['<s>', 'ravenswood_shopping_center_poi_type'], ['<s>', 'ravenswood_shopping_center_address'], ['<s>', "chef_chu's_distance"], ['<s>', "chef_chu's_traffic_info"], ['<s>', "chef_chu's_poi_type"], ['<s>', "chef_chu's_address"], ['<s>', 'the_westin_distance'], ['<s>', 'the_westin_traffic_info'], ['<s>', 'the_westin_poi_type'], ['<s>', 'the_westin_address'], ['<s>', 'dish_parking_distance'], ['<s>', 'dish_parking_traffic_info'], ['<s>', 'dish_parking_poi_type'], ['<s>', 'dish_parking_address'], ['<s>', 'home_distance'], ['<s>', 'home_traffic_info'], ['<s>', 'home_poi_type'], ['<s>', 'home_address'], ['<s>', 'philz_distance'], ['<s>', 'philz_traffic_info'], ['<s>', 'philz_poi_type'], ['<s>', 'philz_address'], ['<s>', 'palo_alto_medical_foundation_distance'], ['<s>', 'palo_alto_medical_foundation_traffic_info'], ['<s>', 'palo_alto_medical_foundation_poi_type'], ['<s>', 'palo_alto_medical_foundation_address']]
decoder.forward() unroll_steps in model.forward
is 15, which is 1st dim of trg_input=torch.Size([3, 15])
batch.trg_input: ['<s>', "you're", 'welcome.', 'drive', 'safely,', 'and', 'enjoy.']
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2146,  0.0120,  0.2082,  0.0517, -0.0801, -0.1415,  0.0555,
          -0.1102, -0.2303, -0.1410,  0.0567, -0.1121, -0.2274, -0.2012,
          -0.0085, -0.1758, -0.2887,  0.0741,  0.2724,  0.1044, -0.0140,
          -0.2263, -0.0237, -0.1912, -0.3094, -0.0017,  0.1981,  0.0323,
          -0.0899,  0.1903,  0.3852,  0.2230,  0.1038]],

        [[-0.1223,  0.1288,  0.3259,  0.1570,  0.0363, -0.0358,  0.1629,
          -0.0122, -0.1203, -0.0590,  0.1509, -0.0299, -0.1380, -0.1111,
           0.0850, -0.0864, -0.1965,  0.1584,  0.3661,  0.1934,  0.0789,
          -0.1181,  0.0873, -0.0913, -0.2020,  0.1049,  0.3012,  0.1295,
           0.0140,  0.2904,  0.4898,  0.3265,  0.2062]],

        [[-0.0200,  0.2136,  0.4076,  0.2488,  0.1249,  0.0679,  0.2560,
           0.0944, -0.0190,  0.0665,  0.2577,  0.0911, -0.0247, -0.0014,
           0.1823,  0.0172, -0.0989,  0.2677,  0.4732,  0.3015,  0.1844,
          -0.0196,  0.1779,  0.0100, -0.1121,  0.2042,  0.4041,  0.2348,
           0.1128,  0.3880,  0.5887,  0.4260,  0.3086]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2539, -0.0263,  0.1701,  0.0132, -0.1184, -0.1786,  0.0174,
          -0.1479, -0.2675, -0.1781,  0.0187, -0.1497, -0.2653, -0.2389,
          -0.0474, -0.2142, -0.3264,  0.0352,  0.2328,  0.0646, -0.0533,
          -0.2658, -0.0621, -0.2302, -0.3490, -0.0398,  0.1598, -0.0058,
          -0.1284,  0.1521,  0.3467,  0.1841,  0.0653]],

        [[-0.1565,  0.0949,  0.2937,  0.1251,  0.0041, -0.0677,  0.1306,
          -0.0424, -0.1519, -0.0893,  0.1191, -0.0597, -0.1689, -0.1443,
           0.0502, -0.1196, -0.2324,  0.1229,  0.3347,  0.1585,  0.0426,
          -0.1526,  0.0544, -0.1226, -0.2354,  0.0711,  0.2719,  0.0984,
          -0.0182,  0.2569,  0.4596,  0.2932,  0.1726]],

        [[-0.0410,  0.1900,  0.3797,  0.2200,  0.1004,  0.0502,  0.2307,
           0.0707, -0.0383,  0.0515,  0.2352,  0.0714, -0.0424, -0.0195,
           0.1570, -0.0051, -0.1205,  0.2482,  0.4491,  0.2795,  0.1604,
          -0.0398,  0.1505, -0.0149, -0.1360,  0.1816,  0.3767,  0.2073,
           0.0881,  0.3636,  0.5615,  0.3993,  0.2802]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2666, -0.0393,  0.1581,  0.0006, -0.1298, -0.1896,  0.0059,
          -0.1594, -0.2772, -0.1896,  0.0069, -0.1611, -0.2763, -0.2513,
          -0.0598, -0.2264, -0.3373,  0.0224,  0.2206,  0.0520, -0.0651,
          -0.2788, -0.0743, -0.2432, -0.3620, -0.0512,  0.1482, -0.0174,
          -0.1396,  0.1388,  0.3347,  0.1717,  0.0532]],

        [[-0.2801, -0.0310,  0.1637, -0.0014, -0.1227, -0.1894,  0.0024,
          -0.1634, -0.2747, -0.2095, -0.0090, -0.1799, -0.2904, -0.2608,
          -0.0753, -0.2373, -0.3510, -0.0054,  0.2036,  0.0293, -0.0878,
          -0.2792, -0.0750, -0.2452, -0.3591, -0.0568,  0.1436, -0.0263,
          -0.1442,  0.1309,  0.3300,  0.1652,  0.0447]],

        [[-0.0983,  0.1282,  0.3146,  0.1578,  0.0374, -0.0091,  0.1666,
           0.0112, -0.0997, -0.0056,  0.1717,  0.0137, -0.1022, -0.0760,
           0.0953, -0.0615, -0.1794,  0.1861,  0.3828,  0.2168,  0.0945,
          -0.0999,  0.0847, -0.0753, -0.1986,  0.1173,  0.3097,  0.1433,
           0.0233,  0.2963,  0.4907,  0.3313,  0.2104]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2410, -0.0152,  0.1835,  0.0264, -0.1034, -0.1640,  0.0326,
          -0.1327, -0.2491, -0.1637,  0.0340, -0.1339, -0.2488, -0.2276,
          -0.0342, -0.2013, -0.3114,  0.0461,  0.2464,  0.0775, -0.0390,
          -0.2533, -0.0476, -0.2171, -0.3356, -0.0248,  0.1750,  0.0095,
          -0.1124,  0.1625,  0.3604,  0.1978,  0.0791]],

        [[-0.3111, -0.0640,  0.1235, -0.0376, -0.1588, -0.2153, -0.0331,
          -0.1920, -0.3049, -0.2327, -0.0434, -0.2060, -0.3183, -0.2837,
          -0.1082, -0.2635, -0.3788, -0.0359,  0.1662, -0.0047, -0.1236,
          -0.3126, -0.1155, -0.2794, -0.3940, -0.0894,  0.1054, -0.0601,
          -0.1792,  0.1018,  0.2941,  0.1317,  0.0111]],

        [[-0.1324,  0.0928,  0.2762,  0.1217, -0.0015, -0.0433,  0.1290,
          -0.0231, -0.1384, -0.0389,  0.1333, -0.0207, -0.1400, -0.1085,
           0.0593, -0.0945, -0.2171,  0.1490,  0.3423,  0.1784,  0.0512,
          -0.1350,  0.0469, -0.1097, -0.2360,  0.0783,  0.2692,  0.1053,
          -0.0180,  0.2582,  0.4494,  0.2916,  0.1667]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1851,  0.0395,  0.2400,  0.0830, -0.0464, -0.1101,  0.0896,
          -0.0768, -0.1928, -0.1090,  0.0915, -0.0770, -0.1921, -0.1760,
           0.0217, -0.1477, -0.2574,  0.0983,  0.3022,  0.1321,  0.0160,
          -0.1970,  0.0106, -0.1597, -0.2779,  0.0312,  0.2326,  0.0666,
          -0.0554,  0.2160,  0.4167,  0.2541,  0.1353]],

        [[-0.4131, -0.1683,  0.0089, -0.1464, -0.2672, -0.3120, -0.1431,
          -0.2923, -0.4065, -0.3285, -0.1540, -0.3059, -0.4200, -0.3771,
          -0.2147, -0.3606, -0.4769, -0.1410,  0.0506, -0.1138, -0.2344,
          -0.4170, -0.2297, -0.3854, -0.5010, -0.1982, -0.0127, -0.1712,
          -0.2918, -0.0033,  0.1788,  0.0221, -0.0994]],

        [[-0.1496,  0.0715,  0.2499,  0.0997, -0.0254, -0.0601,  0.1040,
          -0.0423, -0.1592, -0.0551,  0.1071, -0.0409, -0.1620, -0.1228,
           0.0359, -0.1122, -0.2372,  0.1265,  0.3114,  0.1536,  0.0224,
          -0.1528,  0.0229, -0.1281, -0.2579,  0.0525,  0.2399,  0.0795,
          -0.0460,  0.2303,  0.4162,  0.2625,  0.1346]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1398,  0.0881,  0.2892,  0.1311,  0.0029, -0.0657,  0.1371,
          -0.0317, -0.1471, -0.0667,  0.1375, -0.0332, -0.1478, -0.1338,
           0.0679, -0.1043, -0.2140,  0.1405,  0.3481,  0.1760,  0.0603,
          -0.1501,  0.0585, -0.1132, -0.2300,  0.0776,  0.2801,  0.1127,
          -0.0085,  0.2620,  0.4643,  0.3012,  0.1826]],

        [[-0.5327, -0.2949, -0.1244, -0.2757, -0.3951, -0.4290, -0.2701,
          -0.4110, -0.5248, -0.4453, -0.2800, -0.4231, -0.5382, -0.4893,
          -0.3374, -0.4735, -0.5892, -0.2630, -0.0791, -0.2370, -0.3584,
          -0.5422, -0.3613, -0.5100, -0.6261, -0.3227, -0.1452, -0.2962,
          -0.4169, -0.1288,  0.0462, -0.1054, -0.2278]],

        [[-0.1408,  0.0776,  0.2555,  0.1054, -0.0198, -0.0552,  0.1077,
          -0.0379, -0.1555, -0.0497,  0.1104, -0.0366, -0.1591, -0.1158,
           0.0417, -0.1059, -0.2318,  0.1297,  0.3133,  0.1561,  0.0233,
          -0.1463,  0.0291, -0.1213, -0.2532,  0.0542,  0.2417,  0.0816,
          -0.0453,  0.2307,  0.4161,  0.2623,  0.1339]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0375,  0.1907,  0.3930,  0.2353,  0.1069,  0.0339,  0.2406,
           0.0702, -0.0461,  0.0329,  0.2408,  0.0691, -0.0466, -0.0371,
           0.1704, -0.0053, -0.1160,  0.2385,  0.4508,  0.2770,  0.1612,
          -0.0464,  0.1629, -0.0094, -0.1262,  0.1804,  0.3841,  0.2159,
           0.0941,  0.3628,  0.5678,  0.4048,  0.2858]],

        [[-0.5051, -0.2661, -0.0988, -0.2514, -0.3665, -0.3936, -0.2411,
          -0.3800, -0.4908, -0.4098, -0.2523, -0.3911, -0.5061, -0.4561,
          -0.3098, -0.4445, -0.5592, -0.2328, -0.0530, -0.2098, -0.3301,
          -0.5123, -0.3360, -0.4846, -0.5984, -0.2914, -0.1195, -0.2690,
          -0.3883, -0.0998,  0.0723, -0.0788, -0.2002]],

        [[-0.2019,  0.0217,  0.1953,  0.0426, -0.0801, -0.1161,  0.0440,
          -0.1039, -0.2205, -0.1144,  0.0428, -0.1060, -0.2266, -0.1726,
          -0.0172, -0.1665, -0.2907,  0.0697,  0.2509,  0.0902, -0.0416,
          -0.2089, -0.0346, -0.1869, -0.3164, -0.0113,  0.1730,  0.0118,
          -0.1132,  0.1733,  0.3553,  0.1977,  0.0697]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.0461,  0.2764,  0.4784,  0.3210,  0.1926,  0.1166,  0.3265,
           0.1544,  0.0371,  0.1136,  0.3251,  0.1518,  0.0354,  0.0430,
           0.2548,  0.0760, -0.0357,  0.3188,  0.5347,  0.3590,  0.2431,
           0.0396,  0.2489,  0.0764, -0.0400,  0.2650,  0.4695,  0.3006,
           0.1785,  0.4464,  0.6526,  0.4899,  0.3702]],

        [[-0.4417, -0.2060, -0.0379, -0.1925, -0.3052, -0.3322, -0.1804,
          -0.3196, -0.4300, -0.3443, -0.1884, -0.3262, -0.4425, -0.3914,
          -0.2448, -0.3806, -0.4962, -0.1677,  0.0129, -0.1453, -0.2655,
          -0.4516, -0.2758, -0.4252, -0.5398, -0.2276, -0.0559, -0.2058,
          -0.3251, -0.0376,  0.1361, -0.0177, -0.1366]],

        [[-0.2699, -0.0416,  0.1364, -0.0238, -0.1425, -0.1821, -0.0184,
          -0.1735, -0.2859, -0.1855, -0.0241, -0.1801, -0.2960, -0.2391,
          -0.0817, -0.2354, -0.3553,  0.0069,  0.1890,  0.0236, -0.1052,
          -0.2773, -0.0974, -0.2573, -0.3820, -0.0776,  0.1105, -0.0568,
          -0.1772,  0.1066,  0.2916,  0.1277,  0.0016]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.1381,  0.3758,  0.5773,  0.4178,  0.2921,  0.2104,  0.4246,
           0.2483,  0.1322,  0.2042,  0.4193,  0.2433,  0.1282,  0.1322,
           0.3496,  0.1651,  0.0549,  0.4085,  0.6280,  0.4492,  0.3351,
           0.1360,  0.3463,  0.1718,  0.0586,  0.3621,  0.5674,  0.3967,
           0.2767,  0.5422,  0.7493,  0.5850,  0.4670]],

        [[-0.3454, -0.1009,  0.0771, -0.0855, -0.1976, -0.2370, -0.0722,
          -0.2210, -0.3321, -0.2494, -0.0804, -0.2270, -0.3444, -0.3028,
          -0.1431, -0.2894, -0.4050, -0.0706,  0.1204, -0.0454, -0.1655,
          -0.3526, -0.1649, -0.3234, -0.4374, -0.1219,  0.0598, -0.0973,
          -0.2172,  0.0655,  0.2483,  0.0870, -0.0313]],

        [[-0.2098,  0.0176,  0.1960,  0.0346, -0.0840, -0.1256,  0.0378,
          -0.1180, -0.2303, -0.1247,  0.0357, -0.1207, -0.2390, -0.1836,
          -0.0268, -0.1808, -0.3026,  0.0608,  0.2433,  0.0781, -0.0522,
          -0.2156, -0.0366, -0.1968, -0.3260, -0.0223,  0.1658, -0.0024,
          -0.1255,  0.1583,  0.3443,  0.1797,  0.0540]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 1.8841e-01,  4.2512e-01,  6.2503e-01,  4.6843e-01,  3.4180e-01,
           2.6147e-01,  4.7603e-01,  3.0188e-01,  1.8398e-01,  2.5609e-01,
           4.6929e-01,  2.9689e-01,  1.8047e-01,  1.8150e-01,  3.9978e-01,
           2.1566e-01,  1.0467e-01,  4.5531e-01,  6.7590e-01,  4.9741e-01,
           3.8331e-01,  1.8710e-01,  3.9567e-01,  2.2441e-01,  1.1075e-01,
           4.1301e-01,  6.1790e-01,  4.4940e-01,  3.2845e-01,  5.9062e-01,
           7.9750e-01,  6.3454e-01,  5.1649e-01]],

        [[-2.0274e-01,  3.3192e-02,  2.1283e-01,  4.9970e-02, -5.8698e-02,
          -9.8176e-02,  6.7640e-02, -8.1863e-02, -1.9025e-01, -1.0885e-01,
           6.0060e-02, -8.5951e-02, -2.0393e-01, -1.6039e-01,  2.3231e-04,
          -1.4761e-01, -2.6214e-01,  7.5849e-02,  2.6581e-01,  1.0191e-01,
          -1.6338e-02, -2.1156e-01, -2.5057e-02, -1.8431e-01, -2.9875e-01,
           1.9889e-02,  2.0017e-01,  4.3758e-02, -7.5160e-02,  2.0445e-01,
           3.8759e-01,  2.2753e-01,  1.1340e-01]],

        [[-2.0636e-01,  2.1930e-02,  2.0230e-01,  3.4599e-02, -8.2578e-02,
          -1.2668e-01,  3.9159e-02, -1.2283e-01, -2.3365e-01, -1.2067e-01,
           3.8831e-02, -1.1966e-01, -2.3549e-01, -1.8112e-01, -2.0866e-02,
          -1.8019e-01, -3.0062e-01,  6.6455e-02,  2.4984e-01,  8.0568e-02,
          -4.9223e-02, -2.1506e-01, -3.3216e-02, -1.9818e-01, -3.2475e-01,
          -1.9832e-02,  1.6816e-01, -3.1533e-03, -1.2440e-01,  1.6918e-01,
           3.5676e-01,  1.8563e-01,  6.0089e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.2596,  0.4992,  0.6922,  0.5404,  0.4132,  0.3385,  0.5504,
           0.3791,  0.2587,  0.3268,  0.5375,  0.3680,  0.2502,  0.2557,
           0.4726,  0.2897,  0.1769,  0.5269,  0.7434,  0.5684,  0.4535,
           0.2598,  0.4631,  0.2963,  0.1826,  0.4868,  0.6863,  0.5223,
           0.4008,  0.6643,  0.8651,  0.7062,  0.5878]],

        [[-0.1190,  0.1188,  0.2984,  0.1345,  0.0259, -0.0141,  0.1523,
           0.0015, -0.1078, -0.0262,  0.1423, -0.0039, -0.1232, -0.0762,
           0.0849, -0.0643, -0.1806,  0.1612,  0.3501,  0.1868,  0.0673,
          -0.1269,  0.0592, -0.1010, -0.2160,  0.1049,  0.2846,  0.1281,
           0.0081,  0.2907,  0.4729,  0.3130,  0.1990]],

        [[-0.1563,  0.0673,  0.2554,  0.0852, -0.0321, -0.0791,  0.0951,
          -0.0710, -0.1813, -0.0764,  0.0907, -0.0708, -0.1870, -0.1361,
           0.0324, -0.1297, -0.2506,  0.1177,  0.3058,  0.1358,  0.0060,
          -0.1638,  0.0267, -0.1429, -0.2689,  0.0318,  0.2249,  0.0525,
          -0.0691,  0.2145,  0.4075,  0.2353,  0.1090]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.2994,  0.5419,  0.7320,  0.5842,  0.4569,  0.3832,  0.5942,
           0.4267,  0.3039,  0.3682,  0.5766,  0.4105,  0.2914,  0.2985,
           0.5134,  0.3332,  0.2199,  0.5636,  0.7785,  0.6056,  0.4919,
           0.3030,  0.5035,  0.3408,  0.2266,  0.5305,  0.7288,  0.5679,
           0.4453,  0.7021,  0.9002,  0.7442,  0.6287]],

        [[-0.0153,  0.2222,  0.4067,  0.2425,  0.1350,  0.0862,  0.2584,
           0.1066, -0.0019,  0.0732,  0.2459,  0.1006, -0.0193,  0.0233,
           0.1906,  0.0402, -0.0758,  0.2583,  0.4513,  0.2889,  0.1698,
          -0.0242,  0.1655,  0.0048, -0.1105,  0.2114,  0.3931,  0.2380,
           0.1178,  0.3899,  0.5764,  0.4170,  0.3045]],

        [[-0.1226,  0.1060,  0.2933,  0.1208,  0.0081, -0.0450,  0.1324,
          -0.0400, -0.1453, -0.0455,  0.1248, -0.0429, -0.1543, -0.1009,
           0.0717, -0.0976, -0.2136,  0.1587,  0.3451,  0.1727,  0.0480,
          -0.1278,  0.0648, -0.1096, -0.2310,  0.0691,  0.2622,  0.0864,
          -0.0301,  0.2539,  0.4455,  0.2706,  0.1495]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 2.9862e-01,  5.3751e-01,  7.1901e-01,  5.7885e-01,  4.4925e-01,
           3.8515e-01,  5.8892e-01,  4.2818e-01,  3.0308e-01,  3.6412e-01,
           5.6618e-01,  4.0637e-01,  2.8577e-01,  3.0430e-01,  5.1241e-01,
           3.3846e-01,  2.2330e-01,  5.6365e-01,  7.7158e-01,  6.0480e-01,
           4.8917e-01,  3.0041e-01,  4.9317e-01,  3.3816e-01,  2.2277e-01,
           5.2445e-01,  7.1595e-01,  5.6175e-01,  4.3804e-01,  6.9937e-01,
           8.8945e-01,  7.4031e-01,  6.2205e-01]],

        [[ 5.6081e-02,  2.8533e-01,  4.7095e-01,  3.0779e-01,  2.0480e-01,
           1.5157e-01,  3.2544e-01,  1.7359e-01,  6.9877e-02,  1.4076e-01,
           3.1578e-01,  1.7002e-01,  5.3255e-02,  9.3454e-02,  2.6328e-01,
           1.1190e-01, -4.6703e-04,  3.2819e-01,  5.2259e-01,  3.6118e-01,
           2.4631e-01,  4.4493e-02,  2.3515e-01,  7.4374e-02, -3.8724e-02,
           2.8087e-01,  4.6275e-01,  3.0869e-01,  1.9221e-01,  4.5725e-01,
           6.4565e-01,  4.8720e-01,  3.7937e-01]],

        [[-1.3941e-01,  8.4076e-02,  2.6501e-01,  9.3996e-02, -9.3060e-03,
          -6.0595e-02,  1.0741e-01, -6.0679e-02, -1.5694e-01, -6.0698e-02,
           1.0085e-01, -6.4959e-02, -1.6518e-01, -1.0828e-01,  5.7145e-02,
          -1.0995e-01, -2.1782e-01,  1.4131e-01,  3.2207e-01,  1.4947e-01,
           3.5367e-02, -1.4726e-01,  3.9179e-02, -1.3406e-01, -2.4577e-01,
           4.6775e-02,  2.3193e-01,  5.8252e-02, -4.8230e-02,  2.3362e-01,
           4.2101e-01,  2.4519e-01,  1.3349e-01]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.2903,  0.5381,  0.7172,  0.5771,  0.4498,  0.3835,  0.5870,
           0.4256,  0.3027,  0.3556,  0.5589,  0.3975,  0.2794,  0.3013,
           0.5089,  0.3335,  0.2220,  0.5565,  0.7618,  0.5966,  0.4826,
           0.2940,  0.4879,  0.3330,  0.2206,  0.5232,  0.7143,  0.5609,
           0.4397,  0.6975,  0.8849,  0.7364,  0.6198]],

        [[ 0.0899,  0.3256,  0.5160,  0.3498,  0.2508,  0.1872,  0.3674,
           0.2116,  0.1117,  0.1700,  0.3532,  0.2019,  0.0892,  0.1266,
           0.3036,  0.1477,  0.0380,  0.3608,  0.5613,  0.3963,  0.2852,
           0.0807,  0.2779,  0.1128,  0.0034,  0.3209,  0.5077,  0.3505,
           0.2378,  0.4944,  0.6883,  0.5266,  0.4225]],

        [[-0.0591,  0.1658,  0.3511,  0.1771,  0.0716,  0.0125,  0.1886,
           0.0143, -0.0845,  0.0148,  0.1821,  0.0128, -0.0927, -0.0346,
           0.1374, -0.0348, -0.1448,  0.2236,  0.4074,  0.2330,  0.1168,
          -0.0654,  0.1248, -0.0519, -0.1684,  0.1272,  0.3165,  0.1399,
           0.0294,  0.3162,  0.5057,  0.3278,  0.2168]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.3727,  0.6242,  0.7996,  0.6620,  0.5351,  0.4721,  0.6712,
           0.5132,  0.3888,  0.4426,  0.6395,  0.4824,  0.3603,  0.3896,
           0.5918,  0.4191,  0.3052,  0.6415,  0.8435,  0.6805,  0.5649,
           0.3793,  0.5680,  0.4165,  0.2998,  0.6098,  0.7976,  0.6465,
           0.5221,  0.7821,  0.9668,  0.8200,  0.7050]],

        [[ 0.1093,  0.3515,  0.5500,  0.3813,  0.2841,  0.2056,  0.3945,
           0.2370,  0.1373,  0.1835,  0.3762,  0.2225,  0.1099,  0.1430,
           0.3289,  0.1713,  0.0614,  0.3714,  0.5804,  0.4132,  0.3033,
           0.0995,  0.3054,  0.1378,  0.0290,  0.3464,  0.5407,  0.3820,
           0.2698,  0.5128,  0.7149,  0.5506,  0.4487]],

        [[-0.0860,  0.1465,  0.3292,  0.1534,  0.0509, -0.0073,  0.1654,
          -0.0094, -0.1049, -0.0096,  0.1546, -0.0147, -0.1167, -0.0540,
           0.1163, -0.0567, -0.1630,  0.1999,  0.3821,  0.2062,  0.0936,
          -0.0892,  0.1001, -0.0782, -0.1914,  0.1053,  0.2900,  0.1140,
           0.0062,  0.2972,  0.4851,  0.3046,  0.1965]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
kb_values.shape:torch.Size([3, 33])
debug: kb_values: torch.Size([3, 15, 33])
debug: kb_probs: torch.Size([3, 15, 33])
filled v=torch.Size([3, 15, 2695]) in 0.0764169692993164 seconds
v:tensor([[[-0.2146,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.2539,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.2666,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.2986,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.2903,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.3727,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.1223,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1565,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.2801,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.0561,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0899,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1093,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.0200,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0410,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0983,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.1394,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0591,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0860,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],
       grad_fn=<CopySlices>)
(3, 15)
proc_batch: Hypothesis: ['coffee.', '40', 'ahlambra', '40', '40', 'ahlambra', 'ahlambra', "don't", 'turn', 'ravenswood_shopping_center_distance', 'trouble', 'ravenswood_shopping_center_distance', 'ravenswood_shopping_center_distance', 'trouble', 'scheduled;']

----------TRN FWD PASS: END current batch----------

batch.kbsrc:  (tensor([[0, 3]]), tensor([2])) <class 'tuple'>
batch.kbtrg:  (tensor([[2, 0, 3]]), tensor([3])) <class 'tuple'>

----------TRN FWD PASS: START current batch----------

proc_batch: batch.src: ['hi,', 'please', 'set', 'up', 'a', 'reminder', 'for', 'my', 'dinner', 'on', 'the', '11th', 'at', '4pm', 'with', 'my', 'sister.', 'thanks!']
proc_batch: batch.trg: ['set!', 'have', 'a', 'good', 'time']
proc_batch: kbkeys: [['<unk>']]
proc_batch: kbvals: [['<s>', '<unk>']]
decoder.forward() unroll_steps in model.forward
is 6, which is 1st dim of trg_input=torch.Size([1, 6])
batch.trg_input: ['<s>', 'set!', 'have', 'a', 'good', 'time']
att debug: u_t.shape=torch.Size([1, 1, 1])
u_t
torch.Size([1, 1, 1])
self.hidden_size:  30
[query,context]
query:  torch.Size([1, 1, 30])
context:  torch.Size([1, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([1, 19, 60])
att debug: u_t.shape=torch.Size([1, 1, 1])
u_t
torch.Size([1, 1, 1])
self.hidden_size:  30
[query,context]
query:  torch.Size([1, 1, 30])
context:  torch.Size([1, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([1, 19, 60])
att debug: u_t.shape=torch.Size([1, 1, 1])
u_t
torch.Size([1, 1, 1])
self.hidden_size:  30
[query,context]
query:  torch.Size([1, 1, 30])
context:  torch.Size([1, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([1, 19, 60])
att debug: u_t.shape=torch.Size([1, 1, 1])
u_t
torch.Size([1, 1, 1])
self.hidden_size:  30
[query,context]
query:  torch.Size([1, 1, 30])
context:  torch.Size([1, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([1, 19, 60])
att debug: u_t.shape=torch.Size([1, 1, 1])
u_t
torch.Size([1, 1, 1])
self.hidden_size:  30
[query,context]
query:  torch.Size([1, 1, 30])
context:  torch.Size([1, 1, 60])
