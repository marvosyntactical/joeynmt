<built-in method with_traceback of PicklingError object at 0x7f13a574ca08>
<built-in method with_traceback of PicklingError object at 0x7f13a574ca08>
encoder.output_size:  60
batch.kbsrc:  (tensor([[   0,    3,    1,    1,    1,    1],
        [ 814,  581,    1, 2194,    3,    1],
        [ 814,  581,    1,    0,    3,    1],
        [ 814,  581,    1,    0,    3,    1],
        [ 814,  581,    1,  259,    3,    1],
        [ 523,  840,  581,    1, 2194,    3],
        [ 523,  840,  581,    1,    0,    3],
        [ 523,  840,  581,    1,    0,    3],
        [ 523,  840,  581,    1,  259,    3],
        [1268,  863,    1, 2194,    3,    1],
        [1268,  863,    1,    0,    3,    1],
        [1268,  863,    1,    0,    3,    1],
        [1268,  863,    1,  259,    3,    1],
        [   4,  908,    1, 2194,    3,    1],
        [   4,  908,    1,    0,    3,    1],
        [   4,  908,    1,    0,    3,    1],
        [   4,  908,    1,  259,    3,    1],
        [1688,  720,    1, 2194,    3,    1],
        [1688,  720,    1,    0,    3,    1],
        [1688,  720,    1,    0,    3,    1],
        [1688,  720,    1,  259,    3,    1],
        [ 554,  718,    1, 2194,    3,    1],
        [ 554,  718,    1,    0,    3,    1],
        [ 554,  718,    1,    0,    3,    1],
        [ 554,  718,    1,  259,    3,    1],
        [ 982,    1, 2194,    3,    1,    1],
        [ 982,    1,    0,    3,    1,    1],
        [ 982,    1,    0,    3,    1,    1],
        [ 982,    1,  259,    3,    1,    1],
        [ 781,  901,    1, 2194,    3,    1],
        [ 781,  901,    1,    0,    3,    1],
        [ 781,  901,    1,    0,    3,    1],
        [ 781,  901,    1,  259,    3,    1]]), tensor([2, 5, 5, 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
        5, 4, 4, 4, 4, 5, 5, 5, 5])) <class 'tuple'>
batch.kbtrg:  (tensor([[  2,   0,   3],
        [  2, 335,   3],
        [  2, 337,   3],
        [  2, 336,   3],
        [  2, 334,   3],
        [  2, 505,   3],
        [  2, 507,   3],
        [  2, 506,   3],
        [  2, 504,   3],
        [  2, 709,   3],
        [  2, 711,   3],
        [  2, 710,   3],
        [  2, 708,   3],
        [  2, 479,   3],
        [  2, 481,   3],
        [  2, 480,   3],
        [  2, 478,   3],
        [  2, 348,   3],
        [  2, 350,   3],
        [  2, 349,   3],
        [  2, 347,   3],
        [  2, 323,   3],
        [  2, 325,   3],
        [  2, 324,   3],
        [  2, 322,   3],
        [  2, 528,   3],
        [  2, 530,   3],
        [  2, 529,   3],
        [  2, 527,   3],
        [  2, 392,   3],
        [  2, 394,   3],
        [  2, 393,   3],
        [  2, 391,   3]]), tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3])) <class 'tuple'>

----------TRN FWD PASS: START current batch----------

proc_batch: batch.src: ['<unk>', 'the', 'nearest', 'parking', 'garage', '<unk>', 'the', 'nearest', 'parking', 'garage', 'is', 'dish', 'parking', 'at', '550', 'alester', 'ave.', 'would', 'you', 'like', 'directions', 'there?', '<unk>', 'yes,', 'please', 'set', 'directions', 'via', 'a', 'route', 'that', '<unk>', 'all', 'heavy', 'traffic', 'if', 'possible.', '<unk>', 'it', 'looks', 'like', 'there', 'is', 'a', 'road', 'block', 'being', 'reported', 'on', 'the', 'route', 'but', 'i', 'will', 'still', 'find', 'the', 'quickest', 'route', 'to', '550', 'alester', 'ave.', '<unk>', '<unk>', 'so', 'much', 'for', 'your', 'help.']
proc_batch: batch.trg: ["you're", 'very', 'welcome!']
proc_batch: kbkeys: [['<unk>'], ['dish', 'parking', '<pad>', 'distance'], ['dish', 'parking', '<pad>', '<unk>'], ['dish', 'parking', '<pad>', '<unk>'], ['dish', 'parking', '<pad>', 'address'], ['stanford', 'oval', 'parking', '<pad>', 'distance'], ['stanford', 'oval', 'parking', '<pad>', '<unk>'], ['stanford', 'oval', 'parking', '<pad>', '<unk>'], ['stanford', 'oval', 'parking', '<pad>', 'address'], ['willows', 'market', '<pad>', 'distance'], ['willows', 'market', '<pad>', '<unk>'], ['willows', 'market', '<pad>', '<unk>'], ['willows', 'market', '<pad>', 'address'], ['the', 'westin', '<pad>', 'distance'], ['the', 'westin', '<pad>', '<unk>'], ['the', 'westin', '<pad>', '<unk>'], ['the', 'westin', '<pad>', 'address'], ['toms', 'house', '<pad>', 'distance'], ['toms', 'house', '<pad>', '<unk>'], ['toms', 'house', '<pad>', '<unk>'], ['toms', 'house', '<pad>', 'address'], ['pizza', 'chicago', '<pad>', 'distance'], ['pizza', 'chicago', '<pad>', '<unk>'], ['pizza', 'chicago', '<pad>', '<unk>'], ['pizza', 'chicago', '<pad>', 'address'], ['valero', '<pad>', 'distance'], ['valero', '<pad>', '<unk>'], ['valero', '<pad>', '<unk>'], ['valero', '<pad>', 'address'], ['mandarin', 'roots', '<pad>', 'distance'], ['mandarin', 'roots', '<pad>', '<unk>'], ['mandarin', 'roots', '<pad>', '<unk>'], ['mandarin', 'roots', '<pad>', 'address']]
proc_batch: kbvals: [['<s>', '<unk>'], ['<s>', 'dish_parking_distance'], ['<s>', 'dish_parking_traffic_info'], ['<s>', 'dish_parking_poi_type'], ['<s>', 'dish_parking_address'], ['<s>', 'stanford_oval_parking_distance'], ['<s>', 'stanford_oval_parking_traffic_info'], ['<s>', 'stanford_oval_parking_poi_type'], ['<s>', 'stanford_oval_parking_address'], ['<s>', 'willows_market_distance'], ['<s>', 'willows_market_traffic_info'], ['<s>', 'willows_market_poi_type'], ['<s>', 'willows_market_address'], ['<s>', 'the_westin_distance'], ['<s>', 'the_westin_traffic_info'], ['<s>', 'the_westin_poi_type'], ['<s>', 'the_westin_address'], ['<s>', 'toms_house_distance'], ['<s>', 'toms_house_traffic_info'], ['<s>', 'toms_house_poi_type'], ['<s>', 'toms_house_address'], ['<s>', 'pizza_chicago_distance'], ['<s>', 'pizza_chicago_traffic_info'], ['<s>', 'pizza_chicago_poi_type'], ['<s>', 'pizza_chicago_address'], ['<s>', 'valero_distance'], ['<s>', 'valero_traffic_info'], ['<s>', 'valero_poi_type'], ['<s>', 'valero_address'], ['<s>', 'mandarin_roots_distance'], ['<s>', 'mandarin_roots_traffic_info'], ['<s>', 'mandarin_roots_poi_type'], ['<s>', 'mandarin_roots_address']]
decoder.forward() unroll_steps in model.forward
is 26, which is 1st dim of trg_input=torch.Size([3, 26])
batch.trg_input: ['<s>', "you're", 'very', 'welcome!']
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0166, -0.1129, -0.2478, -0.2478, -0.0505, -0.1099, -0.2418,
          -0.2418, -0.0489,  0.1025, -0.0354, -0.0354,  0.1643,  0.1013,
          -0.0359, -0.0359,  0.1638,  0.3156,  0.1857,  0.1857,  0.3799,
           0.1314, -0.0110, -0.0110,  0.1935,  0.1148, -0.0239, -0.0239,
           0.1778, -0.0291, -0.1602, -0.1602,  0.0312]],

        [[ 0.1308,  0.0081, -0.1123, -0.1123,  0.0703,  0.0229, -0.0992,
          -0.0992,  0.0851,  0.2267,  0.1101,  0.1101,  0.2894,  0.2332,
           0.1117,  0.1117,  0.2927,  0.4130,  0.3079,  0.3079,  0.4797,
           0.2598,  0.1334,  0.1334,  0.3224,  0.2405,  0.1178,  0.1178,
           0.3031,  0.1135, -0.0022, -0.0022,  0.1694]],

        [[-0.0129, -0.1177, -0.2408, -0.2408, -0.0663, -0.0969, -0.2200,
          -0.2200, -0.0471,  0.0872, -0.0351, -0.0351,  0.1408,  0.1002,
          -0.0242, -0.0242,  0.1539,  0.2712,  0.1585,  0.1585,  0.3361,
           0.1099, -0.0211, -0.0211,  0.1673,  0.0959, -0.0282, -0.0282,
           0.1544, -0.0058, -0.1245, -0.1245,  0.0403]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-1.6701e-02, -1.1353e-01, -2.4854e-01, -2.4854e-01, -5.1191e-02,
          -1.1044e-01, -2.4237e-01, -2.4237e-01, -4.9634e-02,  1.0184e-01,
          -3.5716e-02, -3.5716e-02,  1.6376e-01,  1.0086e-01, -3.5929e-02,
          -3.5929e-02,  1.6313e-01,  3.1468e-01,  1.8495e-01,  1.8495e-01,
           3.7891e-01,  1.3095e-01, -1.0725e-02, -1.0725e-02,  1.9310e-01,
           1.1436e-01, -2.3960e-02, -2.3960e-02,  1.7727e-01, -2.9490e-02,
          -1.6084e-01, -1.6084e-01,  3.0670e-02]],

        [[ 6.1158e-02, -6.0783e-02, -1.7942e-01, -1.7942e-01, -4.2960e-05,
          -4.3107e-02, -1.6336e-01, -1.6336e-01,  1.7457e-02,  1.5731e-01,
           4.2887e-02,  4.2887e-02,  2.1706e-01,  1.6557e-01,  4.5797e-02,
           4.5797e-02,  2.2237e-01,  3.4047e-01,  2.3730e-01,  2.3730e-01,
           4.0464e-01,  1.8719e-01,  6.3251e-02,  6.3251e-02,  2.4713e-01,
           1.6880e-01,  4.7989e-02,  4.7989e-02,  2.2862e-01,  4.9502e-02,
          -6.4613e-02, -6.4613e-02,  1.0192e-01]],

        [[ 3.0657e-02, -7.3741e-02, -1.9908e-01, -1.9908e-01, -1.8586e-02,
          -5.4076e-02, -1.7830e-01, -1.7830e-01, -1.1195e-03,  1.3600e-01,
           1.1029e-02,  1.1029e-02,  1.9115e-01,  1.4154e-01,  1.3602e-02,
           1.3602e-02,  1.9979e-01,  3.2802e-01,  2.1038e-01,  2.1038e-01,
           3.9252e-01,  1.5708e-01,  2.2025e-02,  2.2025e-02,  2.1614e-01,
           1.4312e-01,  1.5502e-02,  1.5502e-02,  2.0513e-01,  3.2688e-02,
          -8.7392e-02, -8.7392e-02,  8.3394e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-3.2406e-02, -1.2897e-01, -2.6391e-01, -2.6391e-01, -6.6572e-02,
          -1.2581e-01, -2.5758e-01, -2.5758e-01, -6.5097e-02,  8.5886e-02,
          -5.1512e-02, -5.1512e-02,  1.4785e-01,  8.5381e-02, -5.1096e-02,
          -5.1096e-02,  1.4762e-01,  2.9942e-01,  1.6920e-01,  1.6920e-01,
           3.6396e-01,  1.1506e-01, -2.5898e-02, -2.5898e-02,  1.7746e-01,
           9.8753e-02, -3.9176e-02, -3.9176e-02,  1.6172e-01, -4.5014e-02,
          -1.7640e-01, -1.7640e-01,  1.4684e-02]],

        [[ 2.0751e-02, -9.9209e-02, -2.1616e-01, -2.1616e-01, -4.0963e-02,
          -7.9155e-02, -1.9785e-01, -1.9785e-01, -2.1049e-02,  1.1916e-01,
           5.3472e-03,  5.3472e-03,  1.7603e-01,  1.2578e-01,  7.3499e-03,
           7.3499e-03,  1.8153e-01,  3.0143e-01,  1.9927e-01,  1.9927e-01,
           3.6345e-01,  1.4387e-01,  2.1133e-02,  2.1133e-02,  2.0250e-01,
           1.2515e-01,  6.2379e-03,  6.2379e-03,  1.8385e-01,  9.9308e-03,
          -1.0224e-01, -1.0224e-01,  6.0382e-02]],

        [[ 1.6752e-02, -8.2311e-02, -2.0998e-01, -2.0998e-01, -2.4708e-02,
          -6.4822e-02, -1.8930e-01, -1.8930e-01, -1.0346e-02,  1.2827e-01,
           1.5405e-04,  1.5405e-04,  1.8352e-01,  1.2825e-01, -2.3933e-03,
          -2.3933e-03,  1.8948e-01,  3.2481e-01,  2.0103e-01,  2.0103e-01,
           3.8794e-01,  1.4635e-01,  8.5968e-03,  8.5968e-03,  2.0563e-01,
           1.3479e-01,  4.3863e-03,  4.3863e-03,  1.9852e-01,  1.9497e-02,
          -1.0283e-01, -1.0283e-01,  7.3169e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0560, -0.1519, -0.2870, -0.2870, -0.0897, -0.1487, -0.2808,
          -0.2808, -0.0884,  0.0621, -0.0751, -0.0751,  0.1241,  0.0620,
          -0.0742, -0.0742,  0.1241,  0.2758,  0.1453,  0.1453,  0.3405,
           0.0912, -0.0486, -0.0486,  0.1540,  0.0750, -0.0623, -0.0623,
           0.1381, -0.0682, -0.2000, -0.2000, -0.0091]],

        [[-0.0583, -0.1760, -0.2939, -0.2939, -0.1191, -0.1558, -0.2756,
          -0.2756, -0.0991,  0.0427, -0.0726, -0.0726,  0.0983,  0.0478,
          -0.0708, -0.0708,  0.1035,  0.2290,  0.1253,  0.1253,  0.2908,
           0.0655, -0.0574, -0.0574,  0.1246,  0.0456, -0.0731, -0.0731,
           0.1045, -0.0695, -0.1817, -0.1817, -0.0206]],

        [[ 0.0079, -0.0914, -0.2183, -0.2183, -0.0323, -0.0762, -0.1990,
          -0.1990, -0.0204,  0.1216, -0.0062, -0.0062,  0.1768,  0.1176,
          -0.0128, -0.0128,  0.1812,  0.3199,  0.1957,  0.1957,  0.3825,
           0.1392,  0.0014,  0.0014,  0.1988,  0.1279, -0.0023, -0.0023,
           0.1930,  0.0055, -0.1155, -0.1155,  0.0613]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-8.4977e-02, -1.8018e-01, -3.1534e-01, -3.1534e-01, -1.1826e-01,
          -1.7691e-01, -3.0900e-01, -3.0900e-01, -1.1706e-01,  3.3225e-02,
          -1.0388e-01, -1.0388e-01,  9.5058e-02,  3.3378e-02, -1.0200e-01,
          -1.0200e-01,  9.5520e-02,  2.4727e-01,  1.1629e-01,  1.1629e-01,
           3.1178e-01,  6.2116e-02, -7.6577e-02, -7.6577e-02,  1.2514e-01,
           4.6439e-02, -9.0130e-02, -9.0130e-02,  1.0964e-01, -9.6723e-02,
          -2.2850e-01, -2.2850e-01, -3.8194e-02]],

        [[-1.1977e-01, -2.3411e-01, -3.5269e-01, -3.5269e-01, -1.7682e-01,
          -2.1351e-01, -3.3319e-01, -3.3319e-01, -1.5671e-01, -1.8775e-02,
          -1.3404e-01, -1.3404e-01,  3.6737e-02, -1.4295e-02, -1.3227e-01,
          -1.3227e-01,  4.1461e-02,  1.7281e-01,  6.7232e-02,  6.7232e-02,
           2.3384e-01,  3.5800e-03, -1.1744e-01, -1.1744e-01,  6.2840e-02,
          -1.8049e-02, -1.3564e-01, -1.3564e-01,  4.0712e-02, -1.3340e-01,
          -2.4640e-01, -2.4640e-01, -8.4775e-02]],

        [[ 1.4724e-02, -8.6449e-02, -2.1127e-01, -2.1127e-01, -2.3152e-02,
          -7.6475e-02, -1.9614e-01, -1.9614e-01, -1.7124e-02,  1.2661e-01,
           3.3557e-04,  3.3557e-04,  1.8346e-01,  1.2492e-01, -3.7594e-03,
          -3.7594e-03,  1.9313e-01,  3.3024e-01,  2.0591e-01,  2.0591e-01,
           3.9367e-01,  1.4931e-01,  1.3349e-02,  1.3349e-02,  2.1097e-01,
           1.3769e-01,  9.9172e-03,  9.9172e-03,  2.0625e-01,  4.0188e-03,
          -1.1396e-01, -1.1396e-01,  6.3989e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1218, -0.2170, -0.3518, -0.3518, -0.1551, -0.2133, -0.3449,
          -0.3449, -0.1536, -0.0037, -0.1403, -0.1403,  0.0580, -0.0033,
          -0.1376, -0.1376,  0.0591,  0.2102,  0.0792,  0.0792,  0.2749,
           0.0248, -0.1128, -0.1128,  0.0883,  0.0097, -0.1259, -0.1259,
           0.0733, -0.1331, -0.2641, -0.2641, -0.0750]],

        [[-0.1398, -0.2503, -0.3717, -0.3717, -0.1913, -0.2321, -0.3539,
          -0.3539, -0.1739, -0.0378, -0.1560, -0.1560,  0.0197, -0.0334,
          -0.1531, -0.1531,  0.0243,  0.1606,  0.0513,  0.0513,  0.2238,
          -0.0143, -0.1376, -0.1376,  0.0468, -0.0360, -0.1553, -0.1553,
           0.0246, -0.1560, -0.2709, -0.2709, -0.1057]],

        [[-0.0932, -0.1969, -0.3206, -0.3206, -0.1321, -0.1876, -0.3060,
          -0.3060, -0.1273,  0.0182, -0.1075, -0.1075,  0.0752,  0.0213,
          -0.1058, -0.1058,  0.0918,  0.2235,  0.0990,  0.0990,  0.2874,
           0.0422, -0.0914, -0.0914,  0.1057,  0.0356, -0.0907, -0.0907,
           0.1062, -0.1022, -0.2184, -0.2184, -0.0407]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1738, -0.2669, -0.4012, -0.4012, -0.2060, -0.2631, -0.3939,
          -0.3939, -0.2046, -0.0550, -0.1912, -0.1912,  0.0061, -0.0542,
          -0.1873, -0.1873,  0.0079,  0.1583,  0.0268,  0.0268,  0.2228,
          -0.0280, -0.1639, -0.1639,  0.0357, -0.0418, -0.1760, -0.1760,
           0.0218, -0.1833, -0.3137, -0.3137, -0.1262]],

        [[-0.1588, -0.2639, -0.3885, -0.3885, -0.2055, -0.2487, -0.3734,
          -0.3734, -0.1911, -0.0538, -0.1748, -0.1748,  0.0040, -0.0509,
          -0.1719, -0.1719,  0.0083,  0.1475,  0.0351,  0.0351,  0.2103,
          -0.0307, -0.1557, -0.1557,  0.0316, -0.0520, -0.1725, -0.1725,
           0.0099, -0.1764, -0.2936, -0.2936, -0.1246]],

        [[-0.0726, -0.1810, -0.2988, -0.2988, -0.1111, -0.1763, -0.2884,
          -0.2884, -0.1112,  0.0317, -0.0904, -0.0904,  0.0927,  0.0420,
          -0.0812, -0.0812,  0.1181,  0.2417,  0.1192,  0.1192,  0.3092,
           0.0656, -0.0640, -0.0640,  0.1334,  0.0598, -0.0617, -0.0617,
           0.1354, -0.0905, -0.2001, -0.2001, -0.0234]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-1.9862e-01, -2.9197e-01, -4.2573e-01, -4.2573e-01, -2.3027e-01,
          -2.8801e-01, -4.1819e-01, -4.1819e-01, -2.2901e-01, -8.0021e-02,
          -2.1607e-01, -2.1607e-01, -1.8517e-02, -7.8103e-02, -2.1035e-01,
          -2.1035e-01, -1.3741e-02,  1.3465e-01,  2.8856e-03,  2.8856e-03,
           2.0003e-01, -5.2320e-02, -1.8770e-01, -1.8770e-01,  1.2815e-02,
          -6.5402e-02, -1.9854e-01, -1.9854e-01,  3.3797e-04, -2.0842e-01,
          -3.3749e-01, -3.3749e-01, -1.5009e-01]],

        [[-1.3878e-01, -2.3616e-01, -3.6413e-01, -3.6413e-01, -1.8016e-01,
          -2.2380e-01, -3.5180e-01, -3.5180e-01, -1.6840e-01, -3.3725e-02,
          -1.5806e-01, -1.5806e-01,  2.5321e-02, -3.1334e-02, -1.5418e-01,
          -1.5418e-01,  2.6320e-02,  1.7399e-01,  5.8646e-02,  5.8646e-02,
           2.3458e-01, -9.5888e-03, -1.3604e-01, -1.3604e-01,  5.2709e-02,
          -3.2540e-02, -1.5475e-01, -1.5475e-01,  2.8003e-02, -1.5973e-01,
          -2.8010e-01, -2.8010e-01, -1.0712e-01]],

        [[-8.7930e-02, -2.0430e-01, -3.1626e-01, -3.1626e-01, -1.2982e-01,
          -2.0213e-01, -3.0909e-01, -3.0909e-01, -1.3221e-01,  8.0247e-03,
          -1.1028e-01, -1.1028e-01,  7.3038e-02,  2.7703e-02, -9.1168e-02,
          -9.1168e-02,  1.0903e-01,  2.2251e-01,  1.0342e-01,  1.0342e-01,
           2.9334e-01,  5.3291e-02, -7.1770e-02, -7.1770e-02,  1.2560e-01,
           4.7188e-02, -6.9651e-02, -6.9651e-02,  1.2713e-01, -1.1408e-01,
          -2.1699e-01, -2.1699e-01, -4.1584e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2276, -0.3204, -0.4529, -0.4529, -0.2594, -0.3154, -0.4444,
          -0.4444, -0.2576, -0.1094, -0.2446, -0.2446, -0.0484, -0.1047,
          -0.2357, -0.2357, -0.0396,  0.1045, -0.0269, -0.0269,  0.1699,
          -0.0815, -0.2154, -0.2154, -0.0156, -0.0929, -0.2244, -0.2244,
          -0.0263, -0.2353, -0.3629, -0.3629, -0.1769]],

        [[-0.1154, -0.2107, -0.3391, -0.3391, -0.1545, -0.2009, -0.3299,
          -0.3299, -0.1456, -0.0070, -0.1331, -0.1331,  0.0505, -0.0113,
          -0.1339, -0.1339,  0.0483,  0.2021,  0.0860,  0.0860,  0.2617,
           0.0145, -0.1125, -0.1125,  0.0769, -0.0092, -0.1311, -0.1311,
           0.0523, -0.1436, -0.2629, -0.2629, -0.0899]],

        [[-0.1231, -0.2465, -0.3558, -0.3558, -0.1698, -0.2453, -0.3503,
          -0.3503, -0.1732, -0.0322, -0.1487, -0.1487,  0.0344, -0.0056,
          -0.1224, -0.1224,  0.0783,  0.1860,  0.0693,  0.0693,  0.2570,
           0.0197, -0.1030, -0.1030,  0.0936,  0.0137, -0.1011, -0.1011,
           0.0952, -0.1545, -0.2542, -0.2542, -0.0786]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2754, -0.3692, -0.4997, -0.4997, -0.3080, -0.3617, -0.4885,
          -0.4885, -0.3042, -0.1590, -0.2927, -0.2927, -0.0982, -0.1502,
          -0.2794, -0.2794, -0.0839,  0.0549, -0.0757, -0.0757,  0.1215,
          -0.1303, -0.2626, -0.2626, -0.0633, -0.1401, -0.2697, -0.2697,
          -0.0720, -0.2802, -0.4053, -0.4053, -0.2218]],

        [[-0.0576, -0.1472, -0.2771, -0.2771, -0.0918, -0.1375, -0.2690,
          -0.2690, -0.0828,  0.0485, -0.0765, -0.0765,  0.1070,  0.0437,
          -0.0786, -0.0786,  0.1016,  0.2537,  0.1398,  0.1398,  0.3143,
           0.0699, -0.0565, -0.0565,  0.1317,  0.0452, -0.0766, -0.0766,
           0.1055, -0.0858, -0.2069, -0.2069, -0.0338]],

        [[-0.2769, -0.3981, -0.5060, -0.5060, -0.3175, -0.3956, -0.4995,
          -0.4995, -0.3196, -0.1885, -0.3046, -0.3046, -0.1177, -0.1550,
          -0.2706, -0.2706, -0.0662,  0.0332, -0.0836, -0.0836,  0.1110,
          -0.1321, -0.2535, -0.2535, -0.0519, -0.1363, -0.2498, -0.2498,
          -0.0494, -0.3036, -0.4017, -0.4017, -0.2244]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.3256, -0.4186, -0.5465, -0.5465, -0.3576, -0.4086, -0.5324,
          -0.5324, -0.3521, -0.2105, -0.3424, -0.3424, -0.1502, -0.1977,
          -0.3247, -0.3247, -0.1305,  0.0025, -0.1271, -0.1271,  0.0699,
          -0.1820, -0.3119, -0.3119, -0.1144, -0.1898, -0.3168, -0.3168,
          -0.1207, -0.3271, -0.4497, -0.4497, -0.2688]],

        [[-0.0482, -0.1332, -0.2640, -0.2640, -0.0787, -0.1259, -0.2585,
          -0.2585, -0.0726,  0.0628, -0.0646, -0.0646,  0.1194,  0.0486,
          -0.0747, -0.0747,  0.1059,  0.2692,  0.1536,  0.1536,  0.3284,
           0.0787, -0.0492, -0.0492,  0.1388,  0.0545, -0.0685, -0.0685,
           0.1134, -0.0818, -0.2036, -0.2036, -0.0310]],

        [[-0.2686, -0.3920, -0.4996, -0.4996, -0.3169, -0.3865, -0.4907,
          -0.4907, -0.3156, -0.1793, -0.2956, -0.2956, -0.1125, -0.1520,
          -0.2682, -0.2682, -0.0671,  0.0427, -0.0743, -0.0743,  0.1148,
          -0.1239, -0.2451, -0.2451, -0.0476, -0.1323, -0.2457, -0.2457,
          -0.0499, -0.3014, -0.3996, -0.3996, -0.2242]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.3567, -0.4475, -0.5723, -0.5723, -0.3883, -0.4351, -0.5557,
          -0.5557, -0.3807, -0.2422, -0.3723, -0.3723, -0.1835, -0.2270,
          -0.3523, -0.3523, -0.1598, -0.0305, -0.1586, -0.1586,  0.0369,
          -0.2143, -0.3426, -0.3426, -0.1472, -0.2202, -0.3452, -0.3452,
          -0.1513, -0.3566, -0.4765, -0.4765, -0.2992]],

        [[-0.0410, -0.1184, -0.2507, -0.2507, -0.0666, -0.1132, -0.2476,
          -0.2476, -0.0628,  0.0746, -0.0546, -0.0546,  0.1293,  0.0532,
          -0.0708, -0.0708,  0.1083,  0.2758,  0.1594,  0.1594,  0.3331,
           0.0832, -0.0455, -0.0455,  0.1414,  0.0613, -0.0625, -0.0625,
           0.1179, -0.0718, -0.1949, -0.1949, -0.0232]],

        [[-0.3720, -0.5035, -0.6058, -0.6058, -0.4274, -0.4958, -0.5940,
          -0.5940, -0.4242, -0.2912, -0.4022, -0.4022, -0.2235, -0.2554,
          -0.3666, -0.3666, -0.1696, -0.0690, -0.1823, -0.1823,  0.0042,
          -0.2301, -0.3457, -0.3457, -0.1524, -0.2356, -0.3439, -0.3439,
          -0.1522, -0.4075, -0.5004, -0.5004, -0.3292]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4164, -0.5044, -0.6272, -0.6272, -0.4450, -0.4900, -0.6092,
          -0.6092, -0.4359, -0.3025, -0.4310, -0.4310, -0.2441, -0.2842,
          -0.4082, -0.4082, -0.2158, -0.0918, -0.2187, -0.2187, -0.0235,
          -0.2753, -0.4016, -0.4016, -0.2071, -0.2790, -0.4019, -0.4019,
          -0.2089, -0.4129, -0.5308, -0.5308, -0.3558]],

        [[-0.0139, -0.0857, -0.2174, -0.2174, -0.0368, -0.0816, -0.2156,
          -0.2156, -0.0341,  0.1026, -0.0249, -0.0249,  0.1554,  0.0786,
          -0.0434, -0.0434,  0.1307,  0.2964,  0.1827,  0.1827,  0.3516,
           0.1068, -0.0202, -0.0202,  0.1625,  0.0861, -0.0359, -0.0359,
           0.1399, -0.0431, -0.1654, -0.1654,  0.0028]],

        [[-0.4340, -0.5660, -0.6656, -0.6656, -0.4908, -0.5571, -0.6530,
          -0.6530, -0.4862, -0.3576, -0.4661, -0.4661, -0.2897, -0.3181,
          -0.4268, -0.4268, -0.2323, -0.1357, -0.2472, -0.2472, -0.0613,
          -0.2928, -0.4055, -0.4055, -0.2139, -0.2980, -0.4030, -0.4030,
          -0.2142, -0.4716, -0.5618, -0.5618, -0.3933]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4601, -0.5454, -0.6669, -0.6669, -0.4871, -0.5290, -0.6474,
          -0.6474, -0.4761, -0.3461, -0.4736, -0.4736, -0.2889, -0.3273,
          -0.4507, -0.4507, -0.2589, -0.1371, -0.2629, -0.2629, -0.0685,
          -0.3207, -0.4459, -0.4459, -0.2525, -0.3228, -0.4446, -0.4446,
          -0.2526, -0.4542, -0.5708, -0.5708, -0.3981]],

        [[-0.0011, -0.0726, -0.2019, -0.2019, -0.0259, -0.0670, -0.1997,
          -0.1997, -0.0213,  0.1146, -0.0112, -0.0112,  0.1663,  0.0915,
          -0.0289, -0.0289,  0.1420,  0.3033,  0.1927,  0.1927,  0.3591,
           0.1157, -0.0099, -0.0099,  0.1711,  0.0967, -0.0242, -0.0242,
           0.1492, -0.0278, -0.1481, -0.1481,  0.0155]],

        [[-0.4371, -0.5694, -0.6670, -0.6670, -0.4962, -0.5594, -0.6535,
          -0.6535, -0.4903, -0.3612, -0.4675, -0.4675, -0.2956, -0.3213,
          -0.4283, -0.4283, -0.2372, -0.1419, -0.2524, -0.2524, -0.0701,
          -0.2967, -0.4065, -0.4065, -0.2197, -0.3035, -0.4057, -0.4057,
          -0.2216, -0.4751, -0.5639, -0.5639, -0.3983]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.5118, -0.5975, -0.7156, -0.7156, -0.5364, -0.5777, -0.6925,
          -0.6925, -0.5225, -0.4008, -0.5247, -0.5247, -0.3416, -0.3796,
          -0.5005, -0.5005, -0.3087, -0.1907, -0.3152, -0.3152, -0.1207,
          -0.3768, -0.4977, -0.4977, -0.3062, -0.3784, -0.4964, -0.4964,
          -0.3058, -0.5060, -0.6201, -0.6201, -0.4481]],

        [[-0.0187, -0.0918, -0.2168, -0.2168, -0.0419, -0.0851, -0.2141,
          -0.2141, -0.0372,  0.0919, -0.0305, -0.0305,  0.1440,  0.0734,
          -0.0424, -0.0424,  0.1275,  0.2784,  0.1709,  0.1709,  0.3368,
           0.0930, -0.0276, -0.0276,  0.1505,  0.0760, -0.0404, -0.0404,
           0.1312, -0.0493, -0.1660, -0.1660, -0.0045]],

        [[-0.4469, -0.5796, -0.6739, -0.6739, -0.5079, -0.5679, -0.6589,
          -0.6589, -0.4999, -0.3759, -0.4790, -0.4790, -0.3105, -0.3344,
          -0.4379, -0.4379, -0.2513, -0.1637, -0.2705, -0.2705, -0.0925,
          -0.3067, -0.4137, -0.4137, -0.2300, -0.3146, -0.4129, -0.4129,
          -0.2333, -0.4834, -0.5681, -0.5681, -0.4067]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.5572, -0.6393, -0.7566, -0.7566, -0.5780, -0.6177, -0.7317,
          -0.7317, -0.5624, -0.4455, -0.5688, -0.5688, -0.3867, -0.4249,
          -0.5448, -0.5448, -0.3532, -0.2368, -0.3605, -0.3605, -0.1663,
          -0.4235, -0.5438, -0.5438, -0.3525, -0.4239, -0.5411, -0.5411,
          -0.3507, -0.5497, -0.6625, -0.6625, -0.4912]],

        [[ 0.0148, -0.0523, -0.1769, -0.1769, -0.0086, -0.0439, -0.1737,
          -0.1737, -0.0023,  0.1274,  0.0066,  0.0066,  0.1753,  0.1021,
          -0.0119, -0.0119,  0.1500,  0.3034,  0.1983,  0.1983,  0.3571,
           0.1225,  0.0045,  0.0045,  0.1748,  0.1057, -0.0093, -0.0093,
           0.1549, -0.0126, -0.1299, -0.1299,  0.0260]],

        [[-0.4607, -0.6016, -0.6927, -0.6927, -0.5310, -0.5891, -0.6763,
          -0.6763, -0.5226, -0.3966, -0.4958, -0.4958, -0.3327, -0.3488,
          -0.4474, -0.4474, -0.2678, -0.1877, -0.2912, -0.2912, -0.1200,
          -0.3240, -0.4261, -0.4261, -0.2496, -0.3311, -0.4248, -0.4248,
          -0.2522, -0.4994, -0.5799, -0.5799, -0.4231]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.5942, -0.6748, -0.7906, -0.7906, -0.6131, -0.6511, -0.7638,
          -0.7638, -0.5954, -0.4814, -0.6037, -0.6037, -0.4226, -0.4631,
          -0.5823, -0.5823, -0.3910, -0.2739, -0.3974, -0.3974, -0.2042,
          -0.4627, -0.5817, -0.5817, -0.3915, -0.4627, -0.5788, -0.5788,
          -0.3895, -0.5853, -0.6968, -0.6968, -0.5264]],

        [[ 0.0019, -0.0658, -0.1902, -0.1902, -0.0236, -0.0577, -0.1877,
          -0.1877, -0.0178,  0.1156, -0.0046, -0.0046,  0.1627,  0.0905,
          -0.0235, -0.0235,  0.1361,  0.2908,  0.1859,  0.1859,  0.3431,
           0.1098, -0.0067, -0.0067,  0.1609,  0.0945, -0.0202, -0.0202,
           0.1419, -0.0243, -0.1423, -0.1423,  0.0117]],

        [[-0.3580, -0.5123, -0.5975, -0.5975, -0.4428, -0.5009, -0.5821,
          -0.5821, -0.4354, -0.3055, -0.3980, -0.3980, -0.2413, -0.2580,
          -0.3507, -0.3507, -0.1781, -0.0982, -0.1966, -0.1966, -0.0325,
          -0.2267, -0.3224, -0.3224, -0.1535, -0.2388, -0.3252, -0.3252,
          -0.1607, -0.4146, -0.4897, -0.4897, -0.3375]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.6167, -0.6961, -0.8099, -0.8099, -0.6310, -0.6735, -0.7838,
          -0.7838, -0.6143, -0.5058, -0.6259, -0.6259, -0.4443, -0.4899,
          -0.6077, -0.6077, -0.4143, -0.2972, -0.4202, -0.4202, -0.2249,
          -0.4896, -0.6061, -0.6061, -0.4152, -0.4904, -0.6043, -0.6043,
          -0.4141, -0.6124, -0.7227, -0.7227, -0.5503]],

        [[ 0.0411, -0.0279, -0.1519, -0.1519,  0.0124, -0.0183, -0.1483,
          -0.1483,  0.0199,  0.1523,  0.0340,  0.0340,  0.1990,  0.1323,
           0.0197,  0.0197,  0.1758,  0.3249,  0.2219,  0.2219,  0.3758,
           0.1500,  0.0348,  0.0348,  0.1998,  0.1343,  0.0210,  0.0210,
           0.1803,  0.0170, -0.1006, -0.1006,  0.0516]],

        [[-0.3288, -0.4863, -0.5646, -0.5646, -0.4170, -0.4758, -0.5505,
          -0.5505, -0.4102, -0.2862, -0.3720, -0.3720, -0.2223, -0.2315,
          -0.3171, -0.3171, -0.1520, -0.0873, -0.1778, -0.1778, -0.0224,
          -0.1979, -0.2877, -0.2877, -0.1254, -0.2137, -0.2931, -0.2931,
          -0.1362, -0.3883, -0.4557, -0.4557, -0.3103]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.6462, -0.7264, -0.8387, -0.8387, -0.6610, -0.7003, -0.8085,
          -0.8085, -0.6407, -0.5370, -0.6563, -0.6563, -0.4756, -0.5210,
          -0.6380, -0.6380, -0.4448, -0.3258, -0.4482, -0.4482, -0.2529,
          -0.5207, -0.6372, -0.6372, -0.4464, -0.5224, -0.6355, -0.6355,
          -0.4457, -0.6436, -0.7523, -0.7523, -0.5810]],

        [[ 0.0576, -0.0165, -0.1353, -0.1353,  0.0273, -0.0038, -0.1288,
          -0.1288,  0.0380,  0.1577,  0.0455,  0.0455,  0.2074,  0.1443,
           0.0373,  0.0373,  0.1904,  0.3255,  0.2269,  0.2269,  0.3808,
           0.1649,  0.0562,  0.0562,  0.2175,  0.1458,  0.0379,  0.0379,
           0.1945,  0.0291, -0.0851, -0.0851,  0.0660]],

        [[-0.3299, -0.4845, -0.5646, -0.5646, -0.4165, -0.4735, -0.5508,
          -0.5508, -0.4089, -0.2850, -0.3718, -0.3718, -0.2220, -0.2290,
          -0.3164, -0.3164, -0.1505, -0.0834, -0.1757, -0.1757, -0.0196,
          -0.1995, -0.2895, -0.2895, -0.1277, -0.2169, -0.2967, -0.2967,
          -0.1401, -0.3872, -0.4571, -0.4571, -0.3106]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.6605, -0.7335, -0.8462, -0.8462, -0.6649, -0.7092, -0.8178,
          -0.8178, -0.6464, -0.5490, -0.6687, -0.6687, -0.4852, -0.5337,
          -0.6514, -0.6514, -0.4552, -0.3387, -0.4611, -0.4611, -0.2636,
          -0.5389, -0.6558, -0.6558, -0.4622, -0.5384, -0.6519, -0.6519,
          -0.4594, -0.6544, -0.7635, -0.7635, -0.5891]],

        [[ 0.0563, -0.0235, -0.1437, -0.1437,  0.0193, -0.0119, -0.1377,
          -0.1377,  0.0289,  0.1570,  0.0428,  0.0428,  0.2064,  0.1485,
           0.0393,  0.0393,  0.1940,  0.3330,  0.2317,  0.2317,  0.3866,
           0.1649,  0.0546,  0.0546,  0.2173,  0.1504,  0.0408,  0.0408,
           0.1985,  0.0249, -0.0907, -0.0907,  0.0614]],

        [[-0.2541, -0.4161, -0.4903, -0.4903, -0.3472, -0.4087, -0.4800,
          -0.4800, -0.3429, -0.2175, -0.2991, -0.2991, -0.1538, -0.1609,
          -0.2429, -0.2429, -0.0815, -0.0185, -0.1045, -0.1045,  0.0454,
          -0.1248, -0.2101, -0.2101, -0.0530, -0.1465, -0.2212, -0.2212,
          -0.0694, -0.3239, -0.3882, -0.3882, -0.2452]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.6684, -0.7391, -0.8508, -0.8508, -0.6698, -0.7152, -0.8217,
          -0.8217, -0.6514, -0.5583, -0.6775, -0.6775, -0.4941, -0.5441,
          -0.6611, -0.6611, -0.4648, -0.3451, -0.4693, -0.4693, -0.2708,
          -0.5473, -0.6644, -0.6644, -0.4707, -0.5487, -0.6613, -0.6613,
          -0.4693, -0.6639, -0.7709, -0.7709, -0.5967]],

        [[ 0.0331, -0.0507, -0.1679, -0.1679, -0.0110, -0.0352, -0.1583,
          -0.1583,  0.0023,  0.1293,  0.0191,  0.0191,  0.1769,  0.1276,
           0.0229,  0.0229,  0.1696,  0.3010,  0.2036,  0.2036,  0.3526,
           0.1418,  0.0359,  0.0359,  0.1928,  0.1268,  0.0211,  0.0211,
           0.1730,  0.0046, -0.1073, -0.1073,  0.0382]],

        [[-0.3268, -0.4951, -0.5746, -0.5746, -0.4280, -0.4865, -0.5618,
          -0.5618, -0.4232, -0.2881, -0.3735, -0.3735, -0.2265, -0.2247,
          -0.3107, -0.3107, -0.1482, -0.0775, -0.1687, -0.1687, -0.0157,
          -0.2003, -0.2881, -0.2881, -0.1308, -0.2164, -0.2949, -0.2949,
          -0.1419, -0.3944, -0.4638, -0.4638, -0.3187]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.6778, -0.7445, -0.8554, -0.8554, -0.6770, -0.7205, -0.8260,
          -0.8260, -0.6581, -0.5667, -0.6859, -0.6859, -0.5050, -0.5551,
          -0.6721, -0.6721, -0.4785, -0.3561, -0.4809, -0.4809, -0.2852,
          -0.5590, -0.6769, -0.6769, -0.4853, -0.5605, -0.6731, -0.6731,
          -0.4840, -0.6698, -0.7746, -0.7746, -0.6039]],

        [[ 0.0368, -0.0525, -0.1665, -0.1665, -0.0109, -0.0350, -0.1544,
          -0.1544,  0.0041,  0.1257,  0.0194,  0.0194,  0.1754,  0.1266,
           0.0245,  0.0245,  0.1688,  0.3010,  0.2049,  0.2049,  0.3532,
           0.1419,  0.0407,  0.0407,  0.1941,  0.1253,  0.0227,  0.0227,
           0.1719,  0.0010, -0.1094, -0.1094,  0.0357]],

        [[-0.3052, -0.4696, -0.5454, -0.5454, -0.4025, -0.4613, -0.5334,
          -0.5334, -0.3976, -0.2693, -0.3518, -0.3518, -0.2080, -0.2018,
          -0.2854, -0.2854, -0.1251, -0.0612, -0.1485, -0.1485,  0.0012,
          -0.1782, -0.2641, -0.2641, -0.1087, -0.1974, -0.2732, -0.2732,
          -0.1227, -0.3719, -0.4377, -0.4377, -0.2959]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.6595, -0.7173, -0.8311, -0.8311, -0.6467, -0.6986, -0.8066,
          -0.8066, -0.6327, -0.5443, -0.6660, -0.6660, -0.4802, -0.5381,
          -0.6581, -0.6581, -0.4589, -0.3312, -0.4584, -0.4584, -0.2587,
          -0.5415, -0.6633, -0.6633, -0.4659, -0.5437, -0.6595, -0.6595,
          -0.4651, -0.6513, -0.7582, -0.7582, -0.5819]],

        [[ 0.0439, -0.0493, -0.1635, -0.1635, -0.0085, -0.0312, -0.1506,
          -0.1506,  0.0072,  0.1297,  0.0242,  0.0242,  0.1794,  0.1357,
           0.0349,  0.0349,  0.1764,  0.3047,  0.2098,  0.2098,  0.3565,
           0.1499,  0.0490,  0.0490,  0.2014,  0.1335,  0.0314,  0.0314,
           0.1795,  0.0093, -0.1002, -0.1002,  0.0434]],

        [[-0.3505, -0.4957, -0.5838, -0.5838, -0.4316, -0.4890, -0.5739,
          -0.5739, -0.4279, -0.2925, -0.3871, -0.3871, -0.2352, -0.2407,
          -0.3355, -0.3355, -0.1659, -0.0806, -0.1770, -0.1770, -0.0207,
          -0.2191, -0.3156, -0.3156, -0.1521, -0.2387, -0.3257, -0.3257,
          -0.1662, -0.4049, -0.4828, -0.4828, -0.3323]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-6.4485e-01, -6.9297e-01, -8.1178e-01, -8.1178e-01, -6.2206e-01,
          -6.7979e-01, -7.9304e-01, -7.9304e-01, -6.1340e-01, -5.2142e-01,
          -6.4777e-01, -6.4777e-01, -4.5705e-01, -5.2510e-01, -6.4998e-01,
          -6.4998e-01, -4.4638e-01, -3.0927e-01, -4.4001e-01, -4.4001e-01,
          -2.3711e-01, -5.2641e-01, -6.5351e-01, -6.5351e-01, -4.5131e-01,
          -5.2868e-01, -6.4963e-01, -6.4963e-01, -4.5064e-01, -6.3360e-01,
          -7.4524e-01, -7.4524e-01, -5.6407e-01]],

        [[ 4.2165e-03, -9.5167e-02, -2.0916e-01, -2.0916e-01, -5.2123e-02,
          -7.3948e-02, -1.9250e-01, -1.9250e-01, -3.3524e-02,  8.4199e-02,
          -2.1064e-02, -2.1064e-02,  1.3581e-01,  1.0027e-01, -6.7449e-04,
          -6.7449e-04,  1.4300e-01,  2.6228e-01,  1.6623e-01,  1.6623e-01,
           3.1728e-01,  1.1083e-01,  9.2707e-03,  9.2707e-03,  1.6490e-01,
           9.5480e-02, -6.6794e-03, -6.6794e-03,  1.4434e-01, -2.5940e-02,
          -1.3520e-01, -1.3520e-01,  9.9635e-03]],

        [[-3.4275e-01, -4.9278e-01, -5.7705e-01, -5.7705e-01, -4.2845e-01,
          -4.8648e-01, -5.6703e-01, -5.6703e-01, -4.2548e-01, -2.9657e-01,
          -3.8650e-01, -3.8650e-01, -2.3899e-01, -2.2832e-01, -3.1897e-01,
          -3.1897e-01, -1.5497e-01, -8.2820e-02, -1.7769e-01, -1.7769e-01,
          -2.3776e-02, -2.1743e-01, -3.0807e-01, -3.0807e-01, -1.5100e-01,
          -2.3537e-01, -3.1730e-01, -3.1730e-01, -1.6385e-01, -3.9604e-01,
          -4.7089e-01, -4.7089e-01, -3.2429e-01]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-5.6037e-01, -6.0301e-01, -7.1948e-01, -7.1948e-01, -5.3064e-01,
          -5.9407e-01, -7.0417e-01, -7.0417e-01, -5.2563e-01, -4.4046e-01,
          -5.6508e-01, -5.6508e-01, -3.7416e-01, -4.4625e-01, -5.6982e-01,
          -5.6982e-01, -3.6683e-01, -2.2574e-01, -3.5565e-01, -3.5565e-01,
          -1.5286e-01, -4.4294e-01, -5.6991e-01, -5.6991e-01, -3.6771e-01,
          -4.4987e-01, -5.6964e-01, -5.6964e-01, -3.7139e-01, -5.5672e-01,
          -6.6578e-01, -6.6578e-01, -4.8494e-01]],

        [[ 4.1314e-02, -6.2398e-02, -1.7614e-01, -1.7614e-01, -1.9778e-02,
          -4.0497e-02, -1.5881e-01, -1.5881e-01, -3.5971e-04,  1.1799e-01,
           1.3795e-02,  1.3795e-02,  1.6899e-01,  1.3416e-01,  3.3403e-02,
           3.3403e-02,  1.7461e-01,  2.9533e-01,  2.0067e-01,  2.0067e-01,
           3.5068e-01,  1.4602e-01,  4.4400e-02,  4.4400e-02,  1.9816e-01,
           1.2999e-01,  2.7851e-02,  2.7851e-02,  1.7693e-01,  9.7501e-03,
          -9.9005e-02, -9.9005e-02,  4.3255e-02]],

        [[-3.2123e-01, -4.6710e-01, -5.5361e-01, -5.5361e-01, -4.0503e-01,
          -4.6306e-01, -5.4593e-01, -5.4593e-01, -4.0409e-01, -2.6940e-01,
          -3.6211e-01, -3.6211e-01, -2.1450e-01, -2.0696e-01, -2.9966e-01,
          -2.9966e-01, -1.3533e-01, -5.8524e-02, -1.5409e-01, -1.5409e-01,
          -1.9289e-03, -1.9327e-01, -2.8675e-01, -2.8675e-01, -1.2954e-01,
          -2.1225e-01, -2.9694e-01, -2.9694e-01, -1.4310e-01, -3.7279e-01,
          -4.4992e-01, -4.4992e-01, -3.0220e-01]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4996, -0.5420, -0.6593, -0.6593, -0.4738, -0.5372, -0.6466,
          -0.6466, -0.4728, -0.3777, -0.5028, -0.5028, -0.3157, -0.3952,
          -0.5191, -0.5191, -0.3209, -0.1647, -0.2960, -0.2960, -0.0983,
          -0.3816, -0.5089, -0.5089, -0.3128, -0.3953, -0.5160, -0.5160,
          -0.3229, -0.5046, -0.6151, -0.6151, -0.4358]],

        [[-0.0161, -0.1304, -0.2433, -0.2433, -0.0865, -0.1077, -0.2248,
          -0.2248, -0.0670,  0.0577, -0.0456, -0.0456,  0.1087,  0.0798,
          -0.0195, -0.0195,  0.1220,  0.2379,  0.1436,  0.1436,  0.2945,
           0.0888, -0.0120, -0.0120,  0.1425,  0.0756, -0.0248, -0.0248,
           0.1249, -0.0487, -0.1550, -0.1550, -0.0144]],

        [[-0.3301, -0.4543, -0.5580, -0.5580, -0.3954, -0.4549, -0.5545,
          -0.5545, -0.3987, -0.2551, -0.3634, -0.3634, -0.2033, -0.2105,
          -0.3179, -0.3179, -0.1415, -0.0392, -0.1447, -0.1447,  0.0156,
          -0.1987, -0.3067, -0.3067, -0.1376, -0.2166, -0.3167, -0.3167,
          -0.1502, -0.3717, -0.4665, -0.4665, -0.3043]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 71, 60])
kb_values.shape:torch.Size([3, 33])
debug: kb_values: torch.Size([3, 26, 33])
debug: kb_probs: torch.Size([3, 26, 33])
filled v=torch.Size([3, 26, 2695]) in 0.13912558555603027 seconds
v:tensor([[[-0.0166,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0167,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0324,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.6449,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.5604,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.4996,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.1308,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0612,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0208,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.0042,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0413,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0161,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.0129,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0307,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0168,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.3427,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.3212,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.3301,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],
       grad_fn=<CopySlices>)
(3, 26)
proc_batch: Hypothesis: ['toms_house_address', 'toms_house_address', 'toms_house_address', 'toms_house_address', 'toms_house_address', 'toms_house_address', 'toms_house_address', 'toms_house_address', 'toms_house_address', 'toms_house_address', 'toms_house_address', 'yoga_activity_time', 'inglewood_saturday', 'menlo_park_friday', 'sorry.', 'goodbye!', 'menlo_park_friday', 'goodbye!', 'yoga_activity_time', 'menlo_park_friday', 'needed?', 'archuleta', 'sorry.', 'experience', 'way!', 'experience']

----------TRN FWD PASS: END current batch----------

batch.kbsrc:  (tensor([[   0,    3,    1,    1,    1,    1,    1],
        [ 756,   11,  859,    1, 2194,    3,    1],
        [ 756,   11,  859,    1,    0,    3,    1],
        [ 756,   11,  859,    1,    0,    3,    1],
        [ 756,   11,  859,    1,  259,    3,    1],
        [1141,    1, 2194,    3,    1,    1,    1],
        [1141,    1,    0,    3,    1,    1,    1],
        [1141,    1,    0,    3,    1,    1,    1],
        [1141,    1,  259,    3,    1,    1,    1],
        [ 523,  557,  585,    1, 2194,    3,    1],
        [ 523,  557,  585,    1,    0,    3,    1],
        [ 523,  557,  585,    1,    0,    3,    1],
        [ 523,  557,  585,    1,  259,    3,    1],
        [ 827,    1, 2194,    3,    1,    1,    1],
        [ 827,    1,    0,    3,    1,    1,    1],
        [ 827,    1,    0,    3,    1,    1,    1],
        [ 827,    1,  259,    3,    1,    1,    1],
        [1048,    1, 2194,    3,    1,    1,    1],
        [1048,    1,    0,    3,    1,    1,    1],
        [1048,    1,    0,    3,    1,    1,    1],
        [1048,    1,  259,    3,    1,    1,    1],
        [ 540,  542,  556, 1058,    1, 2194,    3],
        [ 540,  542,  556, 1058,    1,    0,    3],
        [ 540,  542,  556, 1058,    1,    0,    3],
        [ 540,  542,  556, 1058,    1,  259,    3],
        [ 523,  682,  992,    1, 2194,    3,    1],
        [ 523,  682,  992,    1,    0,    3,    1],
        [ 523,  682,  992,    1,    0,    3,    1],
        [ 523,  682,  992,    1,  259,    3,    1],
        [ 540,  542,  847,  914,    1, 2194,    3],
        [ 540,  542,  847,  914,    1,    0,    3],
        [ 540,  542,  847,  914,    1,    0,    3],
        [ 540,  542,  847,  914,    1,  259,    3]]), tensor([2, 6, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 7,
        7, 6, 6, 6, 6, 7, 7, 7, 7])) <class 'tuple'>
batch.kbtrg:  (tensor([[  2,   0,   3],
        [  2, 404,   3],
        [  2, 406,   3],
        [  2, 405,   3],
        [  2, 403,   3],
        [  2, 627,   3],
        [  2, 629,   3],
        [  2, 628,   3],
        [  2, 626,   3],
        [  2, 470,   3],
        [  2, 472,   3],
        [  2, 471,   3],
        [  2, 469,   3],
        [  2, 458,   3],
        [  2, 460,   3],
        [  2, 459,   3],
        [  2, 457,   3],
        [  2, 493,   3],
        [  2, 495,   3],
        [  2, 494,   3],
        [  2, 492,   3],
        [  2, 360,   3],
        [  2, 362,   3],
        [  2, 361,   3],
        [  2, 359,   3],
        [  2, 376,   3],
        [  2, 378,   3],
        [  2, 377,   3],
        [  2, 375,   3],
        [  2, 364,   3],
        [  2, 366,   3],
        [  2, 365,   3],
        [  2, 363,   3]]), tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3])) <class 'tuple'>

----------TRN FWD PASS: START current batch----------

proc_batch: batch.src: ['where', 'is', 'the', 'nearest', 'gas', '<unk>', '<unk>', 'there', 'is', 'a', '76', '4', 'miles', 'away.', '<unk>', 'what', 'is', 'the', 'address?', '<unk>', 'the', '76', 'gas', 'station', 'is', 'located', 'at', '91', 'el', 'camino', 'real.', 'it', 'is', '4', 'miles', 'away', 'through', 'moderate', 'traffic', '<unk>', '<unk>']
proc_batch: batch.trg: ['anytime!']
proc_batch: kbkeys: [['<unk>'], ['town', 'and', 'country', '<pad>', 'distance'], ['town', 'and', 'country', '<pad>', '<unk>'], ['town', 'and', 'country', '<pad>', '<unk>'], ['town', 'and', 'country', '<pad>', 'address'], ['76', '<pad>', 'distance'], ['76', '<pad>', '<unk>'], ['76', '<pad>', '<unk>'], ['76', '<pad>', 'address'], ['stanford', 'shopping', 'center', '<pad>', 'distance'], ['stanford', 'shopping', 'center', '<pad>', '<unk>'], ['stanford', 'shopping', 'center', '<pad>', '<unk>'], ['stanford', 'shopping', 'center', '<pad>', 'address'], ['teavana', '<pad>', 'distance'], ['teavana', '<pad>', '<unk>'], ['teavana', '<pad>', '<unk>'], ['teavana', '<pad>', 'address'], ['dominos', '<pad>', 'distance'], ['dominos', '<pad>', '<unk>'], ['dominos', '<pad>', '<unk>'], ['dominos', '<pad>', 'address'], ['palo', 'alto', 'garage', 'r', '<pad>', 'distance'], ['palo', 'alto', 'garage', 'r', '<pad>', '<unk>'], ['palo', 'alto', 'garage', 'r', '<pad>', '<unk>'], ['palo', 'alto', 'garage', 'r', '<pad>', 'address'], ['stanford', 'express', 'care', '<pad>', 'distance'], ['stanford', 'express', 'care', '<pad>', '<unk>'], ['stanford', 'express', 'care', '<pad>', '<unk>'], ['stanford', 'express', 'care', '<pad>', 'address'], ['palo', 'alto', 'medical', 'foundation', '<pad>', 'distance'], ['palo', 'alto', 'medical', 'foundation', '<pad>', '<unk>'], ['palo', 'alto', 'medical', 'foundation', '<pad>', '<unk>'], ['palo', 'alto', 'medical', 'foundation', '<pad>', 'address']]
proc_batch: kbvals: [['<s>', '<unk>'], ['<s>', 'town_and_country_distance'], ['<s>', 'town_and_country_traffic_info'], ['<s>', 'town_and_country_poi_type'], ['<s>', 'town_and_country_address'], ['<s>', '76_distance'], ['<s>', '76_traffic_info'], ['<s>', '76_poi_type'], ['<s>', '76_address'], ['<s>', 'stanford_shopping_center_distance'], ['<s>', 'stanford_shopping_center_traffic_info'], ['<s>', 'stanford_shopping_center_poi_type'], ['<s>', 'stanford_shopping_center_address'], ['<s>', 'teavana_distance'], ['<s>', 'teavana_traffic_info'], ['<s>', 'teavana_poi_type'], ['<s>', 'teavana_address'], ['<s>', 'dominos_distance'], ['<s>', 'dominos_traffic_info'], ['<s>', 'dominos_poi_type'], ['<s>', 'dominos_address'], ['<s>', 'palo_alto_garage_r_distance'], ['<s>', 'palo_alto_garage_r_traffic_info'], ['<s>', 'palo_alto_garage_r_poi_type'], ['<s>', 'palo_alto_garage_r_address'], ['<s>', 'stanford_express_care_distance'], ['<s>', 'stanford_express_care_traffic_info'], ['<s>', 'stanford_express_care_poi_type'], ['<s>', 'stanford_express_care_address'], ['<s>', 'palo_alto_medical_foundation_distance'], ['<s>', 'palo_alto_medical_foundation_traffic_info'], ['<s>', 'palo_alto_medical_foundation_poi_type'], ['<s>', 'palo_alto_medical_foundation_address']]
decoder.forward() unroll_steps in model.forward
is 20, which is 1st dim of trg_input=torch.Size([3, 20])
batch.trg_input: ['<s>', 'anytime!']
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.0647,  0.1980,  0.0563,  0.0563,  0.2615,  0.1840,  0.0446,
           0.0446,  0.2421,  0.2144,  0.0790,  0.0790,  0.2693,  0.2399,
           0.1022,  0.1022,  0.3040,  0.2237,  0.0851,  0.0851,  0.2842,
           0.0362, -0.1093, -0.1093,  0.0978,  0.0793, -0.0466, -0.0466,
           0.1404, -0.0167, -0.1623, -0.1623,  0.0428]],

        [[ 0.3250,  0.4472,  0.3141,  0.3141,  0.5120,  0.4330,  0.3002,
           0.3002,  0.4867,  0.4560,  0.3258,  0.3258,  0.4996,  0.4874,
           0.3533,  0.3533,  0.5498,  0.4739,  0.3444,  0.3444,  0.5320,
           0.2788,  0.1420,  0.1420,  0.3566,  0.3331,  0.2045,  0.2045,
           0.3852,  0.2388,  0.1001,  0.1001,  0.3039]],

        [[-0.0300,  0.0954, -0.0432, -0.0432,  0.1577,  0.0911, -0.0403,
          -0.0403,  0.1499,  0.1245, -0.0012, -0.0012,  0.1761,  0.1334,
           0.0028,  0.0028,  0.1967,  0.1305,  0.0107,  0.0107,  0.1910,
          -0.0762, -0.2009, -0.2009, -0.0073,  0.0135, -0.1062, -0.1062,
           0.0664, -0.1052, -0.2307, -0.2307, -0.0423]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.0548,  0.1873,  0.0460,  0.0460,  0.2509,  0.1738,  0.0345,
           0.0345,  0.2320,  0.2041,  0.0689,  0.0689,  0.2595,  0.2300,
           0.0921,  0.0921,  0.2943,  0.2134,  0.0752,  0.0752,  0.2741,
           0.0266, -0.1179, -0.1179,  0.0879,  0.0691, -0.0568, -0.0568,
           0.1307, -0.0269, -0.1719, -0.1719,  0.0327]],

        [[ 0.1311,  0.2645,  0.1254,  0.1254,  0.3253,  0.2447,  0.1068,
           0.1068,  0.2980,  0.2712,  0.1359,  0.1359,  0.3174,  0.3059,
           0.1649,  0.1649,  0.3652,  0.2846,  0.1510,  0.1510,  0.3417,
           0.0941, -0.0436, -0.0436,  0.1650,  0.1501,  0.0161,  0.0161,
           0.2014,  0.0469, -0.0929, -0.0929,  0.1096]],

        [[-0.1250,  0.0025, -0.1373, -0.1373,  0.0625, -0.0023, -0.1341,
          -0.1341,  0.0574,  0.0320, -0.0945, -0.0945,  0.0851,  0.0405,
          -0.0896, -0.0896,  0.1017,  0.0365, -0.0831, -0.0831,  0.0969,
          -0.1652, -0.2888, -0.2888, -0.0995, -0.0761, -0.1964, -0.1964,
          -0.0245, -0.1963, -0.3201, -0.3201, -0.1346]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.0406,  0.1724,  0.0312,  0.0312,  0.2361,  0.1596,  0.0203,
           0.0203,  0.2179,  0.1902,  0.0548,  0.0548,  0.2462,  0.2161,
           0.0778,  0.0778,  0.2805,  0.1994,  0.0610,  0.0610,  0.2603,
           0.0130, -0.1311, -0.1311,  0.0736,  0.0553, -0.0708, -0.0708,
           0.1175, -0.0412, -0.1857, -0.1857,  0.0185]],

        [[ 0.0104,  0.1494,  0.0079,  0.0079,  0.2070,  0.1253, -0.0143,
          -0.0143,  0.1778,  0.1540,  0.0164,  0.0164,  0.2007,  0.1884,
           0.0457,  0.0457,  0.2454,  0.1644,  0.0303,  0.0303,  0.2209,
          -0.0219, -0.1578, -0.1578,  0.0461,  0.0356, -0.1001, -0.1001,
           0.0851, -0.0727, -0.2101, -0.2101, -0.0111]],

        [[-0.1497, -0.0191, -0.1564, -0.1564,  0.0364, -0.0277, -0.1584,
          -0.1584,  0.0296,  0.0046, -0.1209, -0.1209,  0.0559,  0.0146,
          -0.1142, -0.1142,  0.0729,  0.0075, -0.1099, -0.1099,  0.0660,
          -0.1835, -0.3040, -0.3040, -0.1232, -0.0993, -0.2184, -0.2184,
          -0.0500, -0.2206, -0.3430, -0.3430, -0.1628]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 2.9910e-02,  1.6096e-01,  1.9832e-02,  1.9832e-02,  2.2476e-01,
           1.4896e-01,  9.6860e-03,  9.6860e-03,  2.0730e-01,  1.7958e-01,
           4.4235e-02,  4.4235e-02,  2.3604e-01,  2.0574e-01,  6.7074e-02,
           6.7074e-02,  2.7029e-01,  1.8875e-01,  5.0361e-02,  5.0361e-02,
           2.4980e-01,  2.6254e-03, -1.4098e-01, -1.4098e-01,  6.2681e-02,
           4.4989e-02, -8.1260e-02, -8.1260e-02,  1.0780e-01, -5.1874e-02,
          -1.9612e-01, -1.9612e-01,  7.7692e-03]],

        [[-1.2404e-01,  1.8066e-02, -1.2263e-01, -1.2263e-01,  7.2183e-02,
          -1.1206e-02, -1.4947e-01, -1.4947e-01,  3.7960e-02,  1.7350e-02,
          -1.2032e-01, -1.2032e-01,  6.0732e-02,  5.4239e-02, -8.8965e-02,
          -8.8965e-02,  1.0749e-01,  2.7494e-02, -1.0456e-01, -1.0456e-01,
           8.0754e-02, -1.5511e-01, -2.8611e-01, -2.8611e-01, -8.7289e-02,
          -9.7014e-02, -2.3251e-01, -2.3251e-01, -5.2246e-02, -2.0659e-01,
          -3.3863e-01, -3.3863e-01, -1.4651e-01]],

        [[-2.2236e-01, -9.0802e-02, -2.2848e-01, -2.2848e-01, -3.7199e-02,
          -9.7210e-02, -2.2845e-01, -2.2845e-01, -4.0979e-02, -6.4895e-02,
          -1.9103e-01, -1.9103e-01, -1.3101e-02, -5.6377e-02, -1.8637e-01,
          -1.8637e-01, -6.0797e-06, -5.9789e-02, -1.7909e-01, -1.7909e-01,
          -2.2423e-03, -2.5336e-01, -3.7481e-01, -3.7481e-01, -1.9571e-01,
          -1.6896e-01, -2.8877e-01, -2.8877e-01, -1.2012e-01, -2.9215e-01,
          -4.1429e-01, -4.1429e-01, -2.3612e-01]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[ 0.0095,  0.1400, -0.0011, -0.0011,  0.2040,  0.1288, -0.0109,
          -0.0109,  0.1867,  0.1604,  0.0244,  0.0244,  0.2170,  0.1864,
           0.0470,  0.0470,  0.2509,  0.1695,  0.0303,  0.0303,  0.2303,
          -0.0177, -0.1615, -0.1615,  0.0420,  0.0253, -0.1015, -0.1015,
           0.0886, -0.0723, -0.2166, -0.2166, -0.0126]],

        [[-0.2550, -0.1134, -0.2509, -0.2509, -0.0627, -0.1474, -0.2817,
          -0.2817, -0.1018, -0.1186, -0.2540, -0.2540, -0.0789, -0.0818,
          -0.2216, -0.2216, -0.0326, -0.1068, -0.2356, -0.2356, -0.0572,
          -0.2828, -0.4088, -0.4088, -0.2153, -0.2281, -0.3602, -0.3602,
          -0.1881, -0.3363, -0.4610, -0.4610, -0.2782]],

        [[-0.2084, -0.0766, -0.2143, -0.2143, -0.0218, -0.0836, -0.2159,
          -0.2159, -0.0254, -0.0510, -0.1786, -0.1786,  0.0006, -0.0379,
          -0.1690, -0.1690,  0.0190, -0.0444, -0.1666, -0.1666,  0.0147,
          -0.2443, -0.3691, -0.3691, -0.1835, -0.1512, -0.2717, -0.2717,
          -0.1040, -0.2792, -0.4039, -0.4039, -0.2213]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0137,  0.1170, -0.0240, -0.0240,  0.1810,  0.1055, -0.0343,
          -0.0343,  0.1637,  0.1389,  0.0022,  0.0022,  0.1960,  0.1631,
           0.0240,  0.0240,  0.2281,  0.1472,  0.0075,  0.0075,  0.2087,
          -0.0406, -0.1848, -0.1848,  0.0185,  0.0023, -0.1245, -0.1245,
           0.0663, -0.0956, -0.2399, -0.2399, -0.0356]],

        [[-0.3058, -0.1685, -0.3025, -0.3025, -0.1201, -0.2054, -0.3356,
          -0.3356, -0.1627, -0.1742, -0.3068, -0.3068, -0.1371, -0.1396,
          -0.2752, -0.2752, -0.0927, -0.1612, -0.2865, -0.2865, -0.1147,
          -0.3293, -0.4513, -0.4513, -0.2623, -0.2843, -0.4120, -0.4120,
          -0.2464, -0.3857, -0.5050, -0.5050, -0.3293]],

        [[-0.2381, -0.1069, -0.2421, -0.2421, -0.0529, -0.1174, -0.2486,
          -0.2486, -0.0580, -0.0855, -0.2140, -0.2140, -0.0338, -0.0662,
          -0.1959, -0.1959, -0.0095, -0.0763, -0.1991, -0.1991, -0.0157,
          -0.2717, -0.3966, -0.3966, -0.2104, -0.1880, -0.3079, -0.3079,
          -0.1421, -0.3072, -0.4325, -0.4325, -0.2492]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0599,  0.0703, -0.0703, -0.0703,  0.1345,  0.0586, -0.0810,
          -0.0810,  0.1165,  0.0938, -0.0433, -0.0433,  0.1512,  0.1173,
          -0.0219, -0.0219,  0.1821,  0.1023, -0.0379, -0.0379,  0.1636,
          -0.0864, -0.2306, -0.2306, -0.0280, -0.0424, -0.1691, -0.1691,
           0.0221, -0.1416, -0.2852, -0.2852, -0.0817]],

        [[-0.3567, -0.2214, -0.3525, -0.3525, -0.1729, -0.2587, -0.3857,
          -0.3857, -0.2165, -0.2238, -0.3533, -0.3533, -0.1872, -0.1959,
          -0.3284, -0.3284, -0.1494, -0.2131, -0.3359, -0.3359, -0.1678,
          -0.3796, -0.4998, -0.4998, -0.3129, -0.3330, -0.4573, -0.4573,
          -0.2955, -0.4365, -0.5522, -0.5522, -0.3804]],

        [[-0.2146, -0.0878, -0.2237, -0.2237, -0.0348, -0.0973, -0.2296,
          -0.2296, -0.0385, -0.0663, -0.1966, -0.1966, -0.0137, -0.0391,
          -0.1692, -0.1692,  0.0170, -0.0501, -0.1768, -0.1768,  0.0111,
          -0.2424, -0.3720, -0.3720, -0.1837, -0.1779, -0.2985, -0.2985,
          -0.1308, -0.2833, -0.4115, -0.4115, -0.2264]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1026,  0.0268, -0.1132, -0.1132,  0.0909,  0.0149, -0.1245,
          -0.1245,  0.0727,  0.0531, -0.0846, -0.0846,  0.1106,  0.0759,
          -0.0631, -0.0631,  0.1408,  0.0619, -0.0791, -0.0791,  0.1233,
          -0.1300, -0.2749, -0.2749, -0.0718, -0.0835, -0.2098, -0.2098,
          -0.0191, -0.1834, -0.3271, -0.3271, -0.1236]],

        [[-0.4254, -0.2933, -0.4210, -0.4210, -0.2469, -0.3331, -0.4567,
          -0.4567, -0.2930, -0.2969, -0.4241, -0.4241, -0.2624, -0.2704,
          -0.3985, -0.3985, -0.2257, -0.2838, -0.4032, -0.4032, -0.2404,
          -0.4452, -0.5621, -0.5621, -0.3794, -0.4040, -0.5246, -0.5246,
          -0.3689, -0.5040, -0.6150, -0.6150, -0.4496]],

        [[-0.2229, -0.0997, -0.2366, -0.2366, -0.0489, -0.1110, -0.2448,
          -0.2448, -0.0538, -0.0790, -0.2125, -0.2125, -0.0288, -0.0414,
          -0.1721, -0.1721,  0.0119, -0.0578, -0.1879, -0.1879,  0.0022,
          -0.2492, -0.3825, -0.3825, -0.1909, -0.1896, -0.3128, -0.3128,
          -0.1459, -0.2897, -0.4204, -0.4204, -0.2337]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1678, -0.0392, -0.1781, -0.1781,  0.0238, -0.0529, -0.1916,
          -0.1916,  0.0038, -0.0116, -0.1494, -0.1494,  0.0448,  0.0121,
          -0.1265, -0.1265,  0.0757, -0.0013, -0.1421, -0.1421,  0.0592,
          -0.1959, -0.3399, -0.3399, -0.1378, -0.1460, -0.2718, -0.2718,
          -0.0835, -0.2470, -0.3893, -0.3893, -0.1880]],

        [[-0.4710, -0.3421, -0.4671, -0.4671, -0.2972, -0.3842, -0.5051,
          -0.5051, -0.3450, -0.3489, -0.4743, -0.4743, -0.3153, -0.3210,
          -0.4461, -0.4461, -0.2774, -0.3340, -0.4499, -0.4499, -0.2910,
          -0.4892, -0.6022, -0.6022, -0.4235, -0.4563, -0.5738, -0.5738,
          -0.4227, -0.5494, -0.6557, -0.6557, -0.4952]],

        [[-0.2283, -0.1107, -0.2435, -0.2435, -0.0650, -0.1264, -0.2557,
          -0.2557, -0.0733, -0.0969, -0.2273, -0.2273, -0.0524, -0.0531,
          -0.1788, -0.1788, -0.0042, -0.0681, -0.1927, -0.1927, -0.0115,
          -0.2547, -0.3826, -0.3826, -0.1974, -0.2032, -0.3225, -0.3225,
          -0.1661, -0.2931, -0.4192, -0.4192, -0.2403]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1915, -0.0637, -0.2028, -0.2028, -0.0010, -0.0776, -0.2165,
          -0.2165, -0.0210, -0.0333, -0.1716, -0.1716,  0.0233, -0.0105,
          -0.1488, -0.1488,  0.0530, -0.0230, -0.1650, -0.1650,  0.0374,
          -0.2199, -0.3652, -0.3652, -0.1624, -0.1694, -0.2951, -0.2951,
          -0.1070, -0.2697, -0.4124, -0.4124, -0.2107]],

        [[-0.5104, -0.3860, -0.5101, -0.5101, -0.3386, -0.4230, -0.5422,
          -0.5422, -0.3819, -0.3862, -0.5101, -0.5101, -0.3511, -0.3606,
          -0.4832, -0.4832, -0.3147, -0.3696, -0.4843, -0.4843, -0.3247,
          -0.5313, -0.6438, -0.6438, -0.4629, -0.4923, -0.6079, -0.6079,
          -0.4572, -0.5865, -0.6910, -0.6910, -0.5306]],

        [[-0.1253, -0.0124, -0.1439, -0.1439,  0.0323, -0.0284, -0.1565,
          -0.1565,  0.0228, -0.0017, -0.1307, -0.1307,  0.0418,  0.0446,
          -0.0779, -0.0779,  0.0939,  0.0313, -0.0918, -0.0918,  0.0877,
          -0.1521, -0.2803, -0.2803, -0.0963, -0.1166, -0.2340, -0.2340,
          -0.0787, -0.1918, -0.3187, -0.3187, -0.1396]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2334, -0.1082, -0.2469, -0.2469, -0.0459, -0.1225, -0.2613,
          -0.2613, -0.0662, -0.0734, -0.2123, -0.2123, -0.0168, -0.0505,
          -0.1884, -0.1884,  0.0128, -0.0624, -0.2054, -0.2054, -0.0021,
          -0.2627, -0.4088, -0.4088, -0.2058, -0.2100, -0.3353, -0.3353,
          -0.1479, -0.3100, -0.4528, -0.4528, -0.2514]],

        [[-0.4597, -0.3319, -0.4590, -0.4590, -0.2868, -0.3727, -0.4950,
          -0.4950, -0.3340, -0.3394, -0.4670, -0.4670, -0.3066, -0.3050,
          -0.4309, -0.4309, -0.2613, -0.3199, -0.4375, -0.4375, -0.2766,
          -0.4787, -0.5938, -0.5938, -0.4112, -0.4495, -0.5687, -0.5687,
          -0.4169, -0.5368, -0.6446, -0.6446, -0.4823]],

        [[-0.0772,  0.0273, -0.1054, -0.1054,  0.0702,  0.0117, -0.1174,
          -0.1174,  0.0577,  0.0406, -0.0901, -0.0901,  0.0786,  0.0990,
          -0.0248, -0.0248,  0.1451,  0.0822, -0.0437, -0.0437,  0.1346,
          -0.1042, -0.2359, -0.2359, -0.0475, -0.0698, -0.1890, -0.1890,
          -0.0352, -0.1420, -0.2712, -0.2712, -0.0924]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2734, -0.1496, -0.2885, -0.2885, -0.0886, -0.1643, -0.3029,
          -0.3029, -0.1083, -0.1123, -0.2516, -0.2516, -0.0561, -0.0886,
          -0.2267, -0.2267, -0.0260, -0.1008, -0.2441, -0.2441, -0.0407,
          -0.3026, -0.4487, -0.4487, -0.2469, -0.2475, -0.3727, -0.3727,
          -0.1862, -0.3488, -0.4914, -0.4914, -0.2907]],

        [[-0.4161, -0.2791, -0.4089, -0.4089, -0.2339, -0.3272, -0.4522,
          -0.4522, -0.2886, -0.2920, -0.4219, -0.4219, -0.2578, -0.2568,
          -0.3861, -0.3861, -0.2138, -0.2788, -0.4011, -0.4011, -0.2357,
          -0.4358, -0.5560, -0.5560, -0.3714, -0.4025, -0.5249, -0.5249,
          -0.3684, -0.4959, -0.6080, -0.6080, -0.4420]],

        [[-0.0142,  0.0852, -0.0463, -0.0463,  0.1290,  0.0724, -0.0563,
          -0.0563,  0.1205,  0.1056, -0.0240, -0.0240,  0.1463,  0.1604,
           0.0384,  0.0384,  0.2089,  0.1423,  0.0175,  0.0175,  0.1968,
          -0.0422, -0.1744, -0.1744,  0.0124, -0.0086, -0.1274, -0.1274,
           0.0292, -0.0765, -0.2088, -0.2088, -0.0261]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2471, -0.1231, -0.2628, -0.2628, -0.0638, -0.1388, -0.2798,
          -0.2798, -0.0852, -0.0840, -0.2251, -0.2251, -0.0303, -0.0583,
          -0.1980, -0.1980,  0.0029, -0.0721, -0.2184, -0.2184, -0.0139,
          -0.2765, -0.4261, -0.4261, -0.2216, -0.2194, -0.3455, -0.3455,
          -0.1604, -0.3213, -0.4671, -0.4671, -0.2648]],

        [[-0.4431, -0.3036, -0.4322, -0.4322, -0.2568, -0.3532, -0.4767,
          -0.4767, -0.3139, -0.3146, -0.4424, -0.4424, -0.2791, -0.2835,
          -0.4108, -0.4108, -0.2395, -0.3063, -0.4275, -0.4275, -0.2626,
          -0.4676, -0.5871, -0.5871, -0.4021, -0.4225, -0.5417, -0.5417,
          -0.3872, -0.5225, -0.6323, -0.6323, -0.4682]],

        [[ 0.0558,  0.1510,  0.0181,  0.0181,  0.1903,  0.1354,  0.0056,
           0.0056,  0.1779,  0.1674,  0.0371,  0.0371,  0.2020,  0.2289,
           0.1086,  0.1086,  0.2721,  0.2089,  0.0832,  0.0832,  0.2576,
           0.0278, -0.1080, -0.1080,  0.0809,  0.0519, -0.0667, -0.0667,
           0.0832, -0.0011, -0.1357, -0.1357,  0.0444]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.3046, -0.1837, -0.3233, -0.3233, -0.1255, -0.2000, -0.3422,
          -0.3422, -0.1473, -0.1397, -0.2826, -0.2826, -0.0865, -0.1106,
          -0.2516, -0.2516, -0.0503, -0.1273, -0.2753, -0.2753, -0.0698,
          -0.3341, -0.4843, -0.4843, -0.2805, -0.2728, -0.3997, -0.3997,
          -0.2145, -0.3764, -0.5229, -0.5229, -0.3211]],

        [[-0.4953, -0.3561, -0.4837, -0.4837, -0.3074, -0.4060, -0.5282,
          -0.5282, -0.3640, -0.3676, -0.4947, -0.4947, -0.3283, -0.3370,
          -0.4639, -0.4639, -0.2908, -0.3604, -0.4807, -0.4807, -0.3136,
          -0.5196, -0.6386, -0.6386, -0.4554, -0.4761, -0.5948, -0.5948,
          -0.4372, -0.5765, -0.6857, -0.6857, -0.5202]],

        [[ 0.1309,  0.2292,  0.0974,  0.0974,  0.2662,  0.2077,  0.0800,
           0.0800,  0.2467,  0.2343,  0.1050,  0.1050,  0.2635,  0.3009,
           0.1824,  0.1824,  0.3414,  0.2768,  0.1539,  0.1539,  0.3224,
           0.0991, -0.0330, -0.0330,  0.1552,  0.1219,  0.0037,  0.0037,
           0.1481,  0.0717, -0.0590, -0.0590,  0.1163]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.3007, -0.1790, -0.3200, -0.3200, -0.1221, -0.1939, -0.3377,
          -0.3377, -0.1416, -0.1321, -0.2758, -0.2758, -0.0792, -0.1059,
          -0.2474, -0.2474, -0.0457, -0.1215, -0.2704, -0.2704, -0.0640,
          -0.3302, -0.4823, -0.4823, -0.2782, -0.2649, -0.3918, -0.3918,
          -0.2074, -0.3721, -0.5208, -0.5208, -0.3177]],

        [[-0.5204, -0.3812, -0.5057, -0.5057, -0.3315, -0.4341, -0.5526,
          -0.5526, -0.3908, -0.3970, -0.5207, -0.5207, -0.3558, -0.3668,
          -0.4904, -0.4904, -0.3201, -0.3905, -0.5076, -0.5076, -0.3425,
          -0.5456, -0.6620, -0.6620, -0.4809, -0.5039, -0.6194, -0.6194,
          -0.4640, -0.6023, -0.7084, -0.7084, -0.5453]],

        [[ 0.1459,  0.2449,  0.1114,  0.1114,  0.2820,  0.2252,  0.0957,
           0.0957,  0.2655,  0.2509,  0.1199,  0.1199,  0.2826,  0.3197,
           0.2017,  0.2017,  0.3613,  0.2900,  0.1658,  0.1658,  0.3372,
           0.1160, -0.0187, -0.0187,  0.1690,  0.1418,  0.0224,  0.0224,
           0.1703,  0.0938, -0.0400, -0.0400,  0.1383]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2525, -0.1280, -0.2701, -0.2701, -0.0758, -0.1493, -0.2956,
          -0.2956, -0.1024, -0.0899, -0.2362, -0.2362, -0.0418, -0.0503,
          -0.1939, -0.1939,  0.0043, -0.0754, -0.2284, -0.2284, -0.0233,
          -0.2757, -0.4314, -0.4314, -0.2264, -0.2209, -0.3502, -0.3502,
          -0.1684, -0.3202, -0.4720, -0.4720, -0.2707]],

        [[-0.5414, -0.4037, -0.5267, -0.5267, -0.3525, -0.4549, -0.5712,
          -0.5712, -0.4098, -0.4191, -0.5406, -0.5406, -0.3754, -0.3899,
          -0.5118, -0.5118, -0.3418, -0.4119, -0.5272, -0.5272, -0.3620,
          -0.5667, -0.6820, -0.6820, -0.5020, -0.5246, -0.6381, -0.6381,
          -0.4828, -0.6229, -0.7276, -0.7276, -0.5648]],

        [[ 0.1174,  0.2214,  0.0877,  0.0877,  0.2564,  0.1959,  0.0675,
           0.0675,  0.2356,  0.2177,  0.0873,  0.0873,  0.2483,  0.2893,
           0.1721,  0.1721,  0.3288,  0.2581,  0.1353,  0.1353,  0.3041,
           0.0899, -0.0432, -0.0432,  0.1413,  0.1116, -0.0070, -0.0070,
           0.1377,  0.0655, -0.0663, -0.0663,  0.1083]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2444, -0.1216, -0.2662, -0.2662, -0.0708, -0.1405, -0.2899,
          -0.2899, -0.0951, -0.0735, -0.2222, -0.2222, -0.0261, -0.0393,
          -0.1843, -0.1843,  0.0146, -0.0628, -0.2195, -0.2195, -0.0122,
          -0.2678, -0.4273, -0.4273, -0.2210, -0.2094, -0.3403, -0.3403,
          -0.1572, -0.3117, -0.4664, -0.4664, -0.2640]],

        [[-0.5252, -0.3838, -0.5073, -0.5073, -0.3317, -0.4348, -0.5520,
          -0.5520, -0.3893, -0.3994, -0.5209, -0.5209, -0.3548, -0.3708,
          -0.4934, -0.4934, -0.3224, -0.3950, -0.5125, -0.5125, -0.3451,
          -0.5537, -0.6716, -0.6716, -0.4895, -0.5041, -0.6179, -0.6179,
          -0.4617, -0.6073, -0.7142, -0.7142, -0.5496]],

        [[ 0.1695,  0.2726,  0.1373,  0.1373,  0.3087,  0.2511,  0.1205,
           0.1205,  0.2899,  0.2740,  0.1418,  0.1418,  0.3036,  0.3462,
           0.2272,  0.2272,  0.3868,  0.3131,  0.1879,  0.1879,  0.3586,
           0.1388,  0.0030,  0.0030,  0.1923,  0.1687,  0.0482,  0.0482,
           0.1950,  0.1200, -0.0151, -0.0151,  0.1634]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2168, -0.0934, -0.2405, -0.2405, -0.0441, -0.1114, -0.2632,
          -0.2632, -0.0674, -0.0436, -0.1946, -0.1946,  0.0023, -0.0078,
          -0.1548, -0.1548,  0.0451, -0.0346, -0.1933, -0.1933,  0.0150,
          -0.2396, -0.4007, -0.4007, -0.1932, -0.1803, -0.3136, -0.3136,
          -0.1292, -0.2826, -0.4392, -0.4392, -0.2362]],

        [[-0.5348, -0.3950, -0.5156, -0.5156, -0.3418, -0.4453, -0.5592,
          -0.5592, -0.3992, -0.4107, -0.5283, -0.5283, -0.3648, -0.3830,
          -0.5025, -0.5025, -0.3338, -0.4048, -0.5201, -0.5201, -0.3545,
          -0.5640, -0.6812, -0.6812, -0.5006, -0.5126, -0.6223, -0.6223,
          -0.4687, -0.6163, -0.7216, -0.7216, -0.5590]],

        [[ 0.1916,  0.2947,  0.1658,  0.1658,  0.3280,  0.2681,  0.1431,
           0.1431,  0.3042,  0.2880,  0.1599,  0.1599,  0.3147,  0.3547,
           0.2406,  0.2406,  0.3941,  0.3232,  0.2054,  0.2054,  0.3675,
           0.1599,  0.0341,  0.0341,  0.2125,  0.1785,  0.0617,  0.0617,
           0.2031,  0.1363,  0.0096,  0.0096,  0.1791]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1932, -0.0698, -0.2192, -0.2192, -0.0215, -0.0866, -0.2407,
          -0.2407, -0.0437, -0.0192, -0.1730, -0.1730,  0.0246,  0.0208,
          -0.1296, -0.1296,  0.0732, -0.0105, -0.1706, -0.1706,  0.0386,
          -0.2149, -0.3768, -0.3768, -0.1677, -0.1553, -0.2923, -0.2923,
          -0.1052, -0.2566, -0.4159, -0.4159, -0.2105]],

        [[-0.5544, -0.4131, -0.5334, -0.5334, -0.3583, -0.4638, -0.5769,
          -0.5769, -0.4168, -0.4273, -0.5442, -0.5442, -0.3800, -0.4028,
          -0.5220, -0.5220, -0.3527, -0.4235, -0.5388, -0.5388, -0.3728,
          -0.5839, -0.7026, -0.7026, -0.5203, -0.5285, -0.6376, -0.6376,
          -0.4829, -0.6353, -0.7415, -0.7415, -0.5781]],

        [[ 0.1897,  0.2986,  0.1674,  0.1674,  0.3329,  0.2723,  0.1459,
           0.1459,  0.3095,  0.2888,  0.1598,  0.1598,  0.3170,  0.3566,
           0.2412,  0.2412,  0.3964,  0.3247,  0.2048,  0.2048,  0.3695,
           0.1591,  0.0307,  0.0307,  0.2115,  0.1816,  0.0638,  0.0638,
           0.2072,  0.1359,  0.0073,  0.0073,  0.1792]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1933, -0.0724, -0.2203, -0.2203, -0.0261, -0.0915, -0.2446,
          -0.2446, -0.0505, -0.0222, -0.1752, -0.1752,  0.0204,  0.0200,
          -0.1277, -0.1277,  0.0705, -0.0121, -0.1721, -0.1721,  0.0352,
          -0.2136, -0.3752, -0.3752, -0.1683, -0.1585, -0.2939, -0.2939,
          -0.1097, -0.2557, -0.4130, -0.4130, -0.2117]],

        [[-0.5649, -0.4264, -0.5442, -0.5442, -0.3709, -0.4755, -0.5852,
          -0.5852, -0.4276, -0.4400, -0.5534, -0.5534, -0.3915, -0.4172,
          -0.5338, -0.5338, -0.3665, -0.4342, -0.5468, -0.5468, -0.3828,
          -0.5946, -0.7112, -0.7112, -0.5311, -0.5383, -0.6446, -0.6446,
          -0.4918, -0.6455, -0.7492, -0.7492, -0.5879]],

        [[ 0.2150,  0.3226,  0.1932,  0.1932,  0.3542,  0.2941,  0.1700,
           0.1700,  0.3284,  0.3103,  0.1835,  0.1835,  0.3363,  0.3739,
           0.2606,  0.2606,  0.4122,  0.3471,  0.2300,  0.2300,  0.3902,
           0.1872,  0.0617,  0.0617,  0.2370,  0.1988,  0.0828,  0.0828,
           0.2230,  0.1590,  0.0333,  0.0333,  0.2005]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 42, 60])
kb_values.shape:torch.Size([3, 33])
debug: kb_values: torch.Size([3, 20, 33])
debug: kb_probs: torch.Size([3, 20, 33])
filled v=torch.Size([3, 20, 2695]) in 0.1039116382598877 seconds
v:tensor([[[ 0.0647,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0548,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0406,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.2168,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1932,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1933,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.3250,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1311,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0104,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.5348,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.5544,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.5649,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.0300,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1250,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1497,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.1916,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1897,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.2150,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],
       grad_fn=<CopySlices>)
(3, 20)
proc_batch: Hypothesis: ['dominos_address', '7th', 'seattle.', '30s.', 'there?', '171', 'welcome,', 'foundation', 'weekend.', 'month.', 'despite', 'dominos_address', 'dominos_address', 'dominos_address', '76_address', 'dominos_address', 'dominos_address', 'dominos_address', '76_address', 'dominos_address']

----------TRN FWD PASS: END current batch----------

batch.kbsrc:  (tensor([[   0,    3,    1,    1,    1,    1,    1],
        [ 898,  927,    1, 2194,    3,    1,    1],
        [ 898,  927,    1,    0,    3,    1,    1],
        [ 898,  927,    1,    0,    3,    1,    1],
        [ 898,  927,    1,  259,    3,    1,    1],
        [1030,  557,  585,    1, 2194,    3,    1],
        [1030,  557,  585,    1,    0,    3,    1],
        [1030,  557,  585,    1,    0,    3,    1],
        [1030,  557,  585,    1,  259,    3,    1],
        [ 913,  968,    1, 2194,    3,    1,    1],
        [ 913,  968,    1,    0,    3,    1,    1],
        [ 913,  968,    1,    0,    3,    1,    1],
        [ 913,  968,    1,  259,    3,    1,    1],
        [   4,  908,    1, 2194,    3,    1,    1],
        [   4,  908,    1,    0,    3,    1,    1],
        [   4,  908,    1,    0,    3,    1,    1],
        [   4,  908,    1,  259,    3,    1,    1],
        [ 814,  581,    1, 2194,    3,    1,    1],
        [ 814,  581,    1,    0,    3,    1,    1],
        [ 814,  581,    1,    0,    3,    1,    1],
        [ 814,  581,    1,  259,    3,    1,    1],
        [ 593,    1, 2194,    3,    1,    1,    1],
        [ 593,    1,    0,    3,    1,    1,    1],
        [ 593,    1,    0,    3,    1,    1,    1],
        [ 593,    1,  259,    3,    1,    1,    1],
        [ 736,    1, 2194,    3,    1,    1,    1],
        [ 736,    1,    0,    3,    1,    1,    1],
        [ 736,    1,    0,    3,    1,    1,    1],
        [ 736,    1,  259,    3,    1,    1,    1],
        [ 540,  542,  847,  914,    1, 2194,    3],
        [ 540,  542,  847,  914,    1,    0,    3],
        [ 540,  542,  847,  914,    1,    0,    3],
        [ 540,  542,  847,  914,    1,  259,    3]]), tensor([2, 5, 5, 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4,
        4, 4, 4, 4, 4, 7, 7, 7, 7])) <class 'tuple'>
batch.kbtrg:  (tensor([[  2,   0,   3],
        [  2, 368,   3],
        [  2, 370,   3],
        [  2, 369,   3],
        [  2, 367,   3],
        [  2, 423,   3],
        [  2, 425,   3],
        [  2, 424,   3],
        [  2, 422,   3],
        [  2, 408,   3],
        [  2, 410,   3],
        [  2, 409,   3],
        [  2, 407,   3],
        [  2, 479,   3],
        [  2, 481,   3],
        [  2, 480,   3],
        [  2, 478,   3],
        [  2, 335,   3],
        [  2, 337,   3],
        [  2, 336,   3],
        [  2, 334,   3],
        [  2,  35,   3],
        [  2,  37,   3],
        [  2,  36,   3],
        [  2,  34,   3],
        [  2, 352,   3],
        [  2, 354,   3],
        [  2, 353,   3],
        [  2, 351,   3],
        [  2, 364,   3],
        [  2, 366,   3],
        [  2, 365,   3],
        [  2, 363,   3]]), tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3])) <class 'tuple'>

----------TRN FWD PASS: START current batch----------

proc_batch: batch.src: ['show', 'me', 'the', 'closest', 'location', 'where', 'i', 'can', 'get', 'chinese', 'food', '<unk>', 'the', 'closest', 'chinese', 'restaurant', 'is', 'pf', 'changs,', 'located', '5', 'miles', 'away.', '<unk>', 'ok,', 'please', 'give', 'me', 'an', 'address', 'and', 'directions', 'via', 'a', 'route', 'that', '<unk>', 'all', 'heavy', 'traffic.', '<unk>', 'p.f.', 'changs', 'route', 'set', 'to', '669', 'el', 'camino', 'real', 'with', 'only', 'moderate', 'traffic', 'noted.', '<unk>', 'thank', 'you']
proc_batch: batch.trg: ["you're", 'welcome.', 'drive', 'safely,', 'and', 'enjoy.']
proc_batch: kbkeys: [['<unk>'], ['p.f.', 'changs', '<pad>', 'distance'], ['p.f.', 'changs', '<pad>', '<unk>'], ['p.f.', 'changs', '<pad>', '<unk>'], ['p.f.', 'changs', '<pad>', 'address'], ['ravenswood', 'shopping', 'center', '<pad>', 'distance'], ['ravenswood', 'shopping', 'center', '<pad>', '<unk>'], ['ravenswood', 'shopping', 'center', '<pad>', '<unk>'], ['ravenswood', 'shopping', 'center', '<pad>', 'address'], ['chef', "chu's", '<pad>', 'distance'], ['chef', "chu's", '<pad>', '<unk>'], ['chef', "chu's", '<pad>', '<unk>'], ['chef', "chu's", '<pad>', 'address'], ['the', 'westin', '<pad>', 'distance'], ['the', 'westin', '<pad>', '<unk>'], ['the', 'westin', '<pad>', '<unk>'], ['the', 'westin', '<pad>', 'address'], ['dish', 'parking', '<pad>', 'distance'], ['dish', 'parking', '<pad>', '<unk>'], ['dish', 'parking', '<pad>', '<unk>'], ['dish', 'parking', '<pad>', 'address'], ['home', '<pad>', 'distance'], ['home', '<pad>', '<unk>'], ['home', '<pad>', '<unk>'], ['home', '<pad>', 'address'], ['philz', '<pad>', 'distance'], ['philz', '<pad>', '<unk>'], ['philz', '<pad>', '<unk>'], ['philz', '<pad>', 'address'], ['palo', 'alto', 'medical', 'foundation', '<pad>', 'distance'], ['palo', 'alto', 'medical', 'foundation', '<pad>', '<unk>'], ['palo', 'alto', 'medical', 'foundation', '<pad>', '<unk>'], ['palo', 'alto', 'medical', 'foundation', '<pad>', 'address']]
proc_batch: kbvals: [['<s>', '<unk>'], ['<s>', 'p.f._changs_distance'], ['<s>', 'p.f._changs_traffic_info'], ['<s>', 'p.f._changs_poi_type'], ['<s>', 'p.f._changs_address'], ['<s>', 'ravenswood_shopping_center_distance'], ['<s>', 'ravenswood_shopping_center_traffic_info'], ['<s>', 'ravenswood_shopping_center_poi_type'], ['<s>', 'ravenswood_shopping_center_address'], ['<s>', "chef_chu's_distance"], ['<s>', "chef_chu's_traffic_info"], ['<s>', "chef_chu's_poi_type"], ['<s>', "chef_chu's_address"], ['<s>', 'the_westin_distance'], ['<s>', 'the_westin_traffic_info'], ['<s>', 'the_westin_poi_type'], ['<s>', 'the_westin_address'], ['<s>', 'dish_parking_distance'], ['<s>', 'dish_parking_traffic_info'], ['<s>', 'dish_parking_poi_type'], ['<s>', 'dish_parking_address'], ['<s>', 'home_distance'], ['<s>', 'home_traffic_info'], ['<s>', 'home_poi_type'], ['<s>', 'home_address'], ['<s>', 'philz_distance'], ['<s>', 'philz_traffic_info'], ['<s>', 'philz_poi_type'], ['<s>', 'philz_address'], ['<s>', 'palo_alto_medical_foundation_distance'], ['<s>', 'palo_alto_medical_foundation_traffic_info'], ['<s>', 'palo_alto_medical_foundation_poi_type'], ['<s>', 'palo_alto_medical_foundation_address']]
decoder.forward() unroll_steps in model.forward
is 15, which is 1st dim of trg_input=torch.Size([3, 15])
batch.trg_input: ['<s>', "you're", 'welcome.', 'drive', 'safely,', 'and', 'enjoy.']
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0846, -0.0054, -0.1470, -0.1470,  0.0547,  0.1097, -0.0266,
          -0.0266,  0.1638, -0.1688, -0.3067, -0.3067, -0.1113,  0.0368,
          -0.1004, -0.1004,  0.0991, -0.1771, -0.3114, -0.3114, -0.1159,
          -0.0459, -0.1820, -0.1820,  0.0156,  0.0609, -0.0766, -0.0766,
           0.1228, -0.1634, -0.3037, -0.3037, -0.1058]],

        [[ 0.1477,  0.2212,  0.0862,  0.0862,  0.2893,  0.3486,  0.2091,
           0.2091,  0.3906,  0.0556, -0.0851, -0.0851,  0.1240,  0.2578,
           0.1246,  0.1246,  0.3170,  0.0448, -0.0858, -0.0858,  0.1082,
           0.1835,  0.0498,  0.0498,  0.2497,  0.2834,  0.1516,  0.1516,
           0.3495,  0.0649, -0.0690, -0.0690,  0.1337]],

        [[-0.0480,  0.0232, -0.1152, -0.1152,  0.0821,  0.1409,  0.0118,
           0.0118,  0.2025, -0.1252, -0.2660, -0.2660, -0.0692,  0.0620,
          -0.0711, -0.0711,  0.1216, -0.1562, -0.2818, -0.2818, -0.0911,
          -0.0086, -0.1376, -0.1376,  0.0508,  0.0836, -0.0478, -0.0478,
           0.1479, -0.1193, -0.2544, -0.2544, -0.0636]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0632,  0.0159, -0.1258, -0.1258,  0.0762,  0.1312, -0.0054,
          -0.0054,  0.1843, -0.1469, -0.2856, -0.2856, -0.0886,  0.0582,
          -0.0789, -0.0789,  0.1215, -0.1556, -0.2908, -0.2908, -0.0937,
          -0.0250, -0.1606, -0.1606,  0.0374,  0.0823, -0.0556, -0.0556,
           0.1451, -0.1424, -0.2819, -0.2819, -0.0835]],

        [[ 0.1606,  0.2324,  0.1008,  0.1008,  0.2998,  0.3612,  0.2235,
           0.2235,  0.4072,  0.0707, -0.0680, -0.0680,  0.1370,  0.2663,
           0.1358,  0.1358,  0.3266,  0.0448, -0.0806, -0.0806,  0.1088,
           0.1956,  0.0637,  0.0637,  0.2603,  0.2906,  0.1619,  0.1619,
           0.3559,  0.0759, -0.0564, -0.0564,  0.1422]],

        [[-0.0561,  0.0122, -0.1256, -0.1256,  0.0721,  0.1296,  0.0024,
           0.0024,  0.1898, -0.1362, -0.2750, -0.2750, -0.0795,  0.0541,
          -0.0780, -0.0780,  0.1150, -0.1663, -0.2909, -0.2909, -0.1000,
          -0.0167, -0.1448, -0.1448,  0.0430,  0.0732, -0.0571, -0.0571,
           0.1386, -0.1264, -0.2606, -0.2606, -0.0703]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0644,  0.0139, -0.1276, -0.1276,  0.0741,  0.1298, -0.0068,
          -0.0068,  0.1825, -0.1474, -0.2858, -0.2858, -0.0890,  0.0590,
          -0.0776, -0.0776,  0.1224, -0.1563, -0.2920, -0.2920, -0.0941,
          -0.0261, -0.1614, -0.1614,  0.0367,  0.0811, -0.0569, -0.0569,
           0.1443, -0.1434, -0.2818, -0.2818, -0.0838]],

        [[ 0.1724,  0.2429,  0.1136,  0.1136,  0.3100,  0.3724,  0.2365,
           0.2365,  0.4199,  0.0839, -0.0529, -0.0529,  0.1492,  0.2739,
           0.1462,  0.1462,  0.3347,  0.0512, -0.0714, -0.0714,  0.1155,
           0.2059,  0.0760,  0.0760,  0.2698,  0.2991,  0.1727,  0.1727,
           0.3641,  0.0862, -0.0448, -0.0448,  0.1510]],

        [[ 0.0109,  0.0756, -0.0607, -0.0607,  0.1362,  0.1894,  0.0656,
           0.0656,  0.2474, -0.0733, -0.2098, -0.2098, -0.0163,  0.1198,
          -0.0110, -0.0110,  0.1796, -0.1035, -0.2260, -0.2260, -0.0371,
           0.0492, -0.0767, -0.0767,  0.1083,  0.1365,  0.0092,  0.0092,
           0.2021, -0.0610, -0.1943, -0.1943, -0.0052]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.0813, -0.0040, -0.1454, -0.1454,  0.0563,  0.1134, -0.0232,
          -0.0232,  0.1663, -0.1638, -0.3013, -0.3013, -0.1053,  0.0433,
          -0.0929, -0.0929,  0.1069, -0.1729, -0.3086, -0.3086, -0.1104,
          -0.0433, -0.1781, -0.1781,  0.0198,  0.0638, -0.0738, -0.0738,
           0.1272, -0.1598, -0.2967, -0.2967, -0.0995]],

        [[ 0.1685,  0.2377,  0.1094,  0.1094,  0.3052,  0.3733,  0.2382,
           0.2382,  0.4216,  0.0820, -0.0540, -0.0540,  0.1466,  0.2676,
           0.1412,  0.1412,  0.3280,  0.0475, -0.0743, -0.0743,  0.1114,
           0.2002,  0.0708,  0.0708,  0.2644,  0.2951,  0.1695,  0.1695,
           0.3597,  0.0804, -0.0497, -0.0497,  0.1456]],

        [[ 0.0200,  0.0830, -0.0511, -0.0511,  0.1436,  0.1907,  0.0695,
           0.0695,  0.2471, -0.0685, -0.2018, -0.2018, -0.0108,  0.1282,
           0.0004,  0.0004,  0.1879, -0.0968, -0.2180, -0.2180, -0.0295,
           0.0567, -0.0665, -0.0665,  0.1149,  0.1421,  0.0173,  0.0173,
           0.2081, -0.0531, -0.1848, -0.1848,  0.0021]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1149, -0.0378, -0.1791, -0.1791,  0.0231,  0.0813, -0.0566,
          -0.0566,  0.1337, -0.1969, -0.3336, -0.3336, -0.1375,  0.0106,
          -0.1249, -0.1249,  0.0752, -0.2059, -0.3423, -0.3423, -0.1422,
          -0.0764, -0.2116, -0.2116, -0.0128,  0.0299, -0.1080, -0.1080,
           0.0944, -0.1925, -0.3283, -0.3283, -0.1311]],

        [[ 0.1716,  0.2397,  0.1116,  0.1116,  0.3077,  0.3804,  0.2451,
           0.2451,  0.4279,  0.0866, -0.0497, -0.0497,  0.1510,  0.2697,
           0.1435,  0.1435,  0.3296,  0.0533, -0.0690, -0.0690,  0.1176,
           0.2038,  0.0741,  0.0741,  0.2681,  0.2993,  0.1737,  0.1737,
           0.3640,  0.0821, -0.0491, -0.0491,  0.1473]],

        [[ 0.0647,  0.1293, -0.0059, -0.0059,  0.1896,  0.2323,  0.1111,
           0.1111,  0.2872, -0.0253, -0.1594, -0.1594,  0.0323,  0.1738,
           0.0444,  0.0444,  0.2323, -0.0492, -0.1716, -0.1716,  0.0177,
           0.1025, -0.0217, -0.0217,  0.1596,  0.1894,  0.0636,  0.0636,
           0.2546, -0.0094, -0.1432, -0.1432,  0.0446]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.1472, -0.0709, -0.2119, -0.2119, -0.0096,  0.0513, -0.0876,
          -0.0876,  0.1033, -0.2282, -0.3640, -0.3640, -0.1675, -0.0191,
          -0.1535, -0.1535,  0.0466, -0.2383, -0.3750, -0.3750, -0.1736,
          -0.1070, -0.2424, -0.2424, -0.0430, -0.0028, -0.1411, -0.1411,
           0.0628, -0.2236, -0.3592, -0.3592, -0.1619]],

        [[ 0.1684,  0.2384,  0.1092,  0.1092,  0.3050,  0.3789,  0.2420,
           0.2420,  0.4234,  0.0823, -0.0548, -0.0548,  0.1466,  0.2662,
           0.1396,  0.1396,  0.3252,  0.0557, -0.0680, -0.0680,  0.1188,
           0.2019,  0.0705,  0.0705,  0.2652,  0.2998,  0.1725,  0.1725,
           0.3637,  0.0796, -0.0544, -0.0544,  0.1435]],

        [[ 0.1104,  0.1763,  0.0422,  0.0422,  0.2360,  0.2706,  0.1499,
           0.1499,  0.3227,  0.0187, -0.1155, -0.1155,  0.0759,  0.2187,
           0.0902,  0.0902,  0.2769, -0.0030, -0.1261, -0.1261,  0.0637,
           0.1469,  0.0240,  0.0240,  0.2032,  0.2345,  0.1093,  0.1093,
           0.2998,  0.0355, -0.0987, -0.0987,  0.0886]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2048, -0.1293, -0.2692, -0.2692, -0.0688, -0.0064, -0.1456,
          -0.1456,  0.0437, -0.2865, -0.4201, -0.4201, -0.2255, -0.0764,
          -0.2088, -0.2088, -0.0108, -0.2950, -0.4312, -0.4312, -0.2306,
          -0.1633, -0.2980, -0.2980, -0.1000, -0.0615, -0.1991, -0.1991,
           0.0042, -0.2791, -0.4125, -0.4125, -0.2175]],

        [[ 0.1187,  0.1910,  0.0603,  0.0603,  0.2558,  0.3379,  0.1981,
           0.1981,  0.3814,  0.0351, -0.1034, -0.1034,  0.0977,  0.2154,
           0.0872,  0.0872,  0.2729,  0.0147, -0.1113, -0.1113,  0.0763,
           0.1563,  0.0217,  0.0217,  0.2177,  0.2553,  0.1253,  0.1253,
           0.3173,  0.0313, -0.1057, -0.1057,  0.0931]],

        [[ 0.1372,  0.2071,  0.0715,  0.0715,  0.2643,  0.2948,  0.1720,
           0.1720,  0.3428,  0.0456, -0.0898, -0.0898,  0.1021,  0.2443,
           0.1145,  0.1145,  0.3004,  0.0298, -0.0965, -0.0965,  0.0946,
           0.1755,  0.0506,  0.0506,  0.2293,  0.2658,  0.1376,  0.1376,
           0.3292,  0.0624, -0.0745, -0.0745,  0.1129]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.2592, -0.1847, -0.3227, -0.3227, -0.1249, -0.0603, -0.1993,
          -0.1993, -0.0108, -0.3429, -0.4731, -0.4731, -0.2805, -0.1294,
          -0.2593, -0.2593, -0.0636, -0.3484, -0.4830, -0.4830, -0.2841,
          -0.2155, -0.3492, -0.3492, -0.1527, -0.1166, -0.2533, -0.2533,
          -0.0507, -0.3320, -0.4638, -0.4638, -0.2711]],

        [[ 0.0895,  0.1661,  0.0341,  0.0341,  0.2271,  0.3136,  0.1709,
           0.1709,  0.3543,  0.0106, -0.1294, -0.1294,  0.0713,  0.1848,
           0.0547,  0.0547,  0.2381, -0.0049, -0.1330, -0.1330,  0.0532,
           0.1299, -0.0077, -0.0077,  0.1883,  0.2312,  0.0983,  0.0983,
           0.2900,  0.0030, -0.1364, -0.1364,  0.0618]],

        [[ 0.0810,  0.1524,  0.0189,  0.0189,  0.2078,  0.2359,  0.1125,
           0.1125,  0.2825, -0.0126, -0.1471, -0.1471,  0.0430,  0.1880,
           0.0607,  0.0607,  0.2449, -0.0247, -0.1508, -0.1508,  0.0399,
           0.1200, -0.0035, -0.0035,  0.1724,  0.2096,  0.0817,  0.0817,
           0.2724,  0.0068, -0.1283, -0.1283,  0.0557]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.3293, -0.2570, -0.3918, -0.3918, -0.1991, -0.1304, -0.2688,
          -0.2688, -0.0827, -0.4153, -0.5417, -0.5417, -0.3535, -0.1989,
          -0.3256, -0.3256, -0.1347, -0.4181, -0.5495, -0.5495, -0.3555,
          -0.2832, -0.4153, -0.4153, -0.2223, -0.1883, -0.3230, -0.3230,
          -0.1236, -0.3984, -0.5268, -0.5268, -0.3392]],

        [[ 0.0307,  0.1118, -0.0231, -0.0231,  0.1694,  0.2605,  0.1142,
           0.1142,  0.2991, -0.0404, -0.1836, -0.1836,  0.0164,  0.1258,
          -0.0072, -0.0072,  0.1757, -0.0529, -0.1852, -0.1852,  0.0022,
           0.0750, -0.0665, -0.0665,  0.1304,  0.1795,  0.0424,  0.0424,
           0.2346, -0.0534, -0.1961, -0.1961,  0.0024]],

        [[ 0.1511,  0.2248,  0.0921,  0.0921,  0.2803,  0.3027,  0.1786,
           0.1786,  0.3475,  0.0559, -0.0794, -0.0794,  0.1117,  0.2548,
           0.1275,  0.1275,  0.3124,  0.0480, -0.0784, -0.0784,  0.1129,
           0.1893,  0.0657,  0.0657,  0.2417,  0.2822,  0.1537,  0.1537,
           0.3452,  0.0759, -0.0599, -0.0599,  0.1247]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.3748, -0.2986, -0.4330, -0.4330, -0.2411, -0.1698, -0.3101,
          -0.3101, -0.1214, -0.4642, -0.5895, -0.5895, -0.4009, -0.2442,
          -0.3705, -0.3705, -0.1795, -0.4601, -0.5908, -0.5908, -0.3976,
          -0.3241, -0.4578, -0.4578, -0.2636, -0.2315, -0.3672, -0.3672,
          -0.1669, -0.4427, -0.5720, -0.5720, -0.3841]],

        [[ 0.0216,  0.1078, -0.0288, -0.0288,  0.1609,  0.2509,  0.1032,
           0.1032,  0.2857, -0.0398, -0.1853, -0.1853,  0.0130,  0.1128,
          -0.0214, -0.0214,  0.1580, -0.0544, -0.1903, -0.1903, -0.0032,
           0.0678, -0.0752, -0.0752,  0.1193,  0.1740,  0.0344,  0.0344,
           0.2251, -0.0611, -0.2057, -0.2057, -0.0091]],

        [[ 0.1584,  0.2341,  0.0997,  0.0997,  0.2875,  0.3110,  0.1858,
           0.1858,  0.3539,  0.0653, -0.0705, -0.0705,  0.1207,  0.2627,
           0.1332,  0.1332,  0.3185,  0.0597, -0.0682, -0.0682,  0.1230,
           0.1996,  0.0732,  0.0732,  0.2504,  0.2937,  0.1624,  0.1624,
           0.3553,  0.0837, -0.0546, -0.0546,  0.1305]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-3.8928e-01, -3.1439e-01, -4.4624e-01, -4.4624e-01, -2.5797e-01,
          -1.8445e-01, -3.2283e-01, -3.2283e-01, -1.3624e-01, -4.8439e-01,
          -6.0609e-01, -6.0609e-01, -4.2058e-01, -2.6018e-01, -3.8361e-01,
          -3.8361e-01, -1.9607e-01, -4.7505e-01, -6.0202e-01, -6.0202e-01,
          -4.1249e-01, -3.3629e-01, -4.6856e-01, -4.6856e-01, -2.7768e-01,
          -2.4815e-01, -3.8118e-01, -3.8118e-01, -1.8385e-01, -4.5665e-01,
          -5.8497e-01, -5.8497e-01, -4.0030e-01]],

        [[ 2.0848e-02,  1.0924e-01, -3.1806e-02, -3.1806e-02,  1.6290e-01,
           2.5180e-01,  1.0278e-01,  1.0278e-01,  2.8821e-01, -3.4247e-02,
          -1.8371e-01, -1.8371e-01,  1.7558e-02,  1.1616e-01, -2.2154e-02,
          -2.2154e-02,  1.6004e-01, -5.2077e-02, -1.9306e-01, -1.9306e-01,
          -5.6925e-04,  7.0605e-02, -7.5535e-02, -7.5535e-02,  1.2215e-01,
           1.7674e-01,  3.4329e-02,  3.4329e-02,  2.2752e-01, -6.2067e-02,
          -2.1079e-01, -2.1079e-01, -9.9219e-03]],

        [[ 1.2072e-01,  1.9783e-01,  6.4729e-02,  6.4729e-02,  2.4840e-01,
           2.6963e-01,  1.4650e-01,  1.4650e-01,  3.1131e-01,  2.4123e-02,
          -1.1108e-01, -1.1108e-01,  7.7736e-02,  2.2365e-01,  9.6170e-02,
           9.6170e-02,  2.7781e-01,  2.0865e-02, -1.0729e-01, -1.0729e-01,
           8.2717e-02,  1.6428e-01,  4.0220e-02,  4.0220e-02,  2.1276e-01,
           2.5448e-01,  1.2445e-01,  1.2445e-01,  3.1409e-01,  4.6437e-02,
          -8.9651e-02, -8.9651e-02,  9.1148e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-4.3230e-01, -3.5605e-01, -4.8698e-01, -4.8698e-01, -3.0180e-01,
          -2.2431e-01, -3.6398e-01, -3.6398e-01, -1.7627e-01, -5.2723e-01,
          -6.4804e-01, -6.4804e-01, -4.6399e-01, -3.0186e-01, -4.2472e-01,
          -4.2472e-01, -2.3951e-01, -5.1810e-01, -6.4333e-01, -6.4333e-01,
          -4.5773e-01, -3.7667e-01, -5.0932e-01, -5.0932e-01, -3.1987e-01,
          -2.9056e-01, -4.2379e-01, -4.2379e-01, -2.2853e-01, -4.9736e-01,
          -6.2418e-01, -6.2418e-01, -4.4250e-01]],

        [[-7.9558e-02,  1.4089e-02, -1.3113e-01, -1.3113e-01,  6.5165e-02,
           1.5140e-01, -6.0645e-04, -6.0645e-04,  1.8737e-01, -1.3193e-01,
          -2.8458e-01, -2.8458e-01, -8.3467e-02,  2.1977e-02, -1.1978e-01,
          -1.1978e-01,  6.3340e-02, -1.4344e-01, -2.8909e-01, -2.8909e-01,
          -9.3958e-02, -2.5126e-02, -1.7503e-01, -1.7503e-01,  2.3910e-02,
           8.3022e-02, -6.3868e-02, -6.3868e-02,  1.3087e-01, -1.6039e-01,
          -3.1166e-01, -3.1166e-01, -1.1073e-01]],

        [[ 1.2011e-01,  1.9590e-01,  6.5110e-02,  6.5110e-02,  2.4636e-01,
           2.6956e-01,  1.4752e-01,  1.4752e-01,  3.1082e-01,  2.3691e-02,
          -1.1024e-01, -1.1024e-01,  7.8025e-02,  2.2258e-01,  9.7153e-02,
           9.7153e-02,  2.7770e-01,  1.8915e-02, -1.0859e-01, -1.0859e-01,
           8.1296e-02,  1.6281e-01,  3.9730e-02,  3.9730e-02,  2.1189e-01,
           2.5368e-01,  1.2423e-01,  1.2423e-01,  3.1369e-01,  4.4203e-02,
          -8.9935e-02, -8.9935e-02,  8.9683e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4427, -0.3626, -0.4931, -0.4931, -0.3101, -0.2309, -0.3703,
          -0.3703, -0.1841, -0.5444, -0.6645, -0.6645, -0.4818, -0.3159,
          -0.4379, -0.4379, -0.2548, -0.5229, -0.6474, -0.6474, -0.4638,
          -0.3825, -0.5155, -0.5155, -0.3280, -0.2990, -0.4318, -0.4318,
          -0.2384, -0.5082, -0.6363, -0.6363, -0.4558]],

        [[-0.1246, -0.0254, -0.1749, -0.1749,  0.0239,  0.0981, -0.0542,
          -0.0542,  0.1355, -0.1724, -0.3284, -0.3284, -0.1267, -0.0162,
          -0.1610, -0.1610,  0.0230, -0.1865, -0.3374, -0.3374, -0.1385,
          -0.0676, -0.2191, -0.2191, -0.0205,  0.0407, -0.1088, -0.1088,
           0.0865, -0.2033, -0.3574, -0.3574, -0.1559]],

        [[ 0.0260,  0.0986, -0.0296, -0.0296,  0.1510,  0.1818,  0.0615,
           0.0615,  0.2265, -0.0715, -0.2033, -0.2033, -0.0155,  0.1298,
           0.0080,  0.0080,  0.1878, -0.0807, -0.2062, -0.2062, -0.0153,
           0.0685, -0.0521, -0.0521,  0.1196,  0.1550,  0.0277,  0.0277,
           0.2174, -0.0516, -0.1818, -0.1818, -0.0040]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-4.6818e-01, -3.8528e-01, -5.1509e-01, -5.1509e-01, -3.3600e-01,
          -2.5856e-01, -3.9742e-01, -3.9742e-01, -2.1410e-01, -5.7491e-01,
          -6.9361e-01, -6.9361e-01, -5.1386e-01, -3.4269e-01, -4.6394e-01,
          -4.6394e-01, -2.8421e-01, -5.4763e-01, -6.7061e-01, -6.7061e-01,
          -4.9100e-01, -4.0418e-01, -5.3705e-01, -5.3705e-01, -3.5318e-01,
          -3.2513e-01, -4.5732e-01, -4.5732e-01, -2.6738e-01, -5.3285e-01,
          -6.6090e-01, -6.6090e-01, -4.8393e-01]],

        [[-5.8585e-02,  4.4535e-02, -1.0565e-01, -1.0565e-01,  9.1532e-02,
           1.4931e-01, -2.0308e-03, -2.0308e-03,  1.8466e-01, -1.0941e-01,
          -2.6612e-01, -2.6612e-01, -6.7302e-02,  5.2500e-02, -9.2867e-02,
          -9.2867e-02,  8.8418e-02, -1.1935e-01, -2.7160e-01, -2.7160e-01,
          -7.4014e-02,  8.3640e-04, -1.5034e-01, -1.5034e-01,  4.5659e-02,
           1.0657e-01, -4.2354e-02, -4.2354e-02,  1.4949e-01, -1.3411e-01,
          -2.8953e-01, -2.8953e-01, -8.9039e-02]],

        [[-4.0532e-02,  2.9742e-02, -9.7120e-02, -9.7120e-02,  8.5351e-02,
           1.2105e-01,  5.7733e-04,  5.7733e-04,  1.6944e-01, -1.3685e-01,
          -2.6727e-01, -2.6727e-01, -7.7365e-02,  6.8160e-02, -5.2577e-02,
          -5.2577e-02,  1.3086e-01, -1.4745e-01, -2.7244e-01, -2.7244e-01,
          -7.8990e-02,  6.7883e-04, -1.1974e-01, -1.1974e-01,  5.5803e-02,
           8.8681e-02, -3.8794e-02, -3.8794e-02,  1.5414e-01, -1.2042e-01,
          -2.4893e-01, -2.4893e-01, -6.8973e-02]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
att debug: u_t.shape=torch.Size([3, 1, 33])
u_t contents=tensor([[[-0.4830, -0.3999, -0.5286, -0.5286, -0.3537, -0.2779, -0.4153,
          -0.4153, -0.2370, -0.5935, -0.7109, -0.7109, -0.5347, -0.3592,
          -0.4792, -0.4792, -0.3034, -0.5636, -0.6854, -0.6854, -0.5094,
          -0.4171, -0.5488, -0.5488, -0.3696, -0.3407, -0.4716, -0.4716,
          -0.2858, -0.5480, -0.6752, -0.6752, -0.5024]],

        [[-0.0941,  0.0119, -0.1390, -0.1390,  0.0561,  0.1096, -0.0412,
          -0.0412,  0.1452, -0.1432, -0.2998, -0.2998, -0.1040,  0.0184,
          -0.1270, -0.1270,  0.0520, -0.1527, -0.3063, -0.3063, -0.1093,
          -0.0315, -0.1833, -0.1833,  0.0105,  0.0719, -0.0775, -0.0775,
           0.1121, -0.1692, -0.3252, -0.3252, -0.1271]],

        [[-0.1719, -0.1037, -0.2307, -0.2307, -0.0462, -0.0059, -0.1259,
          -0.1259,  0.0460, -0.2661, -0.3965, -0.3965, -0.2056, -0.0558,
          -0.1758, -0.1758,  0.0101, -0.2809, -0.4070, -0.4070, -0.2101,
          -0.1294, -0.2487, -0.2487, -0.0724, -0.0444, -0.1714, -0.1714,
           0.0229, -0.2524, -0.3788, -0.3788, -0.1991]]],
       grad_fn=<UnsqueezeBackward0>)
u_t
torch.Size([3, 1, 33])
self.hidden_size:  30
[query,context]
query:  torch.Size([3, 1, 30])
context:  torch.Size([3, 1, 60])
encoder_output; last dim should be encoder hidden (config) * 1/2 (if bidir) torch.Size([3, 59, 60])
kb_values.shape:torch.Size([3, 33])
debug: kb_values: torch.Size([3, 15, 33])
debug: kb_probs: torch.Size([3, 15, 33])
filled v=torch.Size([3, 15, 2695]) in 0.07656097412109375 seconds
v:tensor([[[-0.0846,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0632,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0644,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.4427,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.4682,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.4830,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.1477,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1606,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.1724,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [-0.1246,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0586,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0941,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[-0.0480,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0561,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0109,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         ...,
         [ 0.0260,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.0405,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [-0.1719,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],
       grad_fn=<CopySlices>)
(3, 15)
proc_batch: Hypothesis: ['ravenswood_shopping_center_address', 'ravenswood_shopping_center_address', 'ravenswood_shopping_center_address', 'ravenswood_shopping_center_address', 'ravenswood_shopping_center_address', 'philz_address', 'philz_address', 'philz_address', 'philz_address', 'philz_address', 'philz_address', 'philz_address', 'philz_address', 'ravenswood_shopping_center_address', '18th,']

----------TRN FWD PASS: END current batch----------

batch.kbsrc:  (tensor([[0, 3]]), tensor([2])) <class 'tuple'>
batch.kbtrg:  (tensor([[2, 0, 3]]), tensor([3])) <class 'tuple'>

----------TRN FWD PASS: START current batch----------

proc_batch: batch.src: ['<unk>', 'please', 'set', 'up', 'a', 'reminder', 'for', 'my', 'dinner', 'on', 'the', '11th', 'at', '4pm', 'with', 'my', 'sister.', '<unk>']
proc_batch: batch.trg: ['set!', 'have', 'a', 'good', 'time']
proc_batch: kbkeys: [['<unk>']]
proc_batch: kbvals: [['<s>', '<unk>']]
decoder.forward() unroll_steps in model.forward
is 6, which is 1st dim of trg_input=torch.Size([1, 6])
batch.trg_input: ['<s>', 'set!', 'have', 'a', 'good', 'time']
att debug: u_t.shape=torch.Size([1, 1, 1])
u_t
torch.Size([1, 1, 1])
self.hidden_size:  30
[query,context]
query:  torch.Size([1, 1, 30])
