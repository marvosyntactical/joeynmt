2020-02-20 13:42:40,128 Hello! This is Joey-NMT.
2020-02-20 13:42:42,131 Total params: 2558126
2020-02-20 13:42:42,132 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_hh_l2', 'encoder.rnn.bias_hh_l2_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.bias_ih_l2', 'encoder.rnn.bias_ih_l2_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_hh_l2', 'encoder.rnn.weight_hh_l2_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'encoder.rnn.weight_ih_l2', 'encoder.rnn.weight_ih_l2_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-02-20 13:42:42,133 cfg.name                           : kv_toy
2020-02-20 13:42:42,133 cfg.data.src                       : usr
2020-02-20 13:42:42,133 cfg.data.trg                       : car
2020-02-20 13:42:42,133 cfg.data.train                     : data/kv_ret_dataset/train
2020-02-20 13:42:42,133 cfg.data.dev                       : data/kv_ret_dataset/dev
2020-02-20 13:42:42,133 cfg.data.test                      : data/kv_ret_dataset/test
2020-02-20 13:42:42,133 cfg.data.level                     : word
2020-02-20 13:42:42,133 cfg.data.lowercase                 : True
2020-02-20 13:42:42,133 cfg.data.max_sent_length           : 30
2020-02-20 13:42:42,133 cfg.data.src_voc_min_freq          : 1
2020-02-20 13:42:42,133 cfg.data.src_voc_limit             : 101
2020-02-20 13:42:42,133 cfg.data.trg_voc_min_freq          : 1
2020-02-20 13:42:42,134 cfg.data.trg_voc_limit             : 102
2020-02-20 13:42:42,134 cfg.data.src_vocab                 : data/train.en.w2v.40k.map.voc
2020-02-20 13:42:42,134 cfg.data.trg_vocab                 : data/train.en.w2v.40k.map.voc
2020-02-20 13:42:42,134 cfg.testing.beam_size              : 5
2020-02-20 13:42:42,134 cfg.testing.alpha                  : 1.0
2020-02-20 13:42:42,134 cfg.training.random_seed           : 42
2020-02-20 13:42:42,134 cfg.training.optimizer             : adam
2020-02-20 13:42:42,134 cfg.training.adam_betas            : [0.9, 0.999]
2020-02-20 13:42:42,134 cfg.training.learning_rate         : 0.001
2020-02-20 13:42:42,134 cfg.training.learning_rate_min     : 0.0001
2020-02-20 13:42:42,134 cfg.training.clip_grad_val         : 10.0
2020-02-20 13:42:42,134 cfg.training.weight_decay          : 0.01
2020-02-20 13:42:42,134 cfg.training.batch_size            : 10
2020-02-20 13:42:42,134 cfg.training.batch_type            : sentence
2020-02-20 13:42:42,134 cfg.training.eval_batch_size       : 10
2020-02-20 13:42:42,135 cfg.training.eval_batch_type       : sentence
2020-02-20 13:42:42,135 cfg.training.batch_multiplier      : 1
2020-02-20 13:42:42,135 cfg.training.scheduling            : plateau
2020-02-20 13:42:42,135 cfg.training.patience              : 5
2020-02-20 13:42:42,135 cfg.training.decrease_factor       : 0.5
2020-02-20 13:42:42,135 cfg.training.epochs                : 1
2020-02-20 13:42:42,135 cfg.training.validation_freq       : 10
2020-02-20 13:42:42,135 cfg.training.logging_freq          : 10
2020-02-20 13:42:42,135 cfg.training.eval_metric           : bleu
2020-02-20 13:42:42,135 cfg.training.early_stopping_metric : loss
2020-02-20 13:42:42,135 cfg.training.model_dir             : models/kv_toy_model
2020-02-20 13:42:42,135 cfg.training.overwrite             : True
2020-02-20 13:42:42,135 cfg.training.shuffle               : True
2020-02-20 13:42:42,135 cfg.training.use_cuda              : False
2020-02-20 13:42:42,135 cfg.training.max_output_length     : 31
2020-02-20 13:42:42,136 cfg.training.print_valid_sents     : [0, 1, 2]
2020-02-20 13:42:42,136 cfg.training.keep_last_ckpts       : 3
2020-02-20 13:42:42,136 cfg.training.label_smoothing       : 0.0
2020-02-20 13:42:42,136 cfg.model.initializer              : xavier
2020-02-20 13:42:42,136 cfg.model.init_weight              : 0.01
2020-02-20 13:42:42,136 cfg.model.init_gain                : 1.0
2020-02-20 13:42:42,136 cfg.model.bias_initializer         : zeros
2020-02-20 13:42:42,136 cfg.model.embed_initializer        : normal
2020-02-20 13:42:42,136 cfg.model.embed_init_weight        : 0.1
2020-02-20 13:42:42,136 cfg.model.embed_init_gain          : 1.0
2020-02-20 13:42:42,136 cfg.model.init_rnn_orthogonal      : False
2020-02-20 13:42:42,136 cfg.model.lstm_forget_gate         : 1.0
2020-02-20 13:42:42,136 cfg.model.tied_embeddings          : False
2020-02-20 13:42:42,136 cfg.model.tied_softmax             : False
2020-02-20 13:42:42,136 cfg.model.encoder.type             : recurrent
2020-02-20 13:42:42,136 cfg.model.encoder.rnn_type         : lstm
2020-02-20 13:42:42,137 cfg.model.encoder.embeddings.embedding_dim : 16
2020-02-20 13:42:42,137 cfg.model.encoder.embeddings.scale : False
2020-02-20 13:42:42,137 cfg.model.encoder.embeddings.freeze : False
2020-02-20 13:42:42,137 cfg.model.encoder.hidden_size      : 30
2020-02-20 13:42:42,137 cfg.model.encoder.bidirectional    : True
2020-02-20 13:42:42,137 cfg.model.encoder.dropout          : 0.15
2020-02-20 13:42:42,137 cfg.model.encoder.num_layers       : 3
2020-02-20 13:42:42,137 cfg.model.encoder.freeze           : False
2020-02-20 13:42:42,137 cfg.model.decoder.type             : recurrent
2020-02-20 13:42:42,137 cfg.model.decoder.rnn_type         : lstm
2020-02-20 13:42:42,137 cfg.model.decoder.embeddings.embedding_dim : 16
2020-02-20 13:42:42,137 cfg.model.decoder.embeddings.scale : False
2020-02-20 13:42:42,137 cfg.model.decoder.embeddings.freeze : False
2020-02-20 13:42:42,137 cfg.model.decoder.hidden_size      : 30
2020-02-20 13:42:42,137 cfg.model.decoder.dropout          : 0.15
2020-02-20 13:42:42,138 cfg.model.decoder.hidden_dropout   : 0.2
2020-02-20 13:42:42,138 cfg.model.decoder.num_layers       : 2
2020-02-20 13:42:42,138 cfg.model.decoder.input_feeding    : True
2020-02-20 13:42:42,138 cfg.model.decoder.init_hidden      : last
2020-02-20 13:42:42,138 cfg.model.decoder.attention        : bahdanau
2020-02-20 13:42:42,138 cfg.model.decoder.freeze           : False
2020-02-20 13:42:42,138 Data set sizes: 
	train 6226,
	valid 777,
	test 807
2020-02-20 13:42:42,138 First training example:
	[SRC] where's the nearest parking garage
	[TRG] the nearest parking garage is dish parking at 550 alester ave. would you like directions there?
2020-02-20 13:42:42,138 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) , (6) of (7) . (8) and (9) to
2020-02-20 13:42:42,139 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) , (6) of (7) . (8) and (9) to
2020-02-20 13:42:42,139 Number of Src words (types): 40003
2020-02-20 13:42:42,139 Number of Trg words (types): 40003
2020-02-20 13:42:42,139 Model(
	encoder=RecurrentEncoder(LSTM(16, 30, num_layers=3, batch_first=True, dropout=0.15, bidirectional=True)),
	decoder=RecurrentDecoder(rnn=LSTM(46, 30, num_layers=2, batch_first=True, dropout=0.15), attention=BahdanauAttention),
	src_embed=Embeddings(embedding_dim=16, vocab_size=40003),
	trg_embed=Embeddings(embedding_dim=16, vocab_size=40003))
2020-02-20 13:42:42,169 EPOCH 1
2020-02-20 13:42:44,473 Epoch   1 Step:       10 Batch Loss:   158.959183 Tokens per Sec:      534, Lr: 0.001000
2020-02-20 13:42:57,934 Hooray! New best validation result [loss]!
2020-02-20 13:42:57,934 Saving new checkpoint.
2020-02-20 13:42:57,960 Example #0
2020-02-20 13:42:57,960 	Raw source:     ['make', 'an', 'appointment', 'to', 'reserve', 'conference', 'room', '100', 'later', 'this', 'week', 'for', 'a', 'meeting']
2020-02-20 13:42:57,960 	Raw hypothesis: ['the', 'the', 'the', 'the', 'the', 'the']
2020-02-20 13:42:57,960 	Source:     make an appointment to reserve conference room 100 later this week for a meeting
2020-02-20 13:42:57,960 	Reference:  what day and time should i set an appointment to reserve the conference room?
2020-02-20 13:42:57,961 	Hypothesis: the the the the the the
2020-02-20 13:42:57,961 Example #1
2020-02-20 13:42:57,961 	Raw source:     ['monday', 'at', '3pm.']
2020-02-20 13:42:57,961 	Raw hypothesis: ['the', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']
2020-02-20 13:42:57,961 	Source:     monday at 3pm.
2020-02-20 13:42:57,961 	Reference:  i have made an appointment for monday at 3 pm for the meeting.
2020-02-20 13:42:57,961 	Hypothesis: the <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2020-02-20 13:42:57,961 Example #2
2020-02-20 13:42:57,961 	Raw source:     ['is', 'there', 'supposed', 'to', 'be', 'a', 'blizzard', 'in', 'brentwood', 'on', 'friday?']
2020-02-20 13:42:57,961 	Raw hypothesis: ['the', 'the', 'the', 'the', 'the']
2020-02-20 13:42:57,961 	Source:     is there supposed to be a blizzard in brentwood on friday?
2020-02-20 13:42:57,961 	Reference:  on friday it's gonna rain in brentwood
2020-02-20 13:42:57,961 	Hypothesis: the the the the the
2020-02-20 13:42:57,961 Validation result at epoch   1, step       10: bleu:   0.00, loss: 84748.8516, ppl: 37144.8047, duration: 13.4876s
